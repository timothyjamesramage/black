# action/main.py



# Comments
| Comment | File | Line |
|---------|------|------|
| **# expected format is one of:** | action/main.py | 38 |
| **# - 23.1.0** | action/main.py | 39 |
| **# - 23.1.0-51-g448bba7** | action/main.py | 40 |
| **# the action's commit matches a tag exactly, install exact version from PyPI** | action/main.py | 42 |
| **# the action's commit does not match any tag, install from the local git repo** | action/main.py | 45 |
| **# TODO: remove after a while since this is deprecated in favour of SRC + OPTIONS.** | action/main.py | 63 |

# docs/conf.py



# Comments
| Comment | File | Line |
|---------|------|------|
| **# -*- coding: utf-8 -*-** | docs/conf.py | 1 |
| **#** | docs/conf.py | 2 |
| **# Configuration file for the Sphinx documentation builder.** | docs/conf.py | 3 |
| **#** | docs/conf.py | 4 |
| **# This file does only contain a selection of the most common options. For a** | docs/conf.py | 5 |
| **# full list see the documentation:** | docs/conf.py | 6 |
| **# http://www.sphinx-doc.org/en/stable/config** | docs/conf.py | 7 |
| **# -- Path setup --------------------------------------------------------------** | docs/conf.py | 9 |
| **# If extensions (or modules to document with autodoc) are in another directory,** | docs/conf.py | 11 |
| **# add these directories to sys.path here. If the directory is relative to the** | docs/conf.py | 12 |
| **# documentation root, use os.path.abspath to make it absolute, like shown here.** | docs/conf.py | 13 |
| **#** | docs/conf.py | 14 |
| **# Necessary so Click doesn't hit an encode error when called by** | docs/conf.py | 33 |
| **# sphinxcontrib-programoutput on Windows.** | docs/conf.py | 34 |
| **# -- Project information -----------------------------------------------------** | docs/conf.py | 37 |
| **# Autopopulate version** | docs/conf.py | 43 |
| **# The version, including alpha/beta/rc tags, but not commit hash and datestamps** | docs/conf.py | 44 |
| **# The short X.Y version.** | docs/conf.py | 46 |
| **# -- General configuration ---------------------------------------------------** | docs/conf.py | 54 |
| **# If your documentation needs a minimal Sphinx version, state it here.** | docs/conf.py | 56 |
| **# Add any Sphinx extension module names here, as strings. They can be** | docs/conf.py | 59 |
| **# extensions coming with Sphinx (named 'sphinx.ext.*') or your custom** | docs/conf.py | 60 |
| **# ones.** | docs/conf.py | 61 |
| **# If you need extensions of a certain version or higher, list them here.** | docs/conf.py | 71 |
| **# Add any paths that contain templates here, relative to this directory.** | docs/conf.py | 74 |
| **# The suffix(es) of source filenames.** | docs/conf.py | 77 |
| **# You can specify multiple suffix as a list of string:** | docs/conf.py | 78 |
| **# The master toctree document.** | docs/conf.py | 81 |
| **# The language for content autogenerated by Sphinx. Refer to documentation** | docs/conf.py | 84 |
| **# for a list of supported languages.** | docs/conf.py | 85 |
| **#** | docs/conf.py | 86 |
| **# This is also used if you do content translation via gettext catalogs.** | docs/conf.py | 87 |
| **# Usually you set "language" from the command line for these cases.** | docs/conf.py | 88 |
| **# List of patterns, relative to source directory, that match files and** | docs/conf.py | 91 |
| **# directories to ignore when looking for source files.** | docs/conf.py | 92 |
| **# This pattern also affects html_static_path and html_extra_path .** | docs/conf.py | 93 |
| **# The name of the Pygments (syntax highlighting) style to use.** | docs/conf.py | 97 |
| **# We need headers to be linkable to so ask MyST-Parser to autogenerate anchor IDs for** | docs/conf.py | 100 |
| **# headers up to and including level 3.** | docs/conf.py | 101 |
| **# Prettier support formatting some MyST syntax but not all, so let's disable the** | docs/conf.py | 104 |
| **# unsupported yet still enabled by default ones.** | docs/conf.py | 105 |
| **# Optional MyST Syntaxes** | docs/conf.py | 113 |
| **# -- Options for HTML output -------------------------------------------------** | docs/conf.py | 116 |
| **# The theme to use for HTML and HTML Help pages.  See the documentation for** | docs/conf.py | 118 |
| **# a list of builtin themes.** | docs/conf.py | 119 |
| **#** | docs/conf.py | 120 |
| **# Add any paths that contain custom static files (such as style sheets) here,** | docs/conf.py | 124 |
| **# relative to this directory. They are copied after the builtin static files,** | docs/conf.py | 125 |
| **# so a file named "default.css" will overwrite the builtin "default.css".** | docs/conf.py | 126 |
| **# Custom sidebar templates, must be a dictionary that maps document names** | docs/conf.py | 129 |
| **# to template names.** | docs/conf.py | 130 |
| **#** | docs/conf.py | 131 |
| **# The default sidebars (for documents that don't match any pattern) are** | docs/conf.py | 132 |
| **# defined by theme itself.  Builtin themes are using these templates by** | docs/conf.py | 133 |
| **# default: ``['localtoc.html', 'relations.html', 'sourcelink.html',** | docs/conf.py | 134 |
| **# 'searchbox.html']``.** | docs/conf.py | 135 |
| **#** | docs/conf.py | 136 |
| **# html_sidebars = {}** | docs/conf.py | 137 |
| **# -- Options for HTMLHelp output ---------------------------------------------** | docs/conf.py | 140 |
| **# Output file base name for HTML help builder.** | docs/conf.py | 142 |
| **# -- Options for LaTeX output ------------------------------------------------** | docs/conf.py | 146 |
| **# Grouping the document tree into LaTeX files. List of tuples** | docs/conf.py | 148 |
| **# (source start file, target name, title,** | docs/conf.py | 149 |
| **#  author, documentclass [howto, manual, or own class]).** | docs/conf.py | 150 |
| **# -- Options for manual page output ------------------------------------------** | docs/conf.py | 160 |
| **# One entry per manual page. List of tuples** | docs/conf.py | 162 |
| **# (source start file, name, description, authors, manual section).** | docs/conf.py | 163 |
| **# -- Options for Texinfo output ----------------------------------------------** | docs/conf.py | 167 |
| **# Grouping the document tree into Texinfo files. List of tuples** | docs/conf.py | 169 |
| **# (source start file, target name, title, author,** | docs/conf.py | 170 |
| **#  dir menu entry, description, category)** | docs/conf.py | 171 |
| **# -- Options for Epub output -------------------------------------------------** | docs/conf.py | 183 |
| **# Bibliographic Dublin Core info.** | docs/conf.py | 185 |
| **# The unique identifier of the text. This can be a ISBN number** | docs/conf.py | 191 |
| **# or the project homepage.** | docs/conf.py | 192 |
| **#** | docs/conf.py | 193 |
| **# epub_identifier = ''** | docs/conf.py | 194 |
| **# A unique identification for the text.** | docs/conf.py | 196 |
| **#** | docs/conf.py | 197 |
| **# epub_uid = ''** | docs/conf.py | 198 |
| **# A list of files that should not be packed into the epub file.** | docs/conf.py | 200 |
| **# -- Extension configuration -------------------------------------------------** | docs/conf.py | 204 |
| **#  -- sphinx-copybutton configuration ----------------------------------------** | docs/conf.py | 208 |
| **# -- Options for intersphinx extension ---------------------------------------** | docs/conf.py | 215 |
| **# Example configuration for intersphinx: refer to the Python standard library.** | docs/conf.py | 217 |

## Function Names and Associated Docstring
```python
def make_pypi_svg(version):
"""

"""
```
# gallery/gallery.py



# Comments
| Comment | File | Line |
|---------|------|------|
| **# https://github.com/python/mypy/issues/1484** | gallery/gallery.py | 25 |
| **# continuess to run even it can't format some files. Reporting those** | gallery/gallery.py | 218 |
| **# should be enough** | gallery/gallery.py | 219 |

## Function Names and Associated Docstring
```python
def get_pypi_download_url(package, version):
"""

"""
```
```python
def get_top_packages():
"""

"""
```
```python
def get_package_source(package, version):
"""

"""
```
```python
def get_archive_manager(local_file):
"""

"""
```
```python
def get_first_archive_member(archive):
"""

"""
```
```python
def download_and_extract(package, version, directory):
"""

"""
```
```python
def get_package(package, version, directory):
"""

"""
```
```python
def download_and_extract_top_packages(directory, workers, limit):
"""

"""
```
```python
def git_create_repository(repo):
"""

"""
```
```python
def git_add_and_commit(msg, repo):
"""

"""
```
```python
def git_switch_branch(branch, repo, new, from_branch):
"""

"""
```
```python
def init_repos(options):
"""

"""
```
```python
def black_runner(version, black_repo):
"""

"""
```
```python
def format_repo_with_version(repo, from_branch, black_repo, black_version, input_directory):
"""

"""
```
```python
def format_repos(repos, options):
"""

"""
```
```python
def main():
"""

"""
```
# scripts/check_pre_commit_rev_in_example.py



## Function Names and Associated Docstring
```python
def main(changes, source_version_control):
"""

"""
```
# scripts/check_version_in_basics_example.py



## Function Names and Associated Docstring
```python
def main(changes, the_basics):
"""

"""
```
# scripts/diff_shades_gha_helper.py



# Comments
| Comment | File | Line |
|---------|------|------|
| **# https://docs.github.com/en/actions/using-workflows/workflow-commands-for-github-actions#multiline-strings** | scripts/diff_shades_gha_helper.py | 59 |
| **# Push on main, let's use PyPI Black as the baseline.** | scripts/diff_shades_gha_helper.py | 126 |
| **# PR, let's use main as the baseline.** | scripts/diff_shades_gha_helper.py | 139 |
| **# These are only needed for the PR comment.** | scripts/diff_shades_gha_helper.py | 158 |
| **# fmt: off** | scripts/diff_shades_gha_helper.py | 175 |
| **# fmt: on** | scripts/diff_shades_gha_helper.py | 180 |
| **# It's more convenient to fill in these fields after the first workflow is done** | scripts/diff_shades_gha_helper.py | 227 |
| **# since this command can access the workflows API (doing it in the main workflow** | scripts/diff_shades_gha_helper.py | 228 |
| **# while it's still in progress seems impossible).** | scripts/diff_shades_gha_helper.py | 229 |

## Function Names and Associated Docstring
```python
def set_output(name, value):
"""

"""
```
```python
def http_get(url):
"""

"""
```
```python
def get_main_revision():
"""

"""
```
```python
def get_pr_revision(pr):
"""

"""
```
```python
def get_pypi_version():
"""

"""
```
```python
def main():
"""

"""
```
```python
def config(event):
"""

"""
```
```python
def comment_body(baseline, target, baseline_sha, target_sha, pr_num):
"""

"""
```
```python
def comment_details(run_id):
"""

"""
```
# scripts/fuzz.py



# Comments
| Comment | File | Line |
|---------|------|------|
| **# This test uses the Hypothesis and Hypothesmith libraries to generate random** | scripts/fuzz.py | 18 |
| **# syntatically-valid Python source code and run Black in odd modes.** | scripts/fuzz.py | 19 |
| **# Note that while Hypothesmith might generate code unlike that written by** | scripts/fuzz.py | 27 |
| **# humans, it's a general test that should pass for any *valid* source code.** | scripts/fuzz.py | 28 |
| **# (so e.g. running it against code scraped of the internet might also help)** | scripts/fuzz.py | 29 |
| **# Using randomly-varied modes helps us to exercise less common code paths.** | scripts/fuzz.py | 31 |
| **# Before starting, let's confirm that the input string is valid Python:** | scripts/fuzz.py | 44 |
| **# Then format the code...** | scripts/fuzz.py | 47 |
| **# This is a bug - if it's valid Python code, as above, Black should be** | scripts/fuzz.py | 51 |
| **# able to cope with it.  See issues #970, #1012** | scripts/fuzz.py | 52 |
| **# TODO: remove this try-except block when issues are resolved.** | scripts/fuzz.py | 53 |
| **# This is a bug - if it's valid Python code, as above, Black should be** | scripts/fuzz.py | 60 |
| **# able to cope with it.  See issue #1012.** | scripts/fuzz.py | 61 |
| **# TODO: remove this block when the issue is resolved.** | scripts/fuzz.py | 62 |
| **# And check that we got equivalent and stable output.** | scripts/fuzz.py | 66 |
| **# Future test: check that pure-python and mypyc versions of black** | scripts/fuzz.py | 70 |
| **# give identical output for identical input?** | scripts/fuzz.py | 71 |
| **# Run tests, including shrinking and reporting any known failures.** | scripts/fuzz.py | 75 |
| **# If Atheris is available, run coverage-guided fuzzing.** | scripts/fuzz.py | 78 |
| **# (if you want only bounded fuzzing, just use `pytest fuzz.py`)** | scripts/fuzz.py | 79 |

## Function Names and Associated Docstring
```python
def test_idempotent_any_syntatically_valid_python(src_contents, mode):
"""

"""
```
# scripts/generate_schema.py



# Comments
| Comment | File | Line |
|---------|------|------|
| **# The precise list of unstable features may change frequently, so don't** | scripts/generate_schema.py | 66 |
| **# bother putting it in SchemaStore** | scripts/generate_schema.py | 67 |

## Function Names and Associated Docstring
```python
def generate_schema_from_click(cmd):
"""

"""
```
```python
def main(schemastore, outfile):
"""

"""
```
# scripts/make_width_table.py



# Comments
| Comment | File | Line |
|---------|------|------|
| **# Ignore narrow characters along with zero-width characters so that** | scripts/make_width_table.py | 33 |
| **# they are treated as single-width.  Note that treating zero-width** | scripts/make_width_table.py | 34 |
| **# characters as single-width is consistent with the heuristics built** | scripts/make_width_table.py | 35 |
| **# on top of str.isascii() in the str_width() function in strings.py.** | scripts/make_width_table.py | 36 |
| **# wcwidth {wcwidth.__version__}** | scripts/make_width_table.py | 54 |
| **# Unicode {wcwidth.list_versions()[-1]}** | scripts/make_width_table.py | 55 |

## Function Names and Associated Docstring
```python
def make_width_table():
"""

"""
```
```python
def main():
"""

"""
```
# scripts/migrate-black.py



# Comments
| Comment | File | Line |
|---------|------|------|
| **#!/usr/bin/env python3** | scripts/migrate-black.py | 1 |
| **# check out every commit added by the current branch, blackify them,** | scripts/migrate-black.py | 2 |
| **# and generate diffs to reconstruct the original commits, but then** | scripts/migrate-black.py | 3 |
| **# blackified** | scripts/migrate-black.py | 4 |

## Function Names and Associated Docstring
```python
def git():
"""

"""
```
```python
def blackify(base_branch, black_command, logger):
"""

"""
```
# scripts/release.py



# Comments
| Comment | File | Line |
|---------|------|------|
| **#!/usr/bin/env python3** | scripts/release.py | 1 |
| **## Unreleased** | scripts/release.py | 19 |
| **### Highlights** | scripts/release.py | 21 |
| **### Stable style** | scripts/release.py | 25 |
| **### Preview style** | scripts/release.py | 29 |
| **### Configuration** | scripts/release.py | 33 |
| **### Packaging** | scripts/release.py | 37 |
| **### Parser** | scripts/release.py | 41 |
| **### Performance** | scripts/release.py | 45 |
| **### Output** | scripts/release.py | 49 |
| **### _Blackd_** | scripts/release.py | 53 |
| **### Integrations** | scripts/release.py | 57 |
| **### Documentation** | scripts/release.py | 61 |
| **# TODO: Do better with alpha + beta releases** | scripts/release.py | 71 |
| **# Maybe we vendor packaging library** | scripts/release.py | 72 |
| **# TODO: Support sorting alhpa/beta releases correctly** | scripts/release.py | 85 |
| **# File path fun all pathlib to be platform agnostic** | scripts/release.py | 96 |
| **# Change Unreleased to next version** | scripts/release.py | 145 |
| **# Remove all comments (subheadings are harder - Human required still)** | scripts/release.py | 150 |
| **# Need parent.parent cause script is in scripts/ directory** | scripts/release.py | 233 |

## Function Names and Associated Docstring
```python
def get_git_tags(versions_only):
"""
Pull out all tags or calvers only
"""
```
```python
def tuple_calver(calver):
"""
Convert a calver string into a tuple of ints for sorting
"""
```
```python
def _handle_debug(debug):
"""
Turn on debugging if asked otherwise INFO default
"""
```
```python
def parse_args():
"""

"""
```
```python
def main():
"""

"""
```
```python
def __init__(self, black_repo_dir):
"""

"""
```
```python
def __str__(self):
"""

"""
```
```python
def add_template_to_changes(self):
"""
Add the template to CHANGES.md if it does not exist
"""
```
```python
def cleanup_changes_template_for_release(self):
"""

"""
```
```python
def get_current_version(self):
"""
Get the latest git (version) tag as latest version
"""
```
```python
def get_next_version(self):
"""
Workout the year and month + version number we need to move to
"""
```
```python
def update_repo_for_release(self):
"""
Update CHANGES.md + doc files ready for release
"""
```
```python
def update_version_in_docs(self):
"""

"""
```
# scripts/release_tests.py



# Comments
| Comment | File | Line |
|---------|------|------|
| **#!/usr/bin/env python3** | scripts/release_tests.py | 1 |
| **# Add leading 0 on purpose to ensure we remove it** | scripts/release_tests.py | 19 |
| **# We only test on >= 3.12** | scripts/release_tests.py | 26 |
| **# test we handle no args** | scripts/release_tests.py | 43 |
| **# test we handle** | scripts/release_tests.py | 51 |

## Function Names and Associated Docstring
```python
def today():
"""

"""
```
```python
def strftime():
"""

"""
```
```python
def setUp(self):
"""

"""
```
```python
def tearDown(self):
"""

"""
```
```python
def test_get_current_version(self, mocked_git_tags):
"""

"""
```
```python
def test_get_next_version(self, mocked_git_tags):
"""

"""
```
```python
def test_tuple_calver(self):
"""

"""
```
# src/black/__main__.py


# src/black/_width_table.py


# Comments
| Comment | File | Line |
|---------|------|------|
| **# Generated by make_width_table.py** | src/black/_width_table.py | 1 |
| **# wcwidth 0.2.6** | src/black/_width_table.py | 2 |
| **# Unicode 15.0.0** | src/black/_width_table.py | 3 |

# src/black/brackets.py


# Comments
| Comment | File | Line |
|---------|------|------|
| **# types** | src/black/brackets.py | 21 |
| **# * and ** might also be MATH_OPERATORS but in this case they are not.** | src/black/brackets.py | 241 |
| **# Don't treat them as a delimiter.** | src/black/brackets.py | 242 |
| **# Start with the first opening bracket and ignore closing brackets before.** | src/black/brackets.py | 363 |

## Function Names and Associated Docstring
```python
def is_split_after_delimiter(leaf):
"""
Return the priority of the `leaf` delimiter, given a line break after it.

The delimiter priorities returned here are from those delimiters that would
cause a line break after themselves.

Higher numbers are higher priority.
"""
```
```python
def is_split_before_delimiter(leaf, previous):
"""
Return the priority of the `leaf` delimiter, given a line break before it.

The delimiter priorities returned here are from those delimiters that would
cause a line break before themselves.

Higher numbers are higher priority.
"""
```
```python
def max_delimiter_priority_in_atom(node):
"""
Return maximum delimiter priority inside `node`.

This is specific to atoms with contents contained in a pair of parentheses.
If `node` isn't an atom or there are no enclosing parentheses, returns 0.
"""
```
```python
def get_leaves_inside_matching_brackets(leaves):
"""
Return leaves that are inside matching brackets.

The input `leaves` can have non-matching brackets at the head or tail parts.
Matching brackets are included.
"""
```
```python
def mark(self, leaf):
"""
Mark `leaf` with bracket-related metadata. Keep track of delimiters.

All leaves receive an int `bracket_depth` field that stores how deep
within brackets a given leaf is. 0 means there are no enclosing brackets
that started on this line.

If a leaf is itself a closing bracket and there is a matching opening
bracket earlier, it receives an `opening_bracket` field with which it forms a
pair. This is a one-directional link to avoid reference cycles. Closing
bracket without opening happens on lines continued from previous
breaks, e.g. `) -> "ReturnType":` as part of a funcdef where we place
the return type annotation on its own line of the previous closing RPAR.

If a leaf is a delimiter (a token on which Black can split the line if
needed) and it's on depth 0, its `id()` is stored in the tracker's
`delimiters` field.
"""
```
```python
def any_open_for_or_lambda(self):
"""
Return True if there is an open for or lambda expression on the line.

See maybe_increment_for_loop_variable and maybe_increment_lambda_arguments
for details.
"""
```
```python
def any_open_brackets(self):
"""
Return True if there is an yet unmatched open bracket on the line.
"""
```
```python
def max_delimiter_priority(self, exclude):
"""
Return the highest priority of a delimiter found on the line.

Values are consistent with what `is_split_*_delimiter()` return.
Raises ValueError on no delimiters.
"""
```
```python
def delimiter_count_with_priority(self, priority):
"""
Return the number of delimiters with the given `priority`.

If no `priority` is passed, defaults to max priority on the line.
"""
```
```python
def maybe_increment_for_loop_variable(self, leaf):
"""
In a for loop, or comprehension, the variables are often unpacks.

To avoid splitting on the comma in this situation, increase the depth of
tokens between `for` and `in`.
"""
```
```python
def maybe_decrement_after_for_loop_variable(self, leaf):
"""
See `maybe_increment_for_loop_variable` above for explanation.
"""
```
```python
def maybe_increment_lambda_arguments(self, leaf):
"""
In a lambda expression, there might be more than one argument.

To avoid splitting on the comma in this situation, increase the depth of
tokens between `lambda` and `:`.
"""
```
```python
def maybe_decrement_after_lambda_arguments(self, leaf):
"""
See `maybe_increment_lambda_arguments` above for explanation.
"""
```
```python
def get_open_lsqb(self):
"""
Return the most recent opening square bracket (if any).
"""
```
# src/black/cache.py



# Comments
| Comment | File | Line |
|---------|------|------|
| **# NOTE: Function mostly exists as a clean way to test getting the cache directory.** | src/black/cache.py | 40 |
| **# Likely file too long; see #4172 and #4174** | src/black/cache.py | 71 |
| **# We store raw tuples in the cache because pickling NamedTuples** | src/black/cache.py | 142 |
| **# doesn't work with mypyc on Python 3.8, and because it's faster.** | src/black/cache.py | 143 |

## Function Names and Associated Docstring
```python
def get_cache_dir():
"""
Get the cache directory used by black.

Users can customize this directory on all systems using `BLACK_CACHE_DIR`
environment variable. By default, the cache directory is the user cache directory
under the black application.

This result is immediately set to a constant `black.cache.CACHE_DIR` as to avoid
repeated calls.
"""
```
```python
def get_cache_file(mode):
"""

"""
```
```python
def read(cls, mode):
"""
Read the cache if it exists and is well-formed.

If it is not well-formed, the call to write later should
resolve the issue.
"""
```
```python
def hash_digest(path):
"""
Return hash digest for path.
"""
```
```python
def get_file_data(path):
"""
Return file data for path.
"""
```
```python
def is_changed(self, source):
"""
Check if source has changed compared to cached version.
"""
```
```python
def filtered_cached(self, sources):
"""
Split an iterable of paths in `sources` into two sets.

The first contains paths of files that modified on disk or are not in the
cache. The other contains paths to non-modified files.
"""
```
```python
def write(self, sources):
"""
Update the cache file data and write a new cache file.
"""
```
# src/black/comments.py



# Comments
| Comment | File | Line |
|---------|------|------|
| **# types** | src/black/comments.py | 20 |
| **# Escaped newlines outside of a comment are not really newlines at** | src/black/comments.py | 100 |
| **# all. We treat a single-line comment following an escaped newline** | src/black/comments.py | 101 |
| **# as a simple trailing comment.** | src/black/comments.py | 102 |
| **# We only want standalone comments. If there's no previous leaf or** | src/black/comments.py | 193 |
| **# the previous leaf is indentation, it's a standalone comment in** | src/black/comments.py | 194 |
| **# disguise.** | src/black/comments.py | 195 |
| **# keeping indentation of comment by preserving original whitespaces.** | src/black/comments.py | 230 |
| **# That happens when one of the `ignored_nodes` ended with a NEWLINE** | src/black/comments.py | 243 |
| **# leaf (possibly followed by a DEDENT).** | src/black/comments.py | 244 |
| **# fix for fmt: on in children** | src/black/comments.py | 283 |
| **# This means `# fmt: on` is placed at a different bracket level** | src/black/comments.py | 288 |
| **# than `# fmt: off`. This is an invalid use, but as a courtesy,** | src/black/comments.py | 289 |
| **# we include this closing bracket in the ignored nodes.** | src/black/comments.py | 290 |
| **# The alternative is to fail the formatting.** | src/black/comments.py | 291 |
| **# This means `# fmt: on` is placed right after an indentation** | src/black/comments.py | 299 |
| **# level, and we shouldn't swallow the previous INDENT token.** | src/black/comments.py | 300 |
| **# This can happen when there is no matching `# fmt: on` comment at the** | src/black/comments.py | 307 |
| **# same level as `# fmt: on`. We need to keep this DEDENT.** | src/black/comments.py | 308 |
| **# Need to properly format the leaf prefix to compare it to comment.value,** | src/black/comments.py | 320 |
| **# which is also formatted** | src/black/comments.py | 321 |
| **# The `# fmt: skip` is on the colon line of the if/while/def/class/...** | src/black/comments.py | 335 |
| **# statements. The ignored nodes should be previous siblings of the** | src/black/comments.py | 336 |
| **# parent suite node.** | src/black/comments.py | 337 |
| **# Special case for `async_stmt` where the ASYNC token is on the** | src/black/comments.py | 344 |
| **# grandparent node.** | src/black/comments.py | 345 |
| **# fmt:skip                           <-- single comment** | src/black/comments.py | 397 |
| **# noqa:XXX # fmt:skip # a nice line  <-- multiple comments (Preview)** | src/black/comments.py | 398 |
| **# pylint:XXX; fmt:skip               <-- list of comments (; separated, Preview)** | src/black/comments.py | 399 |

## Function Names and Associated Docstring
```python
def generate_comments(leaf):
"""
Clean the prefix of the `leaf` and generate comments from it, if any.

Comments in lib2to3 are shoved into the whitespace prefix.  This happens
in `pgen2/driver.py:Driver.parse_tokens()`.  This was a brilliant implementation
move because it does away with modifying the grammar to include all the
possible places in which comments can be placed.

The sad consequence for us though is that comments don't "belong" anywhere.
This is why this function generates simple parentless Leaf objects for
comments.  We simply don't know what the correct parent should be.

No matter though, we can live without this.  We really only need to
differentiate between inline and standalone comments.  The latter don't
share the line with any code.

Inline comments are emitted as regular token.COMMENT leaves.  Standalone
are emitted with a fake STANDALONE_COMMENT token identifier.
"""
```
```python
def list_comments(prefix):
"""
Return a list of :class:`ProtoComment` objects parsed from the given `prefix`.
"""
```
```python
def normalize_trailing_prefix(leaf, total_consumed):
"""
Normalize the prefix that's left over after generating comments.

Note: don't use backslashes for formatting or you'll lose your voting rights.
"""
```
```python
def make_comment(content):
"""
Return a consistently formatted comment from the given `content` string.

All comments (except for "##", "#!", "#:", '#'") should have a single
space between the hash sign and the content.

If `content` didn't start with a hash sign, one is provided.
"""
```
```python
def normalize_fmt_off(node, mode, lines):
"""
Convert content between `# fmt: off`/`# fmt: on` into standalone comments.
"""
```
```python
def convert_one_fmt_off_pair(node, mode, lines):
"""
Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.

Returns True if a pair was converted.
"""
```
```python
def generate_ignored_nodes(leaf, comment, mode):
"""
Starting from the container of `leaf`, generate all leaves until `# fmt: on`.

If comment is skip, returns leaf only.
Stops at the end of the block.
"""
```
```python
def _generate_ignored_nodes_from_fmt_skip(leaf, comment):
"""
Generate all leaves that should be ignored by the `# fmt: skip` from `leaf`.
"""
```
```python
def is_fmt_on(container):
"""
Determine whether formatting is switched on within a container.
Determined by whether the last `# fmt:` comment is `on` or `off`.
"""
```
```python
def children_contains_fmt_on(container):
"""
Determine if children have formatting switched on.
"""
```
```python
def contains_pragma_comment(comment_list):
"""
Returns:
    True iff one of the comments in @comment_list is a pragma used by one
    of the more common static analysis tools for python (e.g. mypy, flake8,
    pylint).
"""
```
```python
def _contains_fmt_skip_comment(comment_line, mode):
"""
Checks if the given comment contains FMT_SKIP alone or paired with other comments.
Matching styles:
  # fmt:skip                           <-- single comment
  # noqa:XXX # fmt:skip # a nice line  <-- multiple comments (Preview)
  # pylint:XXX; fmt:skip               <-- list of comments (; separated, Preview)
"""
```
# src/black/concurrency.py



# Comments
| Comment | File | Line |
|---------|------|------|
| **# This part is borrowed from asyncio/runners.py in Python 3.7b2.** | src/black/concurrency.py | 51 |
| **# `concurrent.futures.Future` objects cannot be cancelled once they** | src/black/concurrency.py | 60 |
| **# are already running. There might be some when the `shutdown()` happened.** | src/black/concurrency.py | 61 |
| **# Silence their logger's spew about the event loop being closed.** | src/black/concurrency.py | 62 |
| **# diff-shades depends on being to monkeypatch this function to operate. I know it's** | src/black/concurrency.py | 68 |
| **# not ideal, but this shouldn't cause any issues ... hopefully. ~ichard26** | src/black/concurrency.py | 69 |
| **# Work around https://bugs.python.org/issue26903** | src/black/concurrency.py | 87 |
| **# we arrive here if the underlying system does not support multi-processing** | src/black/concurrency.py | 92 |
| **# like in AWS Lambda or Termux, in which case we gracefully fallback to** | src/black/concurrency.py | 93 |
| **# a ThreadPoolExecutor with just a single worker (more workers would not do us** | src/black/concurrency.py | 94 |
| **# any good due to the Global Interpreter Lock)** | src/black/concurrency.py | 95 |
| **# For diff output, we need locks to ensure we don't interleave output** | src/black/concurrency.py | 149 |
| **# from different processes.** | src/black/concurrency.py | 150 |
| **# There are no good alternatives for these on Windows.** | src/black/concurrency.py | 166 |
| **# If the file was written back or was successfully checked as** | src/black/concurrency.py | 180 |
| **# well-formatted, store this information in the cache.** | src/black/concurrency.py | 181 |

## Function Names and Associated Docstring
```python
def maybe_install_uvloop():
"""
If our environment has uvloop installed we use it.

This is called only from command-line entry points to avoid
interfering with the parent process if Black is used as a library.
"""
```
```python
def cancel(tasks):
"""
asyncio signal handler that cancels all `tasks` and reports to stderr.
"""
```
```python
def shutdown(loop):
"""
Cancel all pending tasks on `loop`, wait for them, and close the loop.
"""
```
```python
def reformat_many(sources, fast, write_back, mode, report, workers):
"""
Reformat multiple files using a ProcessPoolExecutor.
"""
```
# src/black/debug.py


# Comments
| Comment | File | Line |
|---------|------|------|
| **# We don't have to handle prefixes for `Node` objects since** | src/black/debug.py | 40 |
| **# that delegates to the first child anyway.** | src/black/debug.py | 41 |

## Function Names and Associated Docstring
```python
def out(self, message):
"""

"""
```
```python
def visit_default(self, node):
"""

"""
```
```python
def show(cls, code):
"""
Pretty-print the lib2to3 AST of a given string of `code`.

Convenience method for debugging.
"""
```
# src/black/files.py



# Comments
| Comment | File | Line |
|---------|------|------|
| **# Help users on older alphas** | src/black/files.py | 30 |
| **# A list of lists of parents for each 'src'. 'src' is included as a** | src/black/files.py | 79 |
| **# "parent" of itself if it is a directory** | src/black/files.py | 80 |
| **# We do not have access to the user-level config directory, so ignore it.** | src/black/files.py | 122 |
| **# Windows** | src/black/files.py | 239 |
| **# Precondition: resolves_outside_root_or_cannot_stat(path, root) is False** | src/black/files.py | 289 |
| **# something adversarial, fallback to path guaranteed by precondition** | src/black/files.py | 297 |
| **# Note that this logic is sensitive to the ordering of gitignore_dict. Callers must** | src/black/files.py | 307 |
| **# ensure that gitignore_dict is ordered from least specific to most specific.** | src/black/files.py | 308 |
| **# First ignore files matching .gitignore, if passed** | src/black/files.py | 354 |
| **# Then ignore with `--exclude` `--extend-exclude` and `--force-exclude` options.** | src/black/files.py | 361 |
| **# If gitignore is None, gitignore usage is disabled, while a Falsey** | src/black/files.py | 384 |
| **# gitignore is when the directory doesn't have a .gitignore file.** | src/black/files.py | 385 |
| **# Set `strip=False` to avoid needing to modify test_express_diff_with_color.** | src/black/files.py | 432 |

## Function Names and Associated Docstring
```python
def _load_toml(path):
"""

"""
```
```python
def _cached_resolve(path):
"""

"""
```
```python
def find_project_root(srcs, stdin_filename):
"""
Return a directory containing .git, .hg, or pyproject.toml.

That directory will be a common parent of all files and directories
passed in `srcs`.

If no directory in the tree contains a marker that would specify it's the
project root, the root of the file system is returned.

Returns a two-tuple with the first element as the project root path and
the second element as a string describing the method by which the
project root was discovered.
"""
```
```python
def find_pyproject_toml(path_search_start, stdin_filename):
"""
Find the absolute filepath to a pyproject.toml if it exists
"""
```
```python
def parse_pyproject_toml(path_config):
"""
Parse a pyproject toml file, pulling out relevant parts for Black.

If parsing fails, will raise a tomllib.TOMLDecodeError.
"""
```
```python
def infer_target_version(pyproject_toml):
"""
Infer Black's target version from the project metadata in pyproject.toml.

Supports the PyPA standard format (PEP 621):
https://packaging.python.org/en/latest/specifications/declaring-project-metadata/#requires-python

If the target version cannot be inferred, returns None.
"""
```
```python
def parse_req_python_version(requires_python):
"""
Parse a version string (i.e. ``"3.7"``) to a list of TargetVersion.

If parsing fails, will raise a packaging.version.InvalidVersion error.
If the parsed version cannot be mapped to a valid TargetVersion, returns None.
"""
```
```python
def parse_req_python_specifier(requires_python):
"""
Parse a specifier string (i.e. ``">=3.7,<3.10"``) to a list of TargetVersion.

If parsing fails, will raise a packaging.specifiers.InvalidSpecifier error.
If the parsed specifier cannot be mapped to a valid TargetVersion, returns None.
"""
```
```python
def strip_specifier_set(specifier_set):
"""
Strip minor versions for some specifiers in the specifier set.

For background on version specifiers, see PEP 440:
https://peps.python.org/pep-0440/#version-specifiers
"""
```
```python
def find_user_pyproject_toml():
"""
Return the path to the top-level user configuration for black.

This looks for ~\.black on Windows and ~/.config/black on Linux and other
Unix systems.

May raise:
- RuntimeError: if the current user has no homedir
- PermissionError: if the current process cannot access the user's homedir
"""
```
```python
def get_gitignore(root):
"""
Return a PathSpec matching gitignore content if present.
"""
```
```python
def resolves_outside_root_or_cannot_stat(path, root, report):
"""
Returns whether the path is a symbolic link that points outside the
root directory. Also returns True if we failed to resolve the path.
"""
```
```python
def best_effort_relative_path(path, root):
"""

"""
```
```python
def _path_is_ignored(root_relative_path, root, gitignore_dict):
"""

"""
```
```python
def path_is_excluded(normalized_path, pattern):
"""

"""
```
```python
def gen_python_files(paths, root, include, exclude, extend_exclude, force_exclude, report, gitignore_dict):
"""
Generate all files under `path` whose paths are not excluded by the
`exclude_regex`, `extend_exclude`, or `force_exclude` regexes,
but are included by the `include` regex.

Symbolic links pointing outside of the `root` directory are ignored.

`report` is where output about exclusions goes.
"""
```
```python
def wrap_stream_for_windows(f):
"""
Wrap stream with colorama's wrap_stream so colors are shown on Windows.

If `colorama` is unavailable, the original stream is returned unmodified.
Otherwise, the `wrap_stream()` function determines whether the stream needs
to be wrapped for a Windows environment and will accordingly either return
an `AnsiToWin32` wrapper or the original stream.
"""
```
# src/black/handle_ipynb_magics.py



# Comments
| Comment | File | Line |
|---------|------|------|
| **# Might have IPython magics, will process below.** | src/black/handle_ipynb_magics.py | 142 |
| **# Syntax is fine, nothing to mask, early return.** | src/black/handle_ipynb_magics.py | 145 |
| **# Multi-line magic, not supported.** | src/black/handle_ipynb_magics.py | 157 |
| **# ast.NodeVisitor + dataclass = breakage under mypyc.** | src/black/handle_ipynb_magics.py | 315 |
| **# Unsurprisingly, subclassing ast.NodeVisitor means we can't use dataclasses here** | src/black/handle_ipynb_magics.py | 356 |
| **# as mypyc will generate broken code.** | src/black/handle_ipynb_magics.py | 357 |

## Function Names and Associated Docstring
```python
def jupyter_dependencies_are_installed():
"""

"""
```
```python
def remove_trailing_semicolon(src):
"""
Remove trailing semicolon from Jupyter notebook cell.

For example,

    fig, ax = plt.subplots()
    ax.plot(x_data, y_data);  # plot data

would become

    fig, ax = plt.subplots()
    ax.plot(x_data, y_data)  # plot data

Mirrors the logic in `quiet` from `IPython.core.displayhook`, but uses
``tokenize_rt`` so that round-tripping works fine.
"""
```
```python
def put_trailing_semicolon_back(src, has_trailing_semicolon):
"""
Put trailing semicolon back if cell originally had it.

Mirrors the logic in `quiet` from `IPython.core.displayhook`, but uses
``tokenize_rt`` so that round-tripping works fine.
"""
```
```python
def mask_cell(src):
"""
Mask IPython magics so content becomes parseable Python code.

For example,

    %matplotlib inline
    'foo'

becomes

    "25716f358c32750e"
    'foo'

The replacements are returned, along with the transformed code.
"""
```
```python
def get_token(src, magic):
"""
Return randomly generated token to mask IPython magic with.

For example, if 'magic' was `%matplotlib inline`, then a possible
token to mask it with would be `"43fdd17f7e5ddc83"`. The token
will be the same length as the magic, and we make sure that it was
not already present anywhere else in the cell.
"""
```
```python
def replace_cell_magics(src):
"""
Replace cell magic with token.

Note that 'src' will already have been processed by IPython's
TransformerManager().transform_cell.

Example,

    get_ipython().run_cell_magic('t', '-n1', 'ls =!ls\n')

becomes

    "a794."
    ls =!ls

The replacement, along with the transformed code, is returned.
"""
```
```python
def replace_magics(src):
"""
Replace magics within body of cell.

Note that 'src' will already have been processed by IPython's
TransformerManager().transform_cell.

Example, this

    get_ipython().run_line_magic('matplotlib', 'inline')
    'foo'

becomes

    "5e67db56d490fd39"
    'foo'

The replacement, along with the transformed code, are returned.
"""
```
```python
def unmask_cell(src, replacements):
"""
Remove replacements from cell.

For example

    "9b20"
    foo = bar

becomes

    %%time
    foo = bar
"""
```
```python
def _is_ipython_magic(node):
"""
Check if attribute is IPython magic.

Note that the source of the abstract syntax tree
will already have been processed by IPython's
TransformerManager().transform_cell.
"""
```
```python
def _get_str_args(args):
"""

"""
```
```python
def header(self):
"""

"""
```
```python
def __init__(self):
"""

"""
```
```python
def visit_Expr(self, node):
"""
Look for magics in body of cell.

For examples,

    !ls
    !!ls
    ?ls
    ??ls

would (respectively) get transformed to

    get_ipython().system('ls')
    get_ipython().getoutput('ls')
    get_ipython().run_line_magic('pinfo', 'ls')
    get_ipython().run_line_magic('pinfo2', 'ls')

and we look for instances of any of the latter.
"""
```
```python
def visit_Assign(self, node):
"""
Look for system assign magics.

For example,

    black_version = !black --version
    env = %env var

would have been (respectively) transformed to

    black_version = get_ipython().getoutput('black --version')
    env = get_ipython().run_line_magic('env', 'var')

and we look for instances of any of the latter.
"""
```
# src/black/linegen.py



# Comments
| Comment | File | Line |
|---------|------|------|
| **# types** | src/black/linegen.py | 84 |
| **# This isn't a dataclass because @dataclass + Generic breaks mypyc.** | src/black/linegen.py | 93 |
| **# See also https://github.com/mypyc/mypyc/issues/827.** | src/black/linegen.py | 94 |
| **# Special case for async def/for/with statements. `visit_async_stmt`** | src/black/linegen.py | 123 |
| **# adds an `ASYNC` leaf then visits the child def/for/with statement** | src/black/linegen.py | 124 |
| **# nodes. Line yields from those nodes shouldn't treat the former** | src/black/linegen.py | 125 |
| **# `ASYNC` leaf as a complete line.** | src/black/linegen.py | 126 |
| **# any comment within brackets is subject to splitting** | src/black/linegen.py | 139 |
| **# regular trailing comment** | src/black/linegen.py | 142 |
| **# regular standalone comment** | src/black/linegen.py | 147 |
| **# Similar to logic in wrap_in_parentheses** | src/black/linegen.py | 172 |
| **# In blib2to3 INDENT never holds comments.** | src/black/linegen.py | 185 |
| **# The current line might still wait for trailing comments.  At DEDENT time** | src/black/linegen.py | 191 |
| **# there won't be any (they would be prefixes on the preceding NEWLINE).** | src/black/linegen.py | 192 |
| **# Emit the line then.** | src/black/linegen.py | 193 |
| **# While DEDENT has no value, its prefix may contain standalone comments** | src/black/linegen.py | 196 |
| **# that belong to the current indentation level.  Get 'em.** | src/black/linegen.py | 197 |
| **# Finally, emit the dedent.** | src/black/linegen.py | 200 |
| **# Remove redundant brackets around return type annotation.** | src/black/linegen.py | 262 |
| **# STANDALONE_COMMENT happens when `# fmt: skip` is applied on the async** | src/black/linegen.py | 329 |
| **# line.** | src/black/linegen.py | 330 |
| **# Ensure that we are in an attribute trailer** | src/black/linegen.py | 353 |
| **# It shouldn't wrap hexadecimal, binary and octal literals** | src/black/linegen.py | 355 |
| **# It shouldn't wrap complex literals** | src/black/linegen.py | 357 |
| **# We're ignoring docstrings with backslash newline escapes because changing** | src/black/linegen.py | 419 |
| **# indentation of those changes the AST representation of the code.** | src/black/linegen.py | 420 |
| **# visit_default() does handle string normalization for us, but** | src/black/linegen.py | 423 |
| **# since this method acts differently depending on quote style (ex.** | src/black/linegen.py | 424 |
| **# see padding logic below), there's a possibility for unstable** | src/black/linegen.py | 425 |
| **# formatting as visit_default() is called *after*. To avoid a** | src/black/linegen.py | 426 |
| **# situation where this function formats a docstring differently on** | src/black/linegen.py | 427 |
| **# the second pass, normalize it early.** | src/black/linegen.py | 428 |
| **# A natural way to remove the outer quotes is to do:** | src/black/linegen.py | 435 |
| **#   docstring = docstring.strip(quote_char)** | src/black/linegen.py | 436 |
| **# but that breaks on """""x""" (which is '""x').** | src/black/linegen.py | 437 |
| **# So we actually need to remove the first character and the next two** | src/black/linegen.py | 438 |
| **# characters but only if they are the same as the first.** | src/black/linegen.py | 439 |
| **# Add some padding if the docstring starts / ends with a quote mark.** | src/black/linegen.py | 452 |
| **# Odd number of tailing backslashes, add some padding to** | src/black/linegen.py | 460 |
| **# avoid escaping the closing string quote.** | src/black/linegen.py | 461 |
| **# We could enforce triple quotes at this point.** | src/black/linegen.py | 467 |
| **# It's invalid to put closing single-character quotes on a new line.** | src/black/linegen.py | 470 |
| **# We need to find the length of the last line of the docstring** | src/black/linegen.py | 472 |
| **# to find if we can add the closing quotes to the line without** | src/black/linegen.py | 473 |
| **# exceeding the maximum line length.** | src/black/linegen.py | 474 |
| **# If docstring is one line, we don't put the closing quotes on a** | src/black/linegen.py | 475 |
| **# separate line because it looks ugly (#3320).** | src/black/linegen.py | 476 |
| **# If adding closing quotes would cause the last line to exceed** | src/black/linegen.py | 480 |
| **# the maximum line length, and the closing quote is not** | src/black/linegen.py | 481 |
| **# prefixed by a newline then put a line break before** | src/black/linegen.py | 482 |
| **# the closing quotes** | src/black/linegen.py | 483 |
| **# PEP 634** | src/black/linegen.py | 530 |
| **# We need the line string when power operators are hugging to determine if we should** | src/black/linegen.py | 563 |
| **# split the line. Default to line_str, if no power operator are present on the line.** | src/black/linegen.py | 564 |
| **# Only apply basic string preprocessing, since lines shouldn't be split here.** | src/black/linegen.py | 588 |
| **# Note: this check is only able to figure out if the first line of the** | src/black/linegen.py | 608 |
| **# *current* transformation fits in the line length.  This is true only** | src/black/linegen.py | 609 |
| **# for simple cases.  All others require running more transforms via** | src/black/linegen.py | 610 |
| **# `transform_line()`.  This check doesn't know if those would succeed.** | src/black/linegen.py | 611 |
| **# All splits failed, best effort split with no omits.** | src/black/linegen.py | 616 |
| **# This mostly happens to multiline strings that are by definition** | src/black/linegen.py | 617 |
| **# reported as not fitting a single line, as well as lines that contain** | src/black/linegen.py | 618 |
| **# trailing commas (those have to be exploded).** | src/black/linegen.py | 619 |
| **# HACK: nested functions (like _rhs) compiled by mypyc don't retain their** | src/black/linegen.py | 622 |
| **# __name__ attribute which is needed in `run_transformer` further down.** | src/black/linegen.py | 623 |
| **# Unfortunately a nested class breaks mypyc too. So a class must be created** | src/black/linegen.py | 624 |
| **# via type ... https://github.com/mypyc/mypyc/issues/884** | src/black/linegen.py | 625 |
| **# It's always safe to attempt hugging of power operations and pretty much every line** | src/black/linegen.py | 652 |
| **# could match.** | src/black/linegen.py | 653 |
| **# We are accumulating lines in `result` because we might want to abort** | src/black/linegen.py | 657 |
| **# mission and return the original line in the end, or attempt a different** | src/black/linegen.py | 658 |
| **# split altogether.** | src/black/linegen.py | 659 |
| **# using `bracket_split_build_line` will mess with whitespace, so we duplicate a** | src/black/linegen.py | 687 |
| **# couple lines from it.** | src/black/linegen.py | 688 |
| **# we could also return true if the line is too long, and the return type is longer** | src/black/linegen.py | 698 |
| **# than the param list. Or if `should_split_rhs` returns True.** | src/black/linegen.py | 699 |
| **# If there is no opening or closing_bracket that means the split failed and** | src/black/linegen.py | 803 |
| **# all content is in the tail.  Otherwise, if `head_leaves` are empty, it means** | src/black/linegen.py | 804 |
| **# the matching `opening_bracket` wasn't available on `line` anymore.** | src/black/linegen.py | 805 |
| **# Do not hug if it fits on a single line.** | src/black/linegen.py | 855 |
| **# the opening bracket is an optional paren** | src/black/linegen.py | 888 |
| **# the closing bracket is an optional paren** | src/black/linegen.py | 891 |
| **# it's not an import (optional parens are the only thing we can split on** | src/black/linegen.py | 894 |
| **# in this case; attempting a split without them is a waste of time)** | src/black/linegen.py | 895 |
| **# and we can actually remove the parens** | src/black/linegen.py | 897 |
| **# The RHSResult Omitting Optional Parens.** | src/black/linegen.py | 902 |
| **# the -1 is for the ending optional paren** | src/black/linegen.py | 910 |
| **# the omit optional parens split is preferred by some other reason** | src/black/linegen.py | 924 |
| **# For chained assignments we want to use the previous successful split** | src/black/linegen.py | 933 |
| **# If we have multiple targets, we prefer more `=`s on the head vs pushing them to** | src/black/linegen.py | 969 |
| **# the body** | src/black/linegen.py | 970 |
| **# contains matching brackets after the `=` (done by checking there is a** | src/black/linegen.py | 986 |
| **# closing bracket)** | src/black/linegen.py | 987 |
| **# the split is actually from inside the optional parens (done by checking** | src/black/linegen.py | 990 |
| **# the first line still contains the `=`)** | src/black/linegen.py | 991 |
| **# the first line is short enough** | src/black/linegen.py | 993 |
| **# contains unsplittable type ignore** | src/black/linegen.py | 996 |
| **# Ensure a trailing comma for imports and standalone function arguments** | src/black/linegen.py | 1051 |
| **# Don't add one after any comments or within type annotations** | src/black/linegen.py | 1053 |
| **# Don't add one if there's already one there** | src/black/linegen.py | 1055 |
| **# Don't add one inside parenthesized return annotations** | src/black/linegen.py | 1064 |
| **# Don't add one inside PEP 604 unions** | src/black/linegen.py | 1066 |
| **# Populate the line** | src/black/linegen.py | 1087 |
| **# This `node` has a prefix with `# fmt: off`, don't mess with parens.** | src/black/linegen.py | 1288 |
| **# The multiple context managers grammar has a different pattern, thus this is** | src/black/linegen.py | 1291 |
| **# separate from the for-loop below. This possibly wraps them in invisible parens,** | src/black/linegen.py | 1292 |
| **# and later will be removed in remove_with_parens when needed.** | src/black/linegen.py | 1293 |
| **# Fixes a bug where invisible parens are not properly stripped from** | src/black/linegen.py | 1299 |
| **# assignment statements that contain type annotations.** | src/black/linegen.py | 1300 |
| **# Fixes a bug where invisible parens are not properly wrapped around** | src/black/linegen.py | 1306 |
| **# case blocks.** | src/black/linegen.py | 1307 |
| **# Add parentheses around if guards in case blocks** | src/black/linegen.py | 1313 |
| **# Add parentheses around long tuple unpacking in assignments.** | src/black/linegen.py | 1323 |
| **# In except* (PEP 654), the star is actually part of** | src/black/linegen.py | 1363 |
| **# of the keyword. So we need to skip the insertion of** | src/black/linegen.py | 1364 |
| **# invisible parentheses to work more precisely.** | src/black/linegen.py | 1365 |
| **# A special patch for "case case:" scenario, the second occurrence** | src/black/linegen.py | 1374 |
| **# of case will be not parsed as a Python keyword.** | src/black/linegen.py | 1375 |
| **# "import from" nodes store parentheses directly as part of** | src/black/linegen.py | 1389 |
| **# the statement** | src/black/linegen.py | 1390 |
| **# make parentheses invisible** | src/black/linegen.py | 1393 |
| **# insert invisible parentheses** | src/black/linegen.py | 1397 |
| **# Since await is an expression we shouldn't remove** | src/black/linegen.py | 1415 |
| **# brackets in cases where this would change** | src/black/linegen.py | 1416 |
| **# the AST due to operator precedence.** | src/black/linegen.py | 1417 |
| **# Therefore we only aim to remove brackets around** | src/black/linegen.py | 1418 |
| **# power nodes that aren't also await expressions themselves.** | src/black/linegen.py | 1419 |
| **# https://peps.python.org/pep-0492/#updated-operator-precedence-table** | src/black/linegen.py | 1420 |
| **# N.B. We've still removed any redundant nested brackets though :)** | src/black/linegen.py | 1421 |
| **# If it's an atom, it's already wrapped in parens.** | src/black/linegen.py | 1447 |
| **# After wrapping, the with_stmt will look like this:** | src/black/linegen.py | 1462 |
| **#   with_stmt** | src/black/linegen.py | 1463 |
| **#     NAME 'with'** | src/black/linegen.py | 1464 |
| **#     atom** | src/black/linegen.py | 1465 |
| **#       LPAR ''** | src/black/linegen.py | 1466 |
| **#       testlist_gexp** | src/black/linegen.py | 1467 |
| **#         ... <-- context_managers** | src/black/linegen.py | 1468 |
| **#       /testlist_gexp** | src/black/linegen.py | 1469 |
| **#       RPAR ''** | src/black/linegen.py | 1470 |
| **#     /atom** | src/black/linegen.py | 1471 |
| **#     COLON ':'** | src/black/linegen.py | 1472 |
| **# Removing all unnecessary parentheses in with statements in one pass is a tad** | src/black/linegen.py | 1481 |
| **# complex as different variations of bracketed statements result in pretty** | src/black/linegen.py | 1482 |
| **# different parse trees:** | src/black/linegen.py | 1483 |
| **#** | src/black/linegen.py | 1484 |
| **# with (open("file")) as f:                       # this is an asexpr_test** | src/black/linegen.py | 1485 |
| **#     ...** | src/black/linegen.py | 1486 |
| **#** | src/black/linegen.py | 1487 |
| **# with (open("file") as f):                       # this is an atom containing an** | src/black/linegen.py | 1488 |
| **#     ...                                         # asexpr_test** | src/black/linegen.py | 1489 |
| **#** | src/black/linegen.py | 1490 |
| **# with (open("file")) as f, (open("file")) as f:  # this is asexpr_test, COMMA,** | src/black/linegen.py | 1491 |
| **#     ...                                         # asexpr_test** | src/black/linegen.py | 1492 |
| **#** | src/black/linegen.py | 1493 |
| **# with (open("file") as f, open("file") as f):    # an atom containing a** | src/black/linegen.py | 1494 |
| **#     ...                                         # testlist_gexp which then** | src/black/linegen.py | 1495 |
| **#                                                 # contains multiple asexpr_test(s)** | src/black/linegen.py | 1496 |
| **# This condition tries to prevent removing non-optional brackets** | src/black/linegen.py | 1538 |
| **# around a tuple, however, can be a bit overzealous so we provide** | src/black/linegen.py | 1539 |
| **# and option to skip this check for `for` and `with` statements.** | src/black/linegen.py | 1540 |
| **# these ones aren't useful to end users, but they do please fuzzers** | src/black/linegen.py | 1558 |
| **# make parentheses invisible** | src/black/linegen.py | 1569 |
| **# If the prefix of `middle` includes a type comment with** | src/black/linegen.py | 1571 |
| **# ignore annotation, then we do not remove the parentheses** | src/black/linegen.py | 1572 |
| **# Preserve comments before first paren** | src/black/linegen.py | 1577 |
| **# Strip the invisible parens from `middle` by replacing** | src/black/linegen.py | 1587 |
| **# it with the child in-between the invisible parens** | src/black/linegen.py | 1588 |
| **# Preserve comments before last paren** | src/black/linegen.py | 1591 |
| **# We're essentially checking if the body is delimited by commas and there's more** | src/black/linegen.py | 1605 |
| **# than one of them (we're excluding the trailing comma and if the delimiter priority** | src/black/linegen.py | 1606 |
| **# is still commas, that means there's more).** | src/black/linegen.py | 1607 |
| **# always explode imports** | src/black/linegen.py | 1621 |
| **# Never omit bracket pairs with trailing commas.** | src/black/linegen.py | 1667 |
| **# We need to explode on those.** | src/black/linegen.py | 1668 |
| **# Empty brackets would fail a split so treat them as "inner"** | src/black/linegen.py | 1675 |
| **# brackets (e.g. only add them to the `omit` set if another** | src/black/linegen.py | 1676 |
| **# pair of brackets was good enough.** | src/black/linegen.py | 1677 |
| **# Never omit bracket pairs with trailing commas.** | src/black/linegen.py | 1693 |
| **# We need to explode on those.** | src/black/linegen.py | 1694 |
| **# If any leaves have no parents (which _can_ occur since** | src/black/linegen.py | 1729 |
| **# `transform(line)` potentially destroys the line's underlying node** | src/black/linegen.py | 1730 |
| **# structure), then we can't proceed. Doing so would cause the below** | src/black/linegen.py | 1731 |
| **# call to `append_leaves()` to fail.** | src/black/linegen.py | 1732 |

## Function Names and Associated Docstring
```python
def _hugging_power_ops_line_to_string(line, features, mode):
"""

"""
```
```python
def transform_line(line, mode, features):
"""
Transform a `line`, potentially splitting it into many lines.

They should fit in the allotted `line_length` but might not be able to.

`features` are syntactical features that may be used in the output.
"""
```
```python
def should_split_funcdef_with_rhs(line, mode):
"""
If a funcdef has a magic trailing comma in the return type, then we should first
split the line with rhs to respect the comma.
"""
```
```python
def left_hand_split(line, _features, mode):
"""
Split line into many lines, starting with the first matching bracket pair.

Note: this usually looks weird, only use this for function definitions.
Prefer RHS otherwise.  This is why this function is not symmetrical with
:func:`right_hand_split` which also handles optional parentheses.
"""
```
```python
def right_hand_split(line, mode, features, omit):
"""
Split line into many lines, starting with the last matching bracket pair.

If the split was by optional parentheses, attempt splitting without them, too.
`omit` is a collection of closing bracket IDs that shouldn't be considered for
this split.

Note: running this function modifies `bracket_depth` on the leaves of `line`.
"""
```
```python
def _first_right_hand_split(line, omit):
"""
Split the line into head, body, tail starting with the last bracket pair.

Note: this function should not have side effects. It's relied upon by
_maybe_split_omitting_optional_parens to get an opinion whether to prefer
splitting on the right side of an assignment statement.
"""
```
```python
def _maybe_split_omitting_optional_parens(rhs, line, mode, features, omit):
"""

"""
```
```python
def _prefer_split_rhs_oop_over_rhs(rhs_oop, rhs, mode):
"""
Returns whether we should prefer the result from a split omitting optional parens
(rhs_oop) over the original (rhs).
"""
```
```python
def bracket_split_succeeded_or_raise(head, body, tail):
"""
Raise :exc:`CannotSplit` if the last left- or right-hand split failed.

Do nothing otherwise.

A left- or right-hand split is based on a pair of brackets. Content before
(and including) the opening bracket is left on one line, content inside the
brackets is put on a separate line, and finally content starting with and
following the closing bracket is put on a separate line.

Those are called `head`, `body`, and `tail`, respectively. If the split
produced the same line (all content in `head`) or ended up with an empty `body`
and the `tail` is just the closing bracket, then it's considered failed.
"""
```
```python
def bracket_split_build_line(leaves, original, opening_bracket):
"""
Return a new line with given `leaves` and respective comments from `original`.

If it's the head component, brackets will be tracked so trailing commas are
respected.

If it's the body component, the result line is one-indented inside brackets and as
such has its first leaf's prefix normalized and a trailing comma added when
expected.
"""
```
```python
def dont_increase_indentation(split_func):
"""
Normalize prefix of the first leaf in every line returned by `split_func`.

This is a decorator over relevant split functions.
"""
```
```python
def _get_last_non_comment_leaf(line):
"""

"""
```
```python
def _can_add_trailing_comma(leaf, features):
"""

"""
```
```python
def _safe_add_trailing_comma(safe, delimiter_priority, line):
"""

"""
```
```python
def delimiter_split(line, features, mode):
"""
Split according to delimiters of the highest priority.

If the appropriate Features are given, the split will add trailing commas
also in function signatures and calls that contain `*` and `**`.
"""
```
```python
def standalone_comment_split(line, features, mode):
"""
Split standalone comments from the rest of the line.
"""
```
```python
def normalize_invisible_parens(node, parens_after):
"""
Make existing optional parentheses invisible or create new ones.

`parens_after` is a set of string leaf values immediately after which parens
should be put.

Standardizes on visible parentheses for single-element tuples, and keeps
existing visible parentheses for other tuples and generator expressions.
"""
```
```python
def _normalize_import_from(parent, child, index):
"""

"""
```
```python
def remove_await_parens(node):
"""

"""
```
```python
def _maybe_wrap_cms_in_parens(node, mode, features):
"""
When enabled and safe, wrap the multiple context managers in invisible parens.

It is only safe when `features` contain Feature.PARENTHESIZED_CONTEXT_MANAGERS.
"""
```
```python
def remove_with_parens(node, parent):
"""
Recursively hide optional parens in `with` statements.
"""
```
```python
def maybe_make_parens_invisible_in_atom(node, parent, remove_brackets_around_comma):
"""
If it's safe, make the parens in the atom `node` invisible, recursively.
Additionally, remove repeated, adjacent invisible parens from the atom `node`
as they are redundant.

Returns whether the node should itself be wrapped in invisible parentheses.
"""
```
```python
def should_split_line(line, opening_bracket):
"""
Should `line` be immediately split with `delimiter_split()` after RHS?
"""
```
```python
def generate_trailers_to_omit(line, line_length):
"""
Generate sets of closing bracket IDs that should be omitted in a RHS.

Brackets can be omitted if the entire trailer up to and including
a preceding closing bracket fits in one line.

Yielded sets are cumulative (contain results of previous yields, too).  First
set is empty, unless the line should explode, in which case bracket pairs until
the one that needs to explode are omitted.
"""
```
```python
def run_transformer(line, transform, mode, features):
"""

"""
```
```python
def __init__(self, mode, features):
"""

"""
```
```python
def line(self, indent):
"""
Generate a line.

If the line is empty, only emit if it makes sense.
If the line is too long, split it first and then generate.

If any lines were generated, set up a new current_line.
"""
```
```python
def visit_default(self, node):
"""
Default `visit_*()` implementation. Recurses to children of `node`.
"""
```
```python
def visit_test(self, node):
"""
Visit an `x if y else z` test
"""
```
```python
def visit_INDENT(self, node):
"""
Increase indentation level, maybe yield a line.
"""
```
```python
def visit_DEDENT(self, node):
"""
Decrease indentation level, maybe yield a line.
"""
```
```python
def visit_stmt(self, node, keywords, parens):
"""
Visit a statement.

This implementation is shared for `if`, `while`, `for`, `try`, `except`,
`def`, `with`, `class`, `assert`, and assignments.

The relevant Python language `keywords` for a given statement will be
NAME leaves within it. This methods puts those on a separate line.

`parens` holds a set of string leaf values immediately after which
invisible parens should be put.
"""
```
```python
def visit_typeparams(self, node):
"""

"""
```
```python
def visit_typevartuple(self, node):
"""

"""
```
```python
def visit_paramspec(self, node):
"""

"""
```
```python
def visit_dictsetmaker(self, node):
"""

"""
```
```python
def visit_funcdef(self, node):
"""
Visit function definition.
"""
```
```python
def visit_match_case(self, node):
"""
Visit either a match or case statement.
"""
```
```python
def visit_suite(self, node):
"""
Visit a suite.
"""
```
```python
def visit_simple_stmt(self, node):
"""
Visit a statement without nested statements.
"""
```
```python
def visit_async_stmt(self, node):
"""
Visit `async def`, `async for`, `async with`.
"""
```
```python
def visit_decorators(self, node):
"""
Visit decorators.
"""
```
```python
def visit_power(self, node):
"""

"""
```
```python
def visit_SEMI(self, leaf):
"""
Remove a semicolon and put the other statement on a separate line.
"""
```
```python
def visit_ENDMARKER(self, leaf):
"""
End of file. Process outstanding comments and end with a newline.
"""
```
```python
def visit_STANDALONE_COMMENT(self, leaf):
"""

"""
```
```python
def visit_factor(self, node):
"""
Force parentheses between a unary op and a binary power:

-2 ** 8 -> -(2 ** 8)
"""
```
```python
def visit_tname(self, node):
"""
Add potential parentheses around types in function parameter lists to be made
into real parentheses in case the type hint is too long to fit on a line
Examples:
def foo(a: int, b: float = 7): ...

->

def foo(a: (int), b: (float) = 7): ...
"""
```
```python
def visit_STRING(self, leaf):
"""

"""
```
```python
def __post_init__(self):
"""
You are in a twisty little maze of passages.
"""
```
```python
def split_wrapper(line, features, mode):
"""

"""
```
```python
def append_to_line(leaf):
"""
Append `leaf` to current line or to new line if appending impossible.
"""
```
```python
def append_comments(leaf):
"""

"""
```
```python
def _rhs(self, line, features, mode):
"""
Wraps calls to `right_hand_split`.

The calls increasingly `omit` right-hand trailers (bracket pairs with
content), meaning the trailers get glued together to split on another
bracket pair instead.
"""
```
# src/black/lines.py



# Comments
| Comment | File | Line |
|---------|------|------|
| **# types** | src/black/lines.py | 42 |
| **# keys ordered like `leaves`** | src/black/lines.py | 56 |
| **# Note: at this point leaf.prefix should be empty except for** | src/black/lines.py | 82 |
| **# imports, for which we only preserve newlines.** | src/black/lines.py | 83 |
| **# When trailing commas or optional parens are inserted by Black for** | src/black/lines.py | 279 |
| **# consistency, comments after the previous last element are not moved** | src/black/lines.py | 280 |
| **# (they don't have to, rendering will still be correct).  So we ignore** | src/black/lines.py | 281 |
| **# trailing commas and invisible.** | src/black/lines.py | 282 |
| **# A type comment is uncollapsable if it is attached to a leaf** | src/black/lines.py | 288 |
| **# that isn't at the end of the line (since that could cause it** | src/black/lines.py | 289 |
| **# to get associated to a different argument) or if there are** | src/black/lines.py | 290 |
| **# comments before it (since that could cause it to get hidden** | src/black/lines.py | 291 |
| **# behind a comment.** | src/black/lines.py | 292 |
| **# If a 'type: ignore' is attached to the end of a line, we** | src/black/lines.py | 311 |
| **# can't split the line, because we can't know which of the** | src/black/lines.py | 312 |
| **# subexpressions the ignore was meant to apply to.** | src/black/lines.py | 313 |
| **#** | src/black/lines.py | 314 |
| **# We only want this to apply to actual physical lines from the** | src/black/lines.py | 315 |
| **# original source, though: we don't want the presence of a** | src/black/lines.py | 316 |
| **# 'type: ignore' at the end of a multiline expression to** | src/black/lines.py | 317 |
| **# justify pushing it all onto one line. Thus we** | src/black/lines.py | 318 |
| **# (unfortunately) need to check the actual source lines and** | src/black/lines.py | 319 |
| **# only report an unsplittable 'type: ignore' if this line was** | src/black/lines.py | 320 |
| **# one line in the original code.** | src/black/lines.py | 321 |
| **# Grab the first and last line numbers, skipping generated leaves** | src/black/lines.py | 323 |
| **# We look at the last two leaves since a comma or an** | src/black/lines.py | 330 |
| **# invisible paren could have been added at the end of the** | src/black/lines.py | 331 |
| **# line.** | src/black/lines.py | 332 |
| **# Comments on an optional parens wrapping a single leaf should belong to** | src/black/lines.py | 412 |
| **# the wrapped node except if it's a type comment. Pinning the comment like** | src/black/lines.py | 413 |
| **# this avoids unstable formatting caused by comment migration.** | src/black/lines.py | 414 |
| **# Always have one empty line after a module docstring** | src/black/lines.py | 570 |
| **# Maintain the semantic_leading_comment state.** | src/black/lines.py | 588 |
| **# `or before` means this comment already has an empty line before** | src/black/lines.py | 592 |
| **# `or before` means this decorator already has an empty line before** | src/black/lines.py | 597 |
| **# Consume the first leaf's extra newlines.** | src/black/lines.py | 611 |
| **# Mutate self.previous_defs, remainder of this function should be pure** | src/black/lines.py | 622 |
| **# Don't insert empty lines before the first line in the file.** | src/black/lines.py | 630 |
| **# Empty lines between attributes and methods should be preserved.** | src/black/lines.py | 645 |
| **# We shouldn't add two newlines between an indented function and** | src/black/lines.py | 663 |
| **# a dependent non-indented clause. This is to avoid issues with** | src/black/lines.py | 664 |
| **# conditional function definitions that are technically top-level** | src/black/lines.py | 665 |
| **# and therefore get two trailing newlines, but look weird and** | src/black/lines.py | 666 |
| **# inconsistent when they're followed by elif, else, etc. This is** | src/black/lines.py | 667 |
| **# worse because these functions only get *one* preceding newline** | src/black/lines.py | 668 |
| **# already.** | src/black/lines.py | 669 |
| **# Insert an empty line after a decorated stub class** | src/black/lines.py | 696 |
| **# No blank line between classes with an empty body** | src/black/lines.py | 732 |
| **# Don't inspect the previous line if it's part of the body of the previous** | src/black/lines.py | 736 |
| **# statement in the same level, we always want a blank line if there's** | src/black/lines.py | 737 |
| **# something with a body preceding.** | src/black/lines.py | 738 |
| **# In classes empty lines between attributes and methods should** | src/black/lines.py | 745 |
| **# be preserved.** | src/black/lines.py | 746 |
| **# Blank line between a block of functions (maybe with preceding** | src/black/lines.py | 749 |
| **# decorators) and a block of non-functions** | src/black/lines.py | 750 |
| **# If a user has left no space after a dummy implementation, don't insert** | src/black/lines.py | 756 |
| **# new lines. This is useful for instance for @overload or Protocols.** | src/black/lines.py | 757 |
| **# No multiline strings (MLS) present** | src/black/lines.py | 823 |
| **# Traverse the AST to examine the context of the multiline string (MLS),** | src/black/lines.py | 830 |
| **# tracking aspects such as depth and comma existence,** | src/black/lines.py | 831 |
| **# to determine whether to split the MLS or keep it together.** | src/black/lines.py | 832 |
| **# Depth (which is based on the existing bracket_depth concept)** | src/black/lines.py | 833 |
| **# is needed to determine nesting level of the MLS.** | src/black/lines.py | 834 |
| **# Includes special case for trailing commas.** | src/black/lines.py | 835 |
| **# store the leaves that contain parts of the MLS** | src/black/lines.py | 838 |
| **# Have left the level with the MLS, stop tracking commas** | src/black/lines.py | 854 |
| **# MLS was in parens with at least one comma - force split** | src/black/lines.py | 857 |
| **# Inside brackets, ignore trailing comma** | src/black/lines.py | 861 |
| **# directly after MLS/MLS-containing expression** | src/black/lines.py | 862 |
| **# >1 multiline string cannot fit on a single line - force split** | src/black/lines.py | 874 |
| **# fetch the leaf components of the MLS in the AST** | src/black/lines.py | 878 |
| **# May not have a triple-quoted multiline string at all,** | src/black/lines.py | 885 |
| **# in case of a regular string with embedded newlines and line continuations** | src/black/lines.py | 886 |
| **# We need optional parens in order to split standalone comments to their own lines** | src/black/lines.py | 941 |
| **# if there are no nested parens around the standalone comments** | src/black/lines.py | 942 |
| **# Without delimiters the optional parentheses are useless.** | src/black/lines.py | 959 |
| **# With more than one delimiter of a kind the optional parentheses read better.** | src/black/lines.py | 965 |
| **# For two context manager with statements, the optional parentheses read** | src/black/lines.py | 970 |
| **# better. In this case, `rhs.body` is the context managers part of** | src/black/lines.py | 971 |
| **# the with statement. `rhs.head` is the `with (` part on the previous** | src/black/lines.py | 972 |
| **# line.** | src/black/lines.py | 973 |
| **# Otherwise it may also read better, but we don't do it today and requires** | src/black/lines.py | 975 |
| **# careful considerations for all possible cases. See** | src/black/lines.py | 976 |
| **# https://github.com/psf/black/issues/2156.** | src/black/lines.py | 977 |
| **# A single stranded method call doesn't require optional parentheses.** | src/black/lines.py | 980 |
| **# With a single delimiter, omit if the expression starts or ends with** | src/black/lines.py | 985 |
| **# a bracket.** | src/black/lines.py | 986 |
| **# Note: we are not returning False here because a line might have *both*** | src/black/lines.py | 993 |
| **# a leading opening bracket and a trailing closing bracket.  If the** | src/black/lines.py | 994 |
| **# opening bracket doesn't match our rule, maybe the closing will.** | src/black/lines.py | 995 |
| **# don't use indexing for omitting optional parentheses;** | src/black/lines.py | 1004 |
| **# it looks weird** | src/black/lines.py | 1005 |
| **# Empty brackets don't help.** | src/black/lines.py | 1012 |
| **# Additional wrapping of a multiline string in this situation is** | src/black/lines.py | 1016 |
| **# unnecessary.** | src/black/lines.py | 1017 |
| **# There are brackets we can further split on.** | src/black/lines.py | 1040 |
| **# checked the entire string and line length wasn't exceeded** | src/black/lines.py | 1044 |
| **# There are brackets we can further split on.** | src/black/lines.py | 1062 |

## Function Names and Associated Docstring
```python
def enumerate_reversed(sequence):
"""
Like `reversed(enumerate(sequence))` if that were possible.
"""
```
```python
def append_leaves(new_line, old_line, leaves, preformatted):
"""
Append leaves (taken from @old_line) to @new_line, making sure to fix the
underlying Node structure where appropriate.

All of the leaves in @leaves are duplicated. The duplicates are then
appended to @new_line and used to replace their originals in the underlying
Node structure. Any comments attached to the old leaves are reattached to
the new leaves.

Pre-conditions:
    set(@leaves) is a subset of set(@old_line.leaves).
"""
```
```python
def is_line_short_enough(line):
"""
For non-multiline strings, return True if `line` is no longer than `line_length`.
For multiline strings, looks at the context around `line` to determine
if it should be inlined or split up.
Uses the provided `line_str` rendering, if any, otherwise computes a new one.
"""
```
```python
def can_be_split(line):
"""
Return False if the line cannot be split *for sure*.

This is not an exhaustive search but a cheap heuristic that we can use to
avoid some unfortunate formattings (mostly around wrapping unsplittable code
in unnecessary parentheses).
"""
```
```python
def can_omit_invisible_parens(rhs, line_length):
"""
Does `rhs.body` have a shape safe to reformat without optional parens around it?

Returns True for only a subset of potentially nice looking formattings but
the point is to not return false positives that end up producing lines that
are too long.
"""
```
```python
def _can_omit_opening_paren(line):
"""
See `can_omit_invisible_parens`.
"""
```
```python
def _can_omit_closing_paren(line):
"""
See `can_omit_invisible_parens`.
"""
```
```python
def line_to_string(line):
"""
Returns the string representation of @line.

WARNING: This is known to be computationally expensive.
"""
```
```python
def append(self, leaf, preformatted, track_bracket):
"""
Add a new `leaf` to the end of the line.

Unless `preformatted` is True, the `leaf` will receive a new consistent
whitespace prefix and metadata applied by :class:`BracketTracker`.
Trailing commas are maybe removed, unpacked for loop variables are
demoted from being delimiters.

Inline comments are put aside.
"""
```
```python
def append_safe(self, leaf, preformatted):
"""
Like :func:`append()` but disallow invalid standalone comment structure.

Raises ValueError when any `leaf` is appended after a standalone comment
or when a standalone comment is not the first leaf on the line.
"""
```
```python
def is_comment(self):
"""
Is this line a standalone comment?
"""
```
```python
def is_decorator(self):
"""
Is this line a decorator?
"""
```
```python
def is_import(self):
"""
Is this an import line?
"""
```
```python
def is_with_or_async_with_stmt(self):
"""
Is this a with_stmt line?
"""
```
```python
def is_class(self):
"""
Is this line a class definition?
"""
```
```python
def is_stub_class(self):
"""
Is this line a class definition with a body consisting only of "..."?
"""
```
```python
def is_def(self):
"""
Is this a function definition? (Also returns True for async defs.)
"""
```
```python
def is_stub_def(self):
"""
Is this line a function definition with a body consisting only of "..."?
"""
```
```python
def is_class_paren_empty(self):
"""
Is this a class with no base classes but using parentheses?

Those are unnecessary and should be removed.
"""
```
```python
def _is_triple_quoted_string(self):
"""
Is the line a triple quoted string?
"""
```
```python
def is_docstring(self):
"""
Is the line a docstring?
"""
```
```python
def is_chained_assignment(self):
"""
Is the line a chained assignment
"""
```
```python
def opens_block(self):
"""
Does this line open a new level of indentation.
"""
```
```python
def is_fmt_pass_converted(self):
"""
Is this line converted from fmt off/skip code?

If first_leaf_matches is not None, it only returns True if the first
leaf of converted code matches.
"""
```
```python
def contains_standalone_comments(self):
"""
If so, needs to be split before emitting.
"""
```
```python
def contains_implicit_multiline_string_with_comments(self):
"""
Chck if we have an implicit multiline string with comments on the line
"""
```
```python
def contains_uncollapsable_type_comments(self):
"""

"""
```
```python
def contains_unsplittable_type_ignore(self):
"""

"""
```
```python
def contains_multiline_strings(self):
"""

"""
```
```python
def has_magic_trailing_comma(self, closing):
"""
Return True if we have a magic trailing comma, that is when:
- there's a trailing comma here
- it's not from single-element square bracket indexing
- it's not a one-tuple
"""
```
```python
def append_comment(self, comment):
"""
Add an inline or standalone comment to the line.
"""
```
```python
def comments_after(self, leaf):
"""
Generate comments that should appear directly after `leaf`.
"""
```
```python
def remove_trailing_comma(self):
"""
Remove the trailing comma and moves the comments attached to it.
"""
```
```python
def is_complex_subscript(self, leaf):
"""
Return True iff `leaf` is part of a slice with non-trivial exprs.
"""
```
```python
def enumerate_with_length(self, is_reversed):
"""
Return an enumeration of leaves with their length.

Stops prematurely on multiline strings and standalone comments.
"""
```
```python
def clone(self):
"""

"""
```
```python
def __str__(self):
"""
Render the line.
"""
```
```python
def __bool__(self):
"""
Return True if the line has leaves or comments.
"""
```
```python
def all_lines(self):
"""

"""
```
```python
def maybe_empty_lines(self, current_line):
"""
Return the number of extra empty lines before and after the `current_line`.

This is for separating `def`, `async def` and `class` with extra empty
lines (two on module-level).
"""
```
```python
def _maybe_empty_lines(self, current_line):
"""

"""
```
```python
def _maybe_empty_lines_for_class_or_def(self, current_line, before, user_had_newline):
"""

"""
```
# src/black/mode.py


# Comments
| Comment | File | Line |
|---------|------|------|
| **# The following two feature-flags are mutually exclusive, and exactly one should be** | src/black/mode.py | 34 |
| **# set for every version of python.** | src/black/mode.py | 35 |
| **# __future__ flags** | src/black/mode.py | 51 |
| **# NOTE: string_processing requires wrap_long_dict_values_in_parens** | src/black/mode.py | 171 |
| **# for https://github.com/psf/black/issues/3117 to be fixed.** | src/black/mode.py | 172 |
| **# Many issues, see summary in https://github.com/psf/black/issues/4042** | src/black/mode.py | 187 |
| **# See issues #3452 and #4158** | src/black/mode.py | 189 |
| **# See issue #4159** | src/black/mode.py | 191 |
| **# See issue #4036 (crash), #4098, #4099 (proposed tweaks)** | src/black/mode.py | 193 |

## Function Names and Associated Docstring
```python
def supports_feature(target_versions, feature):
"""

"""
```
```python
def __contains__(self, feature):
"""
Provide `Preview.FEATURE in Mode` syntax that mirrors the ``preview`` flag.

In unstable mode, all features are enabled. In preview mode, all features
except those in UNSTABLE_FEATURES are enabled. Any features in
`self.enabled_features` are also enabled.
"""
```
```python
def get_cache_key(self):
"""

"""
```
# src/black/nodes.py



# Comments
| Comment | File | Line |
|---------|------|------|
| **# types** | src/black/nodes.py | 37 |
| **# We explicitly branch on whether a visitor exists (instead of** | src/black/nodes.py | 171 |
| **# using self.visit_default as the default arg to getattr) in order** | src/black/nodes.py | 172 |
| **# to save needing to create a bound method object and so mypyc can** | src/black/nodes.py | 173 |
| **# generate a native call to visit_default.** | src/black/nodes.py | 174 |
| **# A bit hacky: if the equal sign has whitespace, it means we** | src/black/nodes.py | 240 |
| **# previously found it's a typed argument.  So, we're using** | src/black/nodes.py | 241 |
| **# that, too.** | src/black/nodes.py | 242 |
| **# No space between typevar tuples.** | src/black/nodes.py | 250 |
| **# no space in decorators** | src/black/nodes.py | 269 |
| **# untyped function signatures or calls** | src/black/nodes.py | 276 |
| **# lambdas** | src/black/nodes.py | 281 |
| **# typed function signatures** | src/black/nodes.py | 286 |
| **# A bit hacky: if the equal sign has whitespace, it means we** | src/black/nodes.py | 295 |
| **# previously found it's a typed argument.  So, we're using that, too.** | src/black/nodes.py | 296 |
| **# type names** | src/black/nodes.py | 303 |
| **# attributes and calls** | src/black/nodes.py | 310 |
| **# single argument** | src/black/nodes.py | 322 |
| **# decorators** | src/black/nodes.py | 335 |
| **# indexing** | src/black/nodes.py | 354 |
| **# dots, but not the first one.** | src/black/nodes.py | 370 |
| **# dict unpacking** | src/black/nodes.py | 374 |
| **# unary ops** | src/black/nodes.py | 379 |
| **# Multiline docstring on the same line as the `def`.** | src/black/nodes.py | 568 |
| **# `syms.parameters` is only used in funcdefs and async_funcdefs in the Python** | src/black/nodes.py | 570 |
| **# grammar. We're safe to return True without further checks.** | src/black/nodes.py | 571 |
| **# last trailer can be an argument-less parentheses pair** | src/black/nodes.py | 665 |
| **# last trailer can be arguments** | src/black/nodes.py | 672 |
| **# and node.children[1].type == syms.argument** | src/black/nodes.py | 677 |
| **# Star expressions are also used as assignment targets in extended** | src/black/nodes.py | 741 |
| **# iterable unpacking (PEP 3132).  See what its parent is instead.** | src/black/nodes.py | 742 |
| **# Note this works for suites / simple_stmts in async def as well** | src/black/nodes.py | 759 |
| **# If there is a comment, we want to keep it.** | src/black/nodes.py | 772 |

## Function Names and Associated Docstring
```python
def whitespace(leaf):
"""
Return whitespace prefix if needed for the given `leaf`.

`complex_subscript` signals whether the given leaf is part of a subscription
which has non-trivial arguments, like arithmetic expressions or function calls.
"""
```
```python
def make_simple_prefix(nl_count, form_feed, empty_line):
"""
Generate a normalized prefix string.
"""
```
```python
def preceding_leaf(node):
"""
Return the first leaf that precedes `node`, if any.
"""
```
```python
def prev_siblings_are(node, tokens):
"""
Return if the `node` and its previous siblings match types against the provided
list of tokens; the provided `node`has its type matched against the last element in
the list.  `None` can be used as the first element to declare that the start of the
list is anchored at the start of its parent's children.
"""
```
```python
def parent_type(node):
"""
Returns:
    @node.parent.type, if @node is not None and has a parent.
        OR
    None, otherwise.
"""
```
```python
def child_towards(ancestor, descendant):
"""
Return the child of `ancestor` that contains `descendant`.
"""
```
```python
def replace_child(old_child, new_child):
"""
Side Effects:
    * If @old_child.parent is set, replace @old_child with @new_child in
    @old_child's underlying Node structure.
        OR
    * Otherwise, this function does nothing.
"""
```
```python
def container_of(leaf):
"""
Return `leaf` or one of its ancestors that is the topmost container of it.

By "container" we mean a node where `leaf` is the very first child.
"""
```
```python
def first_leaf_of(node):
"""
Returns the first leaf of the node tree.
"""
```
```python
def is_arith_like(node):
"""
Whether node is an arithmetic or a binary arithmetic expression
"""
```
```python
def is_docstring(leaf, mode):
"""

"""
```
```python
def is_empty_tuple(node):
"""
Return True if `node` holds an empty tuple.
"""
```
```python
def is_one_tuple(node):
"""
Return True if `node` holds a tuple with one element, with or without parens.
"""
```
```python
def is_tuple_containing_walrus(node):
"""
Return True if `node` holds a tuple that contains a walrus operator.
"""
```
```python
def is_one_sequence_between(opening, closing, leaves, brackets):
"""
Return True if content between `opening` and `closing` is a one-sequence.
"""
```
```python
def is_walrus_assignment(node):
"""
Return True iff `node` is of the shape ( test := test )
"""
```
```python
def is_simple_decorator_trailer(node, last):
"""
Return True iff `node` is a trailer valid in a simple decorator
"""
```
```python
def is_simple_decorator_expression(node):
"""
Return True iff `node` could be a 'dotted name' decorator

This function takes the node of the 'namedexpr_test' of the new decorator
grammar and test if it would be valid under the old decorator grammar.

The old grammar was: decorator: @ dotted_name [arguments] NEWLINE
The new grammar is : decorator: @ namedexpr_test NEWLINE
"""
```
```python
def is_yield(node):
"""
Return True if `node` holds a `yield` or `yield from` expression.
"""
```
```python
def is_vararg(leaf, within):
"""
Return True if `leaf` is a star or double star in a vararg or kwarg.

If `within` includes VARARGS_PARENTS, this applies to function signatures.
If `within` includes UNPACKING_PARENTS, it applies to right hand-side
extended iterable unpacking (PEP 3132) and additional unpacking
generalizations (PEP 448).
"""
```
```python
def is_multiline_string(leaf):
"""
Return True if `leaf` is a multiline string that actually spans many lines.
"""
```
```python
def is_parent_function_or_class(node):
"""

"""
```
```python
def is_function_or_class(node):
"""

"""
```
```python
def is_stub_suite(node):
"""
Return True if `node` is a suite with a stub body.
"""
```
```python
def is_stub_body(node):
"""
Return True if `node` is a simple statement containing an ellipsis.
"""
```
```python
def is_atom_with_invisible_parens(node):
"""
Given a `LN`, determines whether it's an atom `node` with invisible
parens. Useful in dedupe-ing and normalizing parens.
"""
```
```python
def is_empty_par(leaf):
"""

"""
```
```python
def is_empty_lpar(leaf):
"""

"""
```
```python
def is_empty_rpar(leaf):
"""

"""
```
```python
def is_import(leaf):
"""
Return True if the given leaf starts an import statement.
"""
```
```python
def is_with_or_async_with_stmt(leaf):
"""
Return True if the given leaf starts a with or async with statement.
"""
```
```python
def is_async_stmt_or_funcdef(leaf):
"""
Return True if the given leaf starts an async def/for/with statement.

Note that `async def` can be either an `async_stmt` or `async_funcdef`,
the latter is used when it has decorators.
"""
```
```python
def is_type_comment(leaf):
"""
Return True if the given leaf is a type comment. This function should only
be used for general type comments (excluding ignore annotations, which should
use `is_type_ignore_comment`). Note that general type comments are no longer
used in modern version of Python, this function may be deprecated in the future.
"""
```
```python
def is_type_ignore_comment(leaf):
"""
Return True if the given leaf is a type comment with ignore annotation.
"""
```
```python
def is_type_ignore_comment_string(value):
"""
Return True if the given string match with type comment with
ignore annotation.
"""
```
```python
def wrap_in_parentheses(parent, child):
"""
Wrap `child` in parentheses.

This replaces `child` with an atom holding the parentheses and the old
child.  That requires moving the prefix.

If `visible` is False, the leaves will be valueless (and thus invisible).
"""
```
```python
def unwrap_singleton_parenthesis(node):
"""
Returns `wrapped` if `node` is of the shape ( wrapped ).

Parenthesis can be optional. Returns None otherwise
"""
```
```python
def ensure_visible(leaf):
"""
Make sure parentheses are visible.

They could be invisible as part of some statements (see
:func:`normalize_invisible_parens` and :func:`visit_import_from`).
"""
```
```python
def is_name_token(nl):
"""

"""
```
```python
def is_lpar_token(nl):
"""

"""
```
```python
def is_rpar_token(nl):
"""

"""
```
```python
def is_string_token(nl):
"""

"""
```
```python
def is_number_token(nl):
"""

"""
```
```python
def get_annotation_type(leaf):
"""
Returns the type of annotation this leaf is part of, if any.
"""
```
```python
def is_part_of_annotation(leaf):
"""
Returns whether this leaf is part of a type annotation.
"""
```
```python
def first_leaf(node):
"""
Returns the first leaf of the ancestor node.
"""
```
```python
def last_leaf(node):
"""
Returns the last leaf of the ancestor node.
"""
```
```python
def furthest_ancestor_with_last_leaf(leaf):
"""
Returns the furthest ancestor that has this leaf node as the last leaf.
"""
```
```python
def visit(self, node):
"""
Main method to visit `node` and its children.

It tries to find a `visit_*()` method for the given `node.type`, like
`visit_simple_stmt` for Node objects or `visit_INDENT` for Leaf objects.
If no dedicated `visit_*()` method is found, chooses `visit_default()`
instead.

Then yields objects of type `T` from the selected visitor.
"""
```
```python
def visit_default(self, node):
"""
Default `visit_*()` implementation. Recurses to children of `node`.
"""
```
# src/black/numerics.py


# Comments
| Comment | File | Line |
|---------|------|------|
| **# Leave octal and binary literals alone.** | src/black/numerics.py | 51 |

## Function Names and Associated Docstring
```python
def format_hex(text):
"""
Formats a hexadecimal string like "0x12B3"
"""
```
```python
def format_scientific_notation(text):
"""
Formats a numeric string utilizing scientific notation
"""
```
```python
def format_complex_number(text):
"""
Formats a complex string like `10j`
"""
```
```python
def format_float_or_int_string(text):
"""
Formats a float string like "1.0".
"""
```
```python
def normalize_numeric_literal(leaf):
"""
Normalizes numeric (float, int, and complex) literals.

All letters used in the representation are normalized to lowercase.
"""
```
# src/black/output.py



# Comments
| Comment | File | Line |
|---------|------|------|
| **# Work around https://bugs.python.org/issue2142** | src/black/output.py | 85 |
| **# See:** | src/black/output.py | 86 |
| **# https://www.gnu.org/software/diffutils/manual/html_node/Incomplete-Lines.html** | src/black/output.py | 87 |

## Function Names and Associated Docstring
```python
def _out(message, nl):
"""

"""
```
```python
def _err(message, nl):
"""

"""
```
```python
def out(message, nl):
"""

"""
```
```python
def err(message, nl):
"""

"""
```
```python
def ipynb_diff(a, b, a_name, b_name):
"""
Return a unified diff string between each cell in notebooks `a` and `b`.
"""
```
```python
def _splitlines_no_ff(source):
"""
Split a string into lines ignoring form feed and other chars.

This mimics how the Python parser splits source code.

A simplified version of the function with the same name in Lib/ast.py
"""
```
```python
def diff(a, b, a_name, b_name):
"""
Return a unified diff string between strings `a` and `b`.
"""
```
```python
def color_diff(contents):
"""
Inject the ANSI color codes to the diff.
"""
```
```python
def dump_to_file():
"""
Dump `output` to a temporary file. Return path to the file.
"""
```
# src/black/parsing.py



# Comments
| Comment | File | Line |
|---------|------|------|
| **# No target_version specified, so try all grammars.** | src/black/parsing.py | 26 |
| **# Python 3.7-3.9** | src/black/parsing.py | 28 |
| **# Python 3.0-3.6** | src/black/parsing.py | 30 |
| **# Python 3.10+** | src/black/parsing.py | 32 |
| **# If we have to parse both, try to parse async as a keyword first** | src/black/parsing.py | 37 |
| **# Python 3.7-3.9** | src/black/parsing.py | 41 |
| **# Python 3.0-3.6** | src/black/parsing.py | 44 |
| **# Python 3.10+** | src/black/parsing.py | 47 |
| **# At least one of the above branches must have been taken, because every Python** | src/black/parsing.py | 50 |
| **# version has exactly one of the two 'ASYNC_*' flags** | src/black/parsing.py | 51 |
| **# In edge cases these are raised; and typically don't have a "faulty_line".** | src/black/parsing.py | 80 |
| **# Choose the latest version when raising the actual parsing error.** | src/black/parsing.py | 87 |
| **# TODO: support Python 4+ ;)** | src/black/parsing.py | 130 |
| **# Try to parse without type comments** | src/black/parsing.py | 141 |
| **# To normalize, we strip any leading and trailing space from** | src/black/parsing.py | 152 |
| **# each line...** | src/black/parsing.py | 153 |
| **# ...and remove any blank lines at the beginning and end of** | src/black/parsing.py | 156 |
| **# the whole string** | src/black/parsing.py | 157 |
| **# It's a quirk of history that we strip the u prefix over here. We used to** | src/black/parsing.py | 180 |
| **# rewrite the AST nodes for Python version compatibility and we never copied** | src/black/parsing.py | 181 |
| **# over the kind** | src/black/parsing.py | 182 |
| **# TypeIgnore has only one field 'lineno' which breaks this comparison** | src/black/parsing.py | 188 |
| **# Ignore nested tuples within del statements, because we may insert** | src/black/parsing.py | 201 |
| **# parentheses and they change the AST.** | src/black/parsing.py | 202 |
| **# Any standalone string, ideally this would** | src/black/parsing.py | 226 |
| **# exactly match black.nodes.is_docstring** | src/black/parsing.py | 227 |
| **# Constant strings may be indented across newlines, if they are** | src/black/parsing.py | 230 |
| **# docstrings; fold spaces after newlines when comparing. Similarly,** | src/black/parsing.py | 231 |
| **# trailing and leading space may be removed.** | src/black/parsing.py | 232 |
| **# Trailing whitespace in type comments is removed.** | src/black/parsing.py | 235 |

## Function Names and Associated Docstring
```python
def get_grammars(target_versions):
"""

"""
```
```python
def lib2to3_parse(src_txt, target_versions):
"""
Given a string with source, return the lib2to3 Node.
"""
```
```python
def matches_grammar(src_txt, grammar):
"""

"""
```
```python
def lib2to3_unparse(node):
"""
Given a lib2to3 node, return its string representation.
"""
```
```python
def _parse_single_version(src, version):
"""

"""
```
```python
def parse_ast(src):
"""

"""
```
```python
def _normalize(lineend, value):
"""

"""
```
```python
def stringify_ast(node):
"""
Simple visitor generating strings to compare ASTs by content.
"""
```
```python
def _stringify_ast_with_new_parent(node, parent_stack, new_parent):
"""

"""
```
```python
def _stringify_ast(node, parent_stack):
"""

"""
```
# src/black/ranges.py



# Comments
| Comment | File | Line |
|---------|------|------|
| **# line-ranges are 1-based** | src/black/ranges.py | 67 |
| **# Keep an index of the current search. Since the lines and lines_mappings are** | src/black/ranges.py | 116 |
| **# sorted, this makes the search complexity linear.** | src/black/ranges.py | 117 |
| **# Protect against invalid inputs.** | src/black/ranges.py | 134 |
| **# When the line falls into a changed block, expands to the whole block.** | src/black/ranges.py | 139 |
| **# When the line falls into a changed block, expands to the whole block.** | src/black/ranges.py | 146 |
| **# This is only called for top-level statements, since `visit_suite`** | src/black/ranges.py | 212 |
| **# won't visit its children nodes.** | src/black/ranges.py | 213 |
| **# We need to find the furthest ancestor with the NEWLINE as the last** | src/black/ranges.py | 221 |
| **# leaf, since a `suite` can simply be a `simple_stmt` when it puts** | src/black/ranges.py | 222 |
| **# its body on the same line. Example: `if cond: pass`.** | src/black/ranges.py | 223 |
| **# If there is a STANDALONE_COMMENT node, it means parts of the node tree** | src/black/ranges.py | 230 |
| **# have fmt on/off/skip markers. Those STANDALONE_COMMENT nodes can't** | src/black/ranges.py | 231 |
| **# be simply converted by calling str(node). So we just don't convert** | src/black/ranges.py | 232 |
| **# here.** | src/black/ranges.py | 233 |
| **# Find the semantic parent of this suite. For `async_stmt` and** | src/black/ranges.py | 236 |
| **# `async_funcdef`, the ASYNC token is defined on a separate level by the** | src/black/ranges.py | 237 |
| **# grammar.** | src/black/ranges.py | 238 |
| **# We only consider "unwrapped lines", which are divided by the NEWLINE** | src/black/ranges.py | 256 |
| **# token.** | src/black/ranges.py | 257 |
| **# The `suite` node is defined as:** | src/black/ranges.py | 260 |
| **#   match_stmt: "match" subject_expr ':' NEWLINE INDENT case_block+ DEDENT** | src/black/ranges.py | 261 |
| **# Here we need to check `subject_expr`. The `case_block+` will be** | src/black/ranges.py | 262 |
| **# checked by their own NEWLINEs.** | src/black/ranges.py | 263 |
| **# The `suite` node is defined as:** | src/black/ranges.py | 272 |
| **#   suite: simple_stmt | NEWLINE INDENT stmt+ DEDENT** | src/black/ranges.py | 273 |
| **# We will check `simple_stmt` and `stmt+` separately against the lines set** | src/black/ranges.py | 274 |
| **# NOTE: Multiple suite nodes can exist as siblings in e.g. `if_stmt`.** | src/black/ranges.py | 278 |
| **# Special case for `async_stmt` and `async_funcdef` where the ASYNC** | src/black/ranges.py | 281 |
| **# token is on the grandparent node.** | src/black/ranges.py | 282 |
| **# Consider multiple decorators as a whole block, as their** | src/black/ranges.py | 294 |
| **# newlines have different behaviors than the rest of the grammar.** | src/black/ranges.py | 295 |
| **# This can happen on the following edge cases:** | src/black/ranges.py | 316 |
| **# 1. A block of `# fmt: off/on` code except the `# fmt: on` is placed** | src/black/ranges.py | 317 |
| **#    on the end of the last line instead of on a new line.** | src/black/ranges.py | 318 |
| **# 2. A single backslash on its own line followed by a comment line.** | src/black/ranges.py | 319 |
| **# Ideally we don't want to format them when not requested, but fixing** | src/black/ranges.py | 320 |
| **# isn't easy. These cases are also badly formatted code, so it isn't** | src/black/ranges.py | 321 |
| **# too bad we reformat them.** | src/black/ranges.py | 322 |
| **# The prefix contains comments and indentation whitespaces. They are** | src/black/ranges.py | 324 |
| **# reformatted accordingly to the correct indentation level.** | src/black/ranges.py | 325 |
| **# This also means the indentation will be changed on the unchanged lines, and** | src/black/ranges.py | 326 |
| **# this is actually required to not break incremental reformatting.** | src/black/ranges.py | 327 |
| **# Remove the '\n', as STANDALONE_COMMENT will have '\n' appended when** | src/black/ranges.py | 332 |
| **# generating the formatted code.** | src/black/ranges.py | 333 |
| **# The prefix comment on the NEWLINE leaf is the trailing comment of the statement.** | src/black/ranges.py | 357 |
| **# Leaf nodes like multiline strings can occupy multiple lines.** | src/black/ranges.py | 381 |
| **# Whether this range corresponds to a changed block, or an unchanged block.** | src/black/ranges.py | 426 |
| **# matching_blocks is a sequence of "same block of code ranges", see** | src/black/ranges.py | 467 |
| **# https://docs.python.org/3/library/difflib.html#difflib.SequenceMatcher.get_matching_blocks** | src/black/ranges.py | 468 |
| **# Each block corresponds to a _LinesMapping with is_changed_block=False,** | src/black/ranges.py | 469 |
| **# and the ranges between two blocks corresponds to a _LinesMapping with** | src/black/ranges.py | 470 |
| **# is_changed_block=True,** | src/black/ranges.py | 471 |
| **# NOTE: matching_blocks is 0-based, but _LinesMapping is 1-based.** | src/black/ranges.py | 472 |

## Function Names and Associated Docstring
```python
def parse_line_ranges(line_ranges):
"""

"""
```
```python
def is_valid_line_range(lines):
"""
Returns whether the line range is valid.
"""
```
```python
def sanitized_lines(lines, src_contents):
"""
Returns the valid line ranges for the given source.

This removes ranges that are entirely outside the valid lines.

Other ranges are normalized so that the start values are at least 1 and the
end values are at most the (1-based) index of the last source line.
"""
```
```python
def adjusted_lines(lines, original_source, modified_source):
"""
Returns the adjusted line ranges based on edits from the original code.

This computes the new line ranges by diffing original_source and
modified_source, and adjust each range based on how the range overlaps with
the diffs.

Note the diff can contain lines outside of the original line ranges. This can
happen when the formatting has to be done in adjacent to maintain consistent
local results. For example:

1. def my_func(arg1, arg2,
2.             arg3,):
3.   pass

If it restricts to line 2-2, it can't simply reformat line 2, it also has
to reformat line 1:

1. def my_func(
2.     arg1,
3.     arg2,
4.     arg3,
5. ):
6.   pass

In this case, we will expand the line ranges to also include the whole diff
block.

Args:
  lines: a collection of line ranges.
  original_source: the original source.
  modified_source: the modified source.
"""
```
```python
def convert_unchanged_lines(src_node, lines):
"""
Converts unchanged lines to STANDALONE_COMMENT.

    The idea is similar to how `# fmt: on/off` is implemented. It also converts the
    nodes between those markers as a single `STANDALONE_COMMENT` leaf node with
    the unformatted code as its value. `STANDALONE_COMMENT` is a "fake" token
    that will be formatted as-is with its prefix normalized.

    Here we perform two passes:

    1. Visit the top-level statements, and convert them to a single
       `STANDALONE_COMMENT` when unchanged. This speeds up formatting when some
       of the top-level statements aren't changed.
    2. Convert unchanged "unwrapped lines" to `STANDALONE_COMMENT` nodes line by
       line. "unwrapped lines" are divided by the `NEWLINE` token. e.g. a
       multi-line statement is *one* "unwrapped line" that ends with `NEWLINE`,
       even though this statement itself can span multiple lines, and the
       tokenizer only sees the last '
' as the `NEWLINE` token.

    NOTE: During pass (2), comment prefixes and indentations are ALWAYS
    normalized even when the lines aren't changed. This is fixable by moving
    more formatting to pass (1). However, it's hard to get it correct when
    incorrect indentations are used. So we defer this to future optimizations.
    
"""
```
```python
def _contains_standalone_comment(node):
"""

"""
```
```python
def _convert_unchanged_line_by_line(node, lines_set):
"""
Converts unchanged to STANDALONE_COMMENT line by line.
"""
```
```python
def _convert_node_to_standalone_comment(node):
"""
Convert node to STANDALONE_COMMENT by modifying the tree inline.
"""
```
```python
def _convert_nodes_to_standalone_comment(nodes):
"""
Convert nodes to STANDALONE_COMMENT by modifying the tree inline.
"""
```
```python
def _leaf_line_end(leaf):
"""
Returns the line number of the leaf node's last line.
"""
```
```python
def _get_line_range(node_or_nodes):
"""
Returns the line range of this node or list of nodes.
"""
```
```python
def _calculate_lines_mappings(original_source, modified_source):
"""
Returns a sequence of _LinesMapping by diffing the sources.

For example, given the following diff:
    import re
  - def func(arg1,
  -   arg2, arg3):
  + def func(arg1, arg2, arg3):
      pass
It returns the following mappings:
  original -> modified
   (1, 1)  ->  (1, 1), is_changed_block=False (the "import re" line)
   (2, 3)  ->  (2, 2), is_changed_block=True (the diff)
   (4, 4)  ->  (3, 3), is_changed_block=False (the "pass" line)

You can think of this visually as if it brings up a side-by-side diff, and tries
to map the line ranges from the left side to the right side:

  (1, 1)->(1, 1)    1. import re          1. import re
  (2, 3)->(2, 2)    2. def func(arg1,     2. def func(arg1, arg2, arg3):
                    3.   arg2, arg3):
  (4, 4)->(3, 3)    4.   pass             3.   pass

Args:
  original_source: the original source.
  modified_source: the modified source.
"""
```
```python
def _find_lines_mapping_index(original_line, lines_mappings, start_index):
"""
Returns the original index of the lines mappings for the original line.
"""
```
```python
def __init__(self, lines_set):
"""

"""
```
```python
def visit_simple_stmt(self, node):
"""

"""
```
```python
def visit_suite(self, node):
"""

"""
```
# src/black/report.py


# Comments
| Comment | File | Line |
|---------|------|------|
| **# According to http://tldp.org/LDP/abs/html/exitcodes.html starting with** | src/black/report.py | 70 |
| **# 126 we have special return codes reserved by the shell.** | src/black/report.py | 71 |

## Function Names and Associated Docstring
```python
def done(self, src, changed):
"""
Increment the counter for successful reformatting. Write out a message.
"""
```
```python
def failed(self, src, message):
"""
Increment the counter for failed reformatting. Write out a message.
"""
```
```python
def path_ignored(self, path, message):
"""

"""
```
```python
def return_code(self):
"""
Return the exit code that the app should use.

This considers the current state of changed files and failures:
- if there were any failures, return 123;
- if any files were changed and --check is being used, return 1;
- otherwise return 0.
"""
```
```python
def __str__(self):
"""
Render a color report of the current state.

Use `click.unstyle` to remove colors.
"""
```
# src/black/rusty.py


## Function Names and Associated Docstring
```python
def __init__(self, e):
"""

"""
```
```python
def ok(self):
"""

"""
```
```python
def err(self):
"""

"""
```
# src/black/schema.py



## Function Names and Associated Docstring
```python
def get_schema(tool_name):
"""
Get the stored complete schema for black's settings.
"""
```
# src/black/strings.py



# Comments
| Comment | File | Line |
|---------|------|------|
| **# https://www.python.org/dev/peps/pep-0257/#handling-docstring-indentation** | src/black/strings.py | 66 |
| **# Determine minimum indentation (first line doesn't count):** | src/black/strings.py | 70 |
| **# Remove indentation (first line is special):** | src/black/strings.py | 76 |
| **# Python syntax guarantees max 2 prefixes and that one of them is "r"** | src/black/strings.py | 155 |
| **# Re(gex) does actually cache patterns internally but this still improves** | src/black/strings.py | 161 |
| **# performance on a long list literal of strings by 5-9% since lru_cache's** | src/black/strings.py | 162 |
| **# caching overhead is much lower.** | src/black/strings.py | 163 |
| **# There's at least one unescaped new_quote in this raw string** | src/black/strings.py | 199 |
| **# so converting is impossible** | src/black/strings.py | 200 |
| **# Do not introduce or remove backslashes in raw strings** | src/black/strings.py | 203 |
| **# remove unnecessary escapes** | src/black/strings.py | 206 |
| **# Consider the string without unnecessary escapes as the original** | src/black/strings.py | 209 |
| **# Do not introduce backslashes in interpolated expressions** | src/black/strings.py | 226 |
| **# edge case:** | src/black/strings.py | 230 |
| **# \u** | src/black/strings.py | 258 |
| **# \U** | src/black/strings.py | 261 |
| **# \x** | src/black/strings.py | 264 |
| **# \N{}** | src/black/strings.py | 268 |
| **# Fast path for a line consisting of only ASCII characters** | src/black/strings.py | 309 |

## Function Names and Associated Docstring
```python
def sub_twice(regex, replacement, original):
"""
Replace `regex` with `replacement` twice on `original`.

This is used by string normalization to perform replaces on
overlapping matches.
"""
```
```python
def has_triple_quotes(string):
"""
Returns:
    True iff @string starts with three quotation characters.
"""
```
```python
def lines_with_leading_tabs_expanded(s):
"""
Splits string into lines and expands only leading tabs (following the normal
Python rules)
"""
```
```python
def fix_docstring(docstring, prefix):
"""

"""
```
```python
def get_string_prefix(string):
"""
Pre-conditions:
    * assert_is_leaf_string(@string)

Returns:
    @string's prefix (e.g. '', 'r', 'f', or 'rf').
"""
```
```python
def assert_is_leaf_string(string):
"""
Checks the pre-condition that @string has the format that you would expect
of `leaf.value` where `leaf` is some Leaf such that `leaf.type ==
token.STRING`. A more precise description of the pre-conditions that are
checked are listed below.

Pre-conditions:
    * @string starts with either ', ", <prefix>', or <prefix>" where
    `set(<prefix>)` is some subset of `set(STRING_PREFIX_CHARS)`.
    * @string ends with a quote character (' or ").

Raises:
    AssertionError(...) if the pre-conditions listed above are not
    satisfied.
"""
```
```python
def normalize_string_prefix(s):
"""
Make all string prefixes lowercase.
"""
```
```python
def _cached_compile(pattern):
"""

"""
```
```python
def normalize_string_quotes(s):
"""
Prefer double quotes but only if it doesn't cause more escaping.

Adds or removes backslashes as appropriate. Doesn't parse and fix
strings nested in f-strings.
"""
```
```python
def normalize_unicode_escape_sequences(leaf):
"""
Replace hex codes in Unicode escape sequences with lowercase representation.
"""
```
```python
def char_width(char):
"""
Return the width of a single character as it would be displayed in a
terminal or editor (which respects Unicode East Asian Width).

Full width characters are counted as 2, while half width characters are
counted as 1.  Also control characters are counted as 0.
"""
```
```python
def str_width(line_str):
"""
Return the width of `line_str` as it would be displayed in a terminal
or editor (which respects Unicode East Asian Width).

You could utilize this function to determine, for example, if a string
is too wide to display in a terminal or editor.
"""
```
```python
def count_chars_in_width(line_str, max_width):
"""
Count the number of characters in `line_str` that would fit in a
terminal or editor of `max_width` (which respects Unicode East Asian
Width).
"""
```
```python
def replace(m):
"""

"""
```
# src/black/trans.py



# Comments
| Comment | File | Line |
|---------|------|------|
| **# types** | src/black/trans.py | 62 |
| **# Performance optimization to avoid unnecessary Leaf clones and other ops.** | src/black/trans.py | 90 |
| **# Brackets and parentheses indicate calls, subscripts, etc. ...** | src/black/trans.py | 98 |
| **# basically stuff that doesn't count as "simple". Only a NAME lookup** | src/black/trans.py | 99 |
| **# or dotted lookup (eg. NAME.NAME) is OK.** | src/black/trans.py | 100 |
| **# An operand is considered "simple" if's a NAME, a numeric CONSTANT, a simple** | src/black/trans.py | 115 |
| **# lookup (see above), with or without a preceding unary operator.** | src/black/trans.py | 116 |
| **# kind is always one as bases with a preceding unary op will be checked** | src/black/trans.py | 123 |
| **# for simplicity starting from the next token (so it'll hit the check** | src/black/trans.py | 124 |
| **# above).** | src/black/trans.py | 125 |
| **# We have to be careful to make a new line properly:** | src/black/trans.py | 148 |
| **# - bracket related metadata must be maintained (handled by Line.append)** | src/black/trans.py | 149 |
| **# - comments need to copied over, updating the leaf IDs they're attached to** | src/black/trans.py | 150 |
| **# If the current token isn't disallowed, we'll assume this is** | src/black/trans.py | 171 |
| **# simple as only the disallowed tokens are semantically** | src/black/trans.py | 172 |
| **# attached to this lookup expression we're checking. Also,** | src/black/trans.py | 173 |
| **# stop early if we hit the 'for' bit of a comprehension.** | src/black/trans.py | 174 |
| **# If the current token isn't disallowed, we'll assume this is simple as** | src/black/trans.py | 219 |
| **# only the disallowed tokens are semantically attached to this lookup** | src/black/trans.py | 220 |
| **# expression we're checking. Also, stop early if we hit the 'for' bit** | src/black/trans.py | 221 |
| **# of a comprehension.** | src/black/trans.py | 222 |
| **# Ideally this would be a dataclass, but unfortunately mypyc breaks when used with** | src/black/trans.py | 280 |
| **# `abc.ABC`.** | src/black/trans.py | 281 |
| **# Optimization to avoid calling `self.do_match(...)` when the line does** | src/black/trans.py | 331 |
| **# not contain any string.** | src/black/trans.py | 332 |
| **# Let's check if the string group contains an inline comment** | src/black/trans.py | 479 |
| **# If we have a comment inline, we don't merge the strings** | src/black/trans.py | 480 |
| **# Advance to the next non-STRING leaf.** | src/black/trans.py | 494 |
| **# Advance to the next non-STRING leaf.** | src/black/trans.py | 501 |
| **# Chain the errors together using `__cause__`.** | src/black/trans.py | 536 |
| **# A dict of {string_idx: tuple[num_of_strings, string_leaf]}.** | src/black/trans.py | 605 |
| **# Build the final line ('new_line') that this method will later return.** | src/black/trans.py | 618 |
| **# If the string group is wrapped inside an Atom node, we must make sure** | src/black/trans.py | 653 |
| **# to later replace that Atom with our new (merged) string leaf.** | src/black/trans.py | 654 |
| **# We will place BREAK_MARK in between every two substrings that we** | src/black/trans.py | 657 |
| **# merge. We will then later go through our final result and use the** | src/black/trans.py | 658 |
| **# various instances of BREAK_MARK we find to add the right values to** | src/black/trans.py | 659 |
| **# the custom split map.** | src/black/trans.py | 660 |
| **# We don't want to toggle visible quotes in debug f-strings, as** | src/black/trans.py | 688 |
| **# that would modify the AST** | src/black/trans.py | 689 |
| **# After quotes toggling, quotes in expressions won't be escaped** | src/black/trans.py | 691 |
| **# because quotes can't be reused in f-strings. So we can simply** | src/black/trans.py | 692 |
| **# let the escaping logic below run without knowing f-string** | src/black/trans.py | 693 |
| **# expressions.** | src/black/trans.py | 694 |
| **# Holds the CustomSplit objects that will later be added to the custom** | src/black/trans.py | 703 |
| **# split map.** | src/black/trans.py | 704 |
| **# Temporary storage for the 'has_prefix' part of the CustomSplit objects.** | src/black/trans.py | 707 |
| **# Sets the 'prefix' variable. This is the prefix that the final merged** | src/black/trans.py | 710 |
| **# string will have.** | src/black/trans.py | 711 |
| **# The next loop merges the string group. The final string will be** | src/black/trans.py | 722 |
| **# contained in 'S'.** | src/black/trans.py | 723 |
| **#** | src/black/trans.py | 724 |
| **# The following convenience variables are used:** | src/black/trans.py | 725 |
| **#** | src/black/trans.py | 726 |
| **#   S: string** | src/black/trans.py | 727 |
| **#   NS: naked string** | src/black/trans.py | 728 |
| **#   SS: next string** | src/black/trans.py | 729 |
| **#   NSS: naked next string** | src/black/trans.py | 730 |
| **# If this is an f-string group but this substring is not prefixed** | src/black/trans.py | 741 |
| **# with 'f'...** | src/black/trans.py | 742 |
| **# Then we must escape any braces contained in this substring.** | src/black/trans.py | 744 |
| **# Take a note on the index of the non-STRING leaf.** | src/black/trans.py | 757 |
| **# Fill the 'custom_splits' list with the appropriate CustomSplit objects.** | src/black/trans.py | 764 |
| **# If not all children of the atom node are merged (this can happen** | src/black/trans.py | 779 |
| **# when there is a standalone comment in the middle) ...** | src/black/trans.py | 780 |
| **# We need to replace the old STRING leaves with the new string leaf.** | src/black/trans.py | 782 |
| **# Else replace the atom node with the new string leaf.** | src/black/trans.py | 789 |
| **# We first check for "inner" stand-alone comments (i.e. stand-alone** | src/black/trans.py | 819 |
| **# comments that have a string leaf before them AND after them).** | src/black/trans.py | 820 |
| **# If the string group is trailed by a comma, we count the** | src/black/trans.py | 844 |
| **# comments trailing the comma to be one of the string group's** | src/black/trans.py | 845 |
| **# comments.** | src/black/trans.py | 846 |
| **# Should be a string...** | src/black/trans.py | 916 |
| **# If this is a "pointless" string...** | src/black/trans.py | 920 |
| **# Should be preceded by a non-empty LPAR...** | src/black/trans.py | 928 |
| **# That LPAR should NOT be preceded by a function name or a closing** | src/black/trans.py | 936 |
| **# bracket (which could be a function which returns a function or a** | src/black/trans.py | 937 |
| **# list/dictionary that contains a function)...** | src/black/trans.py | 938 |
| **# Skip the string trailer, if one exists.** | src/black/trans.py | 946 |
| **# if the leaves in the parsed string include a PERCENT, we need to** | src/black/trans.py | 950 |
| **# make sure the initial LPAR is NOT preceded by an operator with** | src/black/trans.py | 951 |
| **# higher or equal precedence to PERCENT** | src/black/trans.py | 952 |
| **# mypy can't quite follow unless we name this** | src/black/trans.py | 954 |
| **# only unary PLUS/MINUS** | src/black/trans.py | 973 |
| **# Should be followed by a non-empty RPAR...** | src/black/trans.py | 981 |
| **# That RPAR should NOT be followed by anything with higher** | src/black/trans.py | 987 |
| **# precedence than PERCENT** | src/black/trans.py | 988 |
| **# Should not strip parentheses which have comments attached** | src/black/trans.py | 1019 |
| **# to them.** | src/black/trans.py | 1020 |
| **# We need to sort the indices, since string_idx and its matching** | src/black/trans.py | 1042 |
| **# rpar_idx may not come in order, e.g. in** | src/black/trans.py | 1043 |
| **# `("outer" % ("inner".join(items)))`, the "inner" string's** | src/black/trans.py | 1044 |
| **# string_idx is smaller than "outer" string's rpar_idx.** | src/black/trans.py | 1045 |
| **# replace comments** | src/black/trans.py | 1055 |
| **# Append the leaves after the last idx:** | src/black/trans.py | 1063 |
| **# We use the shorthand "WMA4" in comments to abbreviate "We must** | src/black/trans.py | 1196 |
| **# account for". When giving examples, we use STRING to mean some/any** | src/black/trans.py | 1197 |
| **# valid string.** | src/black/trans.py | 1198 |
| **#** | src/black/trans.py | 1199 |
| **# Finally, we use the following convenience variables:** | src/black/trans.py | 1200 |
| **#** | src/black/trans.py | 1201 |
| **#   P:  The leaf that is before the target string leaf.** | src/black/trans.py | 1202 |
| **#   N:  The leaf that is after the target string leaf.** | src/black/trans.py | 1203 |
| **#   NN: The leaf that is after N.** | src/black/trans.py | 1204 |
| **# WMA4 the whitespace at the beginning of the line.** | src/black/trans.py | 1206 |
| **# If the previous leaf is an empty LPAR placeholder, we should skip it.** | src/black/trans.py | 1216 |
| **# WMA4 a space and a string operator (e.g. `+ STRING` or `== STRING`).** | src/black/trans.py | 1221 |
| **# WMA4 a space, a comma, and a closing bracket [e.g. `), STRING`].** | src/black/trans.py | 1225 |
| **# This conditional branch is meant to handle dictionary keys,** | src/black/trans.py | 1229 |
| **# variable assignments, 'return STRING' statement lines, and** | src/black/trans.py | 1230 |
| **# 'else STRING' ternary expression lines.** | src/black/trans.py | 1231 |
| **# WMA4 a single space.** | src/black/trans.py | 1233 |
| **# WMA4 the lengths of any leaves that came before that space,** | src/black/trans.py | 1236 |
| **# but after any closing bracket before that space.** | src/black/trans.py | 1237 |
| **# If the next leaf is an empty RPAR placeholder, we should skip it.** | src/black/trans.py | 1246 |
| **# WMA4 a single comma at the end of the string (e.g `STRING,`).** | src/black/trans.py | 1250 |
| **# This conditional branch is meant to handle method calls invoked** | src/black/trans.py | 1257 |
| **# off of a string literal up to and including the LPAR character.** | src/black/trans.py | 1258 |
| **# WMA4 the '.' character.** | src/black/trans.py | 1260 |
| **# WMA4 the left parenthesis character.** | src/black/trans.py | 1267 |
| **# WMA4 the length of the method's name.** | src/black/trans.py | 1270 |
| **# WMA4 two spaces before the '#' character.** | src/black/trans.py | 1277 |
| **# WMA4 the length of the inline comment.** | src/black/trans.py | 1280 |
| **# The line must start with a string.** | src/black/trans.py | 1297 |
| **# If the string is an immediate child of a list/set/tuple literal...** | src/black/trans.py | 1306 |
| **# And the string is surrounded by commas (or is the first/last child)...** | src/black/trans.py | 1311 |
| **# If it's an atom string, we need to check the parent atom's siblings.** | src/black/trans.py | 1319 |
| **# if we're in a string part of the f-string, ignore escaped curly braces** | src/black/trans.py | 1343 |
| **# we've made it back out of the expression! yield the span** | src/black/trans.py | 1356 |
| **# if we're in an expression part of the f-string, fast-forward through strings** | src/black/trans.py | 1362 |
| **# note that backslashes are not legal in the expression portion of f-strings** | src/black/trans.py | 1363 |
| **# The first two leaves MAY be the 'not in' keywords...** | src/black/trans.py | 1457 |
| **# Else the first leaf MAY be a string operator symbol or the 'in' keyword...** | src/black/trans.py | 1465 |
| **# The next/first leaf MAY be an empty LPAR...** | src/black/trans.py | 1473 |
| **# The next/first leaf MUST be a string...** | src/black/trans.py | 1477 |
| **# Skip the string trailer, if one exists.** | src/black/trans.py | 1483 |
| **# That string MAY be followed by an empty RPAR...** | src/black/trans.py | 1487 |
| **# That string / empty RPAR leaf MAY be followed by a comma...** | src/black/trans.py | 1491 |
| **# But no more leaves are allowed...** | src/black/trans.py | 1495 |
| **# We MAY choose to drop the 'f' prefix from substrings that don't** | src/black/trans.py | 1518 |
| **# contain any f-expressions, but ONLY if the original f-string** | src/black/trans.py | 1519 |
| **# contains at least one f-expression. Otherwise, we will alter the AST** | src/black/trans.py | 1520 |
| **# of the program.** | src/black/trans.py | 1521 |
| **# --- Calculate Max Break Width (for string value)** | src/black/trans.py | 1566 |
| **# We start with the line length limit** | src/black/trans.py | 1567 |
| **# The last index of a string of length N is N-1.** | src/black/trans.py | 1569 |
| **# Leading whitespace is not present in the string value (e.g. Leaf.value).** | src/black/trans.py | 1571 |
| **# Check if StringMerger registered any custom splits.** | src/black/trans.py | 1580 |
| **# We use them ONLY if none of them would produce lines that exceed the** | src/black/trans.py | 1582 |
| **# line limit.** | src/black/trans.py | 1583 |
| **# Temporary storage for the remaining chunk of the string line that** | src/black/trans.py | 1589 |
| **# can't fit onto the line currently being constructed.** | src/black/trans.py | 1590 |
| **# Custom User Split (manual)** | src/black/trans.py | 1607 |
| **# Algorithmic Split (automatic)** | src/black/trans.py | 1611 |
| **# If we are unable to algorithmically determine a good split** | src/black/trans.py | 1618 |
| **# and this string has custom splits registered to it, we** | src/black/trans.py | 1619 |
| **# fall back to using them--which means we have to start** | src/black/trans.py | 1620 |
| **# over from the beginning.** | src/black/trans.py | 1621 |
| **# Otherwise, we stop splitting here.** | src/black/trans.py | 1629 |
| **# --- Construct `next_value`** | src/black/trans.py | 1634 |
| **# HACK: The following 'if' statement is a hack to fix the custom** | src/black/trans.py | 1637 |
| **# breakpoint index in the case of either: (a) substrings that were** | src/black/trans.py | 1638 |
| **# f-strings but will have the 'f' prefix removed OR (b) substrings** | src/black/trans.py | 1639 |
| **# that were not f-strings but will now become f-strings because of** | src/black/trans.py | 1640 |
| **# redundant use of the 'f' prefix (i.e. none of the substrings** | src/black/trans.py | 1641 |
| **# contain f-expressions but one or more of them had the 'f' prefix** | src/black/trans.py | 1642 |
| **# anyway; in which case, we will prepend 'f' to _all_ substrings).** | src/black/trans.py | 1643 |
| **#** | src/black/trans.py | 1644 |
| **# There is probably a better way to accomplish what is being done** | src/black/trans.py | 1645 |
| **# here...** | src/black/trans.py | 1646 |
| **#** | src/black/trans.py | 1647 |
| **# If this substring is an f-string, we _could_ remove the 'f'** | src/black/trans.py | 1648 |
| **# prefix, and the current custom split did NOT originally use a** | src/black/trans.py | 1649 |
| **# prefix...** | src/black/trans.py | 1650 |
| **# `next_value == prefix + QUOTE` happens when the custom** | src/black/trans.py | 1655 |
| **# split is an empty string.** | src/black/trans.py | 1656 |
| **# Then `csplit.break_idx` will be off by one after removing** | src/black/trans.py | 1661 |
| **# the 'f' prefix.** | src/black/trans.py | 1662 |
| **# --- Construct `next_leaf`** | src/black/trans.py | 1669 |
| **# --- Construct `next_line`** | src/black/trans.py | 1674 |
| **# NOTE: I could not find a test case that verifies that the following** | src/black/trans.py | 1691 |
| **# line is actually necessary, but it seems to be. Otherwise we risk** | src/black/trans.py | 1692 |
| **# not normalizing the last substring, right?** | src/black/trans.py | 1693 |
| **# If there are any leaves to the right of the target string...** | src/black/trans.py | 1699 |
| **# We use `temp_value` here to determine how long the last line** | src/black/trans.py | 1701 |
| **# would be if we were to append all the leaves to the right of the** | src/black/trans.py | 1702 |
| **# target string to the last string line.** | src/black/trans.py | 1703 |
| **# Try to fit them all on the same line with the last substring...** | src/black/trans.py | 1710 |
| **# Otherwise, place the last substring on one line and everything** | src/black/trans.py | 1718 |
| **# else on a line below that...** | src/black/trans.py | 1719 |
| **# Else the target string was the last leaf...** | src/black/trans.py | 1727 |
| **# True - the previous backslash was unescaped** | src/black/trans.py | 1740 |
| **# False - the previous backslash was escaped *or* there was no backslash** | src/black/trans.py | 1741 |
| **# malformed nameescape expression?** | src/black/trans.py | 1759 |
| **# should have been detected by AST parsing earlier...** | src/black/trans.py | 1760 |
| **# First, we check all indices BELOW @max_break_idx.** | src/black/trans.py | 1851 |
| **# If that fails, we check all indices ABOVE @max_break_idx.** | src/black/trans.py | 1857 |
| **#** | src/black/trans.py | 1858 |
| **# If we are able to find a valid index here, the next line is going** | src/black/trans.py | 1859 |
| **# to be longer than the specified line length, but it's probably** | src/black/trans.py | 1860 |
| **# better than doing nothing at all.** | src/black/trans.py | 1861 |
| **# If the string has neither spaces nor East Asian stops...** | src/black/trans.py | 1991 |
| **# And will still violate the line length limit when split...** | src/black/trans.py | 1995 |
| **# And has no associated custom splits...** | src/black/trans.py | 1998 |
| **# Then we should NOT put this string on its own line.** | src/black/trans.py | 2000 |
| **# If this line is a part of a return/yield statement and the first leaf** | src/black/trans.py | 2021 |
| **# contains either the "return" or "yield" keywords...** | src/black/trans.py | 2022 |
| **# The next visible leaf MUST contain a string...** | src/black/trans.py | 2029 |
| **# If this line is a part of a ternary expression and the first leaf** | src/black/trans.py | 2046 |
| **# contains the "else" keyword...** | src/black/trans.py | 2047 |
| **# The next visible leaf MUST contain a string...** | src/black/trans.py | 2056 |
| **# If this line is a part of an assert statement and the first leaf** | src/black/trans.py | 2073 |
| **# contains the "assert" keyword...** | src/black/trans.py | 2074 |
| **# We MUST find a comma...** | src/black/trans.py | 2079 |
| **# That comma MUST be followed by a string...** | src/black/trans.py | 2083 |
| **# Skip the string trailer, if one exists.** | src/black/trans.py | 2087 |
| **# But no more leaves are allowed...** | src/black/trans.py | 2091 |
| **# If this line is a part of an expression statement or is a function** | src/black/trans.py | 2108 |
| **# argument AND the first leaf contains a variable name...** | src/black/trans.py | 2109 |
| **# We MUST find either an '=' or '+=' symbol...** | src/black/trans.py | 2117 |
| **# That symbol MUST be followed by a string...** | src/black/trans.py | 2121 |
| **# Skip the string trailer, if one exists.** | src/black/trans.py | 2125 |
| **# The next leaf MAY be a comma iff this line is a part** | src/black/trans.py | 2129 |
| **# of a function argument...** | src/black/trans.py | 2130 |
| **# But no more leaves are allowed...** | src/black/trans.py | 2138 |
| **# If this line is a part of a dictionary key assignment or lambda expression...** | src/black/trans.py | 2155 |
| **# We MUST find a colon, it can either be dict's or lambda's colon...** | src/black/trans.py | 2161 |
| **# That colon MUST be followed by a string...** | src/black/trans.py | 2165 |
| **# Skip the string trailer, if one exists.** | src/black/trans.py | 2169 |
| **# That string MAY be followed by a comma...** | src/black/trans.py | 2173 |
| **# But no more leaves are allowed...** | src/black/trans.py | 2177 |
| **# --- First Line** | src/black/trans.py | 2205 |
| **# We have to remember to account for (possibly invisible) LPAR and RPAR** | src/black/trans.py | 2209 |
| **# leaves that already wrapped the target string. If these leaves do** | src/black/trans.py | 2210 |
| **# exist, we will replace them with our own LPAR and RPAR leaves.** | src/black/trans.py | 2211 |
| **# We throw inline comments that were originally to the right of the** | src/black/trans.py | 2227 |
| **# target string to the top line. They will now be shown to the right of** | src/black/trans.py | 2228 |
| **# the LPAR.** | src/black/trans.py | 2229 |
| **# --- Middle (String) Line** | src/black/trans.py | 2236 |
| **# We only need to yield one (possibly too long) string line, since the** | src/black/trans.py | 2237 |
| **# `StringSplitter` will break it down further if necessary.** | src/black/trans.py | 2238 |
| **# Special case for lambda expressions as dict's value, e.g.:** | src/black/trans.py | 2264 |
| **#     my_dict = {** | src/black/trans.py | 2265 |
| **#        "key": lambda x: f"formatted: {x},** | src/black/trans.py | 2266 |
| **#     }** | src/black/trans.py | 2267 |
| **# After wrapping the dict's value with parentheses, the string is** | src/black/trans.py | 2268 |
| **# followed by a RPAR but its opening bracket is lambda's, not** | src/black/trans.py | 2269 |
| **# the string's:** | src/black/trans.py | 2270 |
| **#        "key": (lambda x: f"formatted: {x}),** | src/black/trans.py | 2271 |
| **# --- Last Line** | src/black/trans.py | 2286 |
| **# If the target string ended with a comma, we place this comma to the** | src/black/trans.py | 2297 |
| **# right of the RPAR on the last line.** | src/black/trans.py | 2298 |
| **# String Parser States** | src/black/trans.py | 2339 |
| **# Lookup Table for Next State** | src/black/trans.py | 2349 |
| **# A string trailer may start with '.' OR '%'.** | src/black/trans.py | 2351 |
| **# A '.' MUST be followed by an attribute or method name.** | src/black/trans.py | 2355 |
| **# A method name MUST be followed by an '(', whereas an attribute name** | src/black/trans.py | 2357 |
| **# is the last symbol in the string trailer.** | src/black/trans.py | 2358 |
| **# A '%' symbol can be followed by an '(' or a single argument (e.g. a** | src/black/trans.py | 2361 |
| **# string or variable name).** | src/black/trans.py | 2362 |
| **# If a '%' symbol is followed by a single argument, that argument is** | src/black/trans.py | 2365 |
| **# the last leaf in the string trailer.** | src/black/trans.py | 2366 |
| **# If present, a ')' symbol is the last symbol in a string trailer.** | src/black/trans.py | 2368 |
| **# (NOTE: LPARS and nested RPARS are not included in this lookup table,** | src/black/trans.py | 2369 |
| **# since they are treated as a special case by the parsing logic in this** | src/black/trans.py | 2370 |
| **# classes' implementation.)** | src/black/trans.py | 2371 |
| **# We ignore empty LPAR or RPAR leaves.** | src/black/trans.py | 2410 |
| **# The LPAR parser state is a special case. We will return True until we** | src/black/trans.py | 2420 |
| **# find the matching RPAR token.** | src/black/trans.py | 2421 |
| **# Otherwise, we use a lookup table to determine the next state.** | src/black/trans.py | 2427 |
| **# If the lookup table matches the current state to the next** | src/black/trans.py | 2429 |
| **# token, we use the lookup table.** | src/black/trans.py | 2430 |
| **# Otherwise, we check if a the current state was assigned a** | src/black/trans.py | 2434 |
| **# default.** | src/black/trans.py | 2435 |
| **# If no default has been assigned, then this parser has a logic** | src/black/trans.py | 2438 |
| **# error.** | src/black/trans.py | 2439 |

## Function Names and Associated Docstring
```python
def TErr(err_msg):
"""
(T)ransform Err

Convenience function used when working with the TResult type.
"""
```
```python
def hug_power_op(line, features, mode):
"""
A transformer which normalizes spacing around power operators.
"""
```
```python
def original_is_simple_lookup_func(line, index, step):
"""

"""
```
```python
def handle_is_simple_look_up_prev(line, index, disallowed):
"""
Handling the determination of is_simple_lookup for the lines prior to the doublestar
token. This is required because of the need to isolate the chained expression
to determine the bracket or parenthesis belong to the single expression.
"""
```
```python
def handle_is_simple_lookup_forward(line, index, disallowed):
"""
Handling decision is_simple_lookup for the lines behind the doublestar token.
This function is simplified to keep consistent with the prior logic and the forward
case are more straightforward and do not need to care about chained expressions.
"""
```
```python
def is_expression_chained(chained_leaves):
"""
Function to determine if the variable is a chained call.
(e.g., foo.lookup, foo().lookup, (foo.lookup())) will be recognized as chained call)
"""
```
```python
def iter_fexpr_spans(s):
"""
Yields spans corresponding to expressions in a given f-string.
Spans are half-open ranges (left inclusive, right exclusive).
Assumes the input string is a valid f-string, but will not crash if the input
string is invalid.
"""
```
```python
def fstring_contains_expr(s):
"""

"""
```
```python
def _toggle_fexpr_quotes(fstring, old_quote):
"""
Toggles quotes used in f-string expressions that are `old_quote`.

f-string expressions can't contain backslashes, so we need to toggle the
quotes if the f-string itself will end up using the same quote. We can
simply toggle without escaping because, quotes can't be reused in f-string
expressions. They will fail to parse.

NOTE: If PEP 701 is accepted, above statement will no longer be true.
Though if quotes can be reused, we can simply reuse them without updates or
escaping, once Black figures out how to parse the new grammar.
"""
```
```python
def insert_str_child_factory(string_leaf):
"""
Factory for a convenience function that is used to orphan @string_leaf
and then insert multiple new leaves into the same part of the node
structure that @string_leaf had originally occupied.

Examples:
    Let `string_leaf = Leaf(token.STRING, '"foo"')` and `N =
    string_leaf.parent`. Assume the node `N` has the following
    original structure:

    Node(
        expr_stmt, [
            Leaf(NAME, 'x'),
            Leaf(EQUAL, '='),
            Leaf(STRING, '"foo"'),
        ]
    )

    We then run the code snippet shown below.
    ```
    insert_str_child = insert_str_child_factory(string_leaf)

    lpar = Leaf(token.LPAR, '(')
    insert_str_child(lpar)

    bar = Leaf(token.STRING, '"bar"')
    insert_str_child(bar)

    rpar = Leaf(token.RPAR, ')')
    insert_str_child(rpar)
    ```

    After which point, it follows that `string_leaf.parent is None` and
    the node `N` now has the following structure:

    Node(
        expr_stmt, [
            Leaf(NAME, 'x'),
            Leaf(EQUAL, '='),
            Leaf(LPAR, '('),
            Leaf(STRING, '"bar"'),
            Leaf(RPAR, ')'),
        ]
    )
"""
```
```python
def is_valid_index_factory(seq):
"""
Examples:
    ```
    my_list = [1, 2, 3]

    is_valid_index = is_valid_index_factory(my_list)

    assert is_valid_index(0)
    assert is_valid_index(2)

    assert not is_valid_index(3)
    assert not is_valid_index(-1)
    ```
"""
```
```python
def is_simple_lookup(index, kind):
"""

"""
```
```python
def is_simple_operand(index, kind):
"""

"""
```
```python
def __init__(self):
"""

"""
```
```python
def do_match(self, line):
"""

"""
```
```python
def do_transform(self, line, string_indices):
"""

"""
```
```python
def __call__(self, line, _features, _mode):
"""
StringTransformer instances have a call signature that mirrors that of
the Transformer type.

Raises:
    CannotTransform(...) if the concrete StringTransformer class is unable
    to transform @line.
"""
```
```python
def _get_key(string):
"""
Returns:
    A unique identifier that is used internally to map @string to a
    group of custom splits.
"""
```
```python
def add_custom_splits(self, string, custom_splits):
"""
Custom Split Map Setter Method

Side Effects:
    Adds a mapping from @string to the custom splits @custom_splits.
"""
```
```python
def pop_custom_splits(self, string):
"""
Custom Split Map Getter Method

Returns:
    * A list of the custom splits that are mapped to @string, if any
      exist.
      OR
    * [], otherwise.

Side Effects:
    Deletes the mapping between @string and its associated custom
    splits (which are returned to the caller).
"""
```
```python
def has_custom_splits(self, string):
"""
Returns:
    True iff @string is associated with a set of custom splits.
"""
```
```python
def _remove_backslash_line_continuation_chars(line, string_indices):
"""
Merge strings that were split across multiple lines using
line-continuation backslashes.

Returns:
    Ok(new_line), if @line contains backslash line-continuation
    characters.
        OR
    Err(CannotTransform), otherwise.
"""
```
```python
def _merge_string_group(self, line, string_indices):
"""
Merges string groups (i.e. set of adjacent strings).

Each index from `string_indices` designates one string group's first
leaf in `line.leaves`.

Returns:
    Ok(new_line), if ALL of the validation checks found in
    _validate_msg(...) pass.
        OR
    Err(CannotTransform), otherwise.
"""
```
```python
def _merge_one_string_group(self, LL, string_idx, is_valid_index):
"""
Merges one string group where the first string in the group is
`LL[string_idx]`.

Returns:
    A tuple of `(num_of_strings, leaf)` where `num_of_strings` is the
    number of strings merged and `leaf` is the newly merged string
    to be replaced in the new line.
"""
```
```python
def _validate_msg(line, string_idx):
"""
Validate (M)erge (S)tring (G)roup

Transform-time string validation logic for _merge_string_group(...).

Returns:
    * Ok(None), if ALL validation checks (listed below) pass.
        OR
    * Err(CannotTransform), if any of the following are true:
        - The target string group does not contain ANY stand-alone comments.
        - The target string is not in a string group (i.e. it has no
          adjacent strings).
        - The string group has more than one inline comment.
        - The string group has an inline comment that appears to be a pragma.
        - The set of all string prefixes in the string group is of
          length greater than one and is not equal to {"", "f"}.
        - The string group consists of raw strings.
        - The string group is stringified type annotations. We don't want to
          process stringified type annotations since pyright doesn't support
          them spanning multiple string values. (NOTE: mypy, pytype, pyre do
          support them, so we can change if pyright also gains support in the
          future. See https://github.com/microsoft/pyright/issues/4359.)
"""
```
```python
def _transform_to_new_line(self, line, string_and_rpar_indices):
"""

"""
```
```python
def do_splitter_match(self, line):
"""

"""
```
```python
def _validate(self, line, string_idx):
"""
Checks that @line meets all of the requirements listed in this classes'
docstring. Refer to `help(BaseStringSplitter)` for a detailed
description of those requirements.

Returns:
    * Ok(None), if ALL of the requirements are met.
      OR
    * Err(CannotTransform), if ANY of the requirements are NOT met.
"""
```
```python
def _get_max_string_length(self, line, string_idx):
"""
Calculates the max string length used when attempting to determine
whether or not the target string is responsible for causing the line to
go over the line length limit.

WARNING: This method is tightly coupled to both StringSplitter and
(especially) StringParenWrapper. There is probably a better way to
accomplish what is being done here.

Returns:
    max_string_length: such that `line.leaves[string_idx].value >
    max_string_length` implies that the target string IS responsible
    for causing this line to exceed the line length limit.
"""
```
```python
def _prefer_paren_wrap_match(LL):
"""
Returns:
    string_idx such that @LL[string_idx] is equal to our target (i.e.
    matched) string, if this line matches the "prefer paren wrap" statement
    requirements listed in the 'Requirements' section of the StringParenWrapper
    class's docstring.
        OR
    None, otherwise.
"""
```
```python
def _iter_nameescape_slices(self, string):
"""
Yields:
    All ranges of @string which, if @string were to be split there,
    would result in the splitting of an \N{...} expression (which is NOT
    allowed).
"""
```
```python
def _iter_fexpr_slices(self, string):
"""
Yields:
    All ranges of @string which, if @string were to be split there,
    would result in the splitting of an f-expression (which is NOT
    allowed).
"""
```
```python
def _get_illegal_split_indices(self, string):
"""

"""
```
```python
def _get_break_idx(self, string, max_break_idx):
"""
This method contains the algorithm that StringSplitter uses to
determine which character to split each string at.

Args:
    @string: The substring that we are attempting to split.
    @max_break_idx: The ideal break index. We will return this value if it
    meets all the necessary conditions. In the likely event that it
    doesn't we will try to find the closest index BELOW @max_break_idx
    that does. If that fails, we will expand our search by also
    considering all valid indices ABOVE @max_break_idx.

Pre-Conditions:
    * assert_is_leaf_string(@string)
    * 0 <= @max_break_idx < len(@string)

Returns:
    break_idx, if an index is able to be found that meets all of the
    conditions listed in the 'Transformations' section of this classes'
    docstring.
        OR
    None, otherwise.
"""
```
```python
def _maybe_normalize_string_quotes(self, leaf):
"""

"""
```
```python
def _normalize_f_string(self, string, prefix):
"""
Pre-Conditions:
    * assert_is_leaf_string(@string)

Returns:
    * If @string is an f-string that contains no f-expressions, we
    return a string identical to @string except that the 'f' prefix
    has been stripped and all double braces (i.e. '{{' or '}}') have
    been normalized (i.e. turned into '{' or '}').
        OR
    * Otherwise, we return @string.
"""
```
```python
def _get_string_operator_leaves(self, leaves):
"""

"""
```
```python
def _return_match(LL):
"""
Returns:
    string_idx such that @LL[string_idx] is equal to our target (i.e.
    matched) string, if this line matches the return/yield statement
    requirements listed in the 'Requirements' section of this classes'
    docstring.
        OR
    None, otherwise.
"""
```
```python
def _else_match(LL):
"""
Returns:
    string_idx such that @LL[string_idx] is equal to our target (i.e.
    matched) string, if this line matches the ternary expression
    requirements listed in the 'Requirements' section of this classes'
    docstring.
        OR
    None, otherwise.
"""
```
```python
def _assert_match(LL):
"""
Returns:
    string_idx such that @LL[string_idx] is equal to our target (i.e.
    matched) string, if this line matches the assert statement
    requirements listed in the 'Requirements' section of this classes'
    docstring.
        OR
    None, otherwise.
"""
```
```python
def _assign_match(LL):
"""
Returns:
    string_idx such that @LL[string_idx] is equal to our target (i.e.
    matched) string, if this line matches the assignment statement
    requirements listed in the 'Requirements' section of this classes'
    docstring.
        OR
    None, otherwise.
"""
```
```python
def _dict_or_lambda_match(LL):
"""
Returns:
    string_idx such that @LL[string_idx] is equal to our target (i.e.
    matched) string, if this line matches the dictionary key assignment
    statement or lambda expression requirements listed in the
    'Requirements' section of this classes' docstring.
        OR
    None, otherwise.
"""
```
```python
def parse(self, leaves, string_idx):
"""
Pre-conditions:
    * @leaves[@string_idx].type == token.STRING

Returns:
    The index directly after the last leaf which is a part of the string
    trailer, if a "trailer" exists.
    OR
    @string_idx + 1, if no string "trailer" exists.
"""
```
```python
def _next_state(self, leaf):
"""
Pre-conditions:
    * On the first call to this function, @leaf MUST be the leaf that
      was directly after the string leaf in question (e.g. if our target
      string is `line.leaves[i]` then the first call to this method must
      be `line.leaves[i + 1]`).
    * On the next call to this function, the leaf parameter passed in
      MUST be the leaf directly following @leaf.

Returns:
    True iff @leaf is a part of the string's trailer.
"""
```
```python
def insert_str_child(child):
"""

"""
```
```python
def is_valid_index(idx):
"""
Returns:
    True iff @idx is positive AND seq[@idx] does NOT raise an
    IndexError.
"""
```
```python
def make_naked(string, string_prefix):
"""
Strip @string (i.e. make it a "naked" string)

Pre-conditions:
    * assert_is_leaf_string(@string)

Returns:
    A string that is identical to @string except that
    @string_prefix has been stripped, the surrounding QUOTE
    characters have been removed, and any remaining QUOTE
    characters have been escaped.
"""
```
```python
def maybe_append_string_operators(new_line):
"""
Side Effects:
    If @line starts with a string operator and this is the first
    line we are constructing, this function appends the string
    operator to @new_line and replaces the old string operator leaf
    in the node structure. Otherwise this function does nothing.
"""
```
```python
def max_last_string_column():
"""
Returns:
    The max allowed width of the string value used for the last
    line we will construct.  Note that this value means the width
    rather than the number of characters (e.g., many East Asian
    characters expand to two columns).
"""
```
```python
def more_splits_should_be_made():
"""
Returns:
    True iff `rest_value` (the remaining string value from the last
    split), should be split again.
"""
```
```python
def breaks_unsplittable_expression(i):
"""
Returns:
    True iff returning @i would result in the splitting of an
    unsplittable expression (which is NOT allowed).
"""
```
```python
def passes_all_checks(i):
"""
Returns:
    True iff ALL of the conditions listed in the 'Transformations'
    section of this classes' docstring would be met by returning @i.
"""
```
# src/blackd/__main__.py


# src/blackd/middlewares.py


# Comments
| Comment | File | Line |
|---------|------|------|
| **# @middleware is deprecated and its behaviour is the default since aiohttp 4.0** | src/blackd/middlewares.py | 13 |
| **# so if it doesn't exist anymore, define a no-op for forward compatibility.** | src/blackd/middlewares.py | 14 |

## Function Names and Associated Docstring
```python
def cors(allow_headers):
"""

"""
```
# src/blib2to3/pgen2/conv.py



# Comments
| Comment | File | Line |
|---------|------|------|
| **# Copyright 2004-2005 Elemental Security, Inc. All Rights Reserved.** | src/blib2to3/pgen2/conv.py | 1 |
| **# Licensed to PSF under a Contributor Agreement.** | src/blib2to3/pgen2/conv.py | 2 |
| **# mypy: ignore-errors** | src/blib2to3/pgen2/conv.py | 4 |
| **# Python imports** | src/blib2to3/pgen2/conv.py | 31 |
| **# Local imports** | src/blib2to3/pgen2/conv.py | 34 |
| **#include "pgenheaders.h"** | src/blib2to3/pgen2/conv.py | 90 |
| **#include "grammar.h"** | src/blib2to3/pgen2/conv.py | 91 |
| **# The code below essentially uses f's iterator-ness!** | src/blib2to3/pgen2/conv.py | 118 |
| **# Expect the two #include lines** | src/blib2to3/pgen2/conv.py | 121 |
| **# Parse the state definitions** | src/blib2to3/pgen2/conv.py | 127 |
| **# Parse the dfas** | src/blib2to3/pgen2/conv.py | 166 |
| **# Parse the labels** | src/blib2to3/pgen2/conv.py | 197 |
| **# Parse the grammar struct** | src/blib2to3/pgen2/conv.py | 218 |

## Function Names and Associated Docstring
```python
def run(self, graminit_h, graminit_c):
"""
Load the grammar tables from the text files written by pgen.
"""
```
```python
def parse_graminit_h(self, filename):
"""
Parse the .h file written by pgen.  (Internal)

This file is a sequence of #define statements defining the
nonterminals of the grammar as numbers.  We build two tables
mapping the numbers to names and back.
"""
```
```python
def parse_graminit_c(self, filename):
"""
Parse the .c file written by pgen.  (Internal)

The file looks as follows.  The first two lines are always this:

#include "pgenheaders.h"
#include "grammar.h"

After that come four blocks:

1) one or more state definitions
2) a table defining dfas
3) a table defining labels
4) a struct defining the grammar

A state definition has the following form:
- one or more arc arrays, each of the form:
  static arc arcs_<n>_<m>[<k>] = {
          {<i>, <j>},
          ...
  };
- followed by a state array, of the form:
  static state states_<s>[<t>] = {
          {<k>, arcs_<n>_<m>},
          ...
  };
"""
```
```python
def finish_off(self):
"""
Create additional useful structures.  (Internal).
"""
```
# src/blib2to3/pgen2/driver.py



# Comments
| Comment | File | Line |
|---------|------|------|
| **# Copyright 2004-2005 Elemental Security, Inc. All Rights Reserved.** | src/blib2to3/pgen2/driver.py | 1 |
| **# Licensed to PSF under a Contributor Agreement.** | src/blib2to3/pgen2/driver.py | 2 |
| **# Modifications:** | src/blib2to3/pgen2/driver.py | 4 |
| **# Copyright 2006 Google, Inc. All Rights Reserved.** | src/blib2to3/pgen2/driver.py | 5 |
| **# Licensed to PSF under a Contributor Agreement.** | src/blib2to3/pgen2/driver.py | 6 |
| **# Python imports** | src/blib2to3/pgen2/driver.py | 18 |
| **# Pgen imports** | src/blib2to3/pgen2/driver.py | 33 |
| **# Lock the last release range to the final position that** | src/blib2to3/pgen2/driver.py | 63 |
| **# has been eaten.** | src/blib2to3/pgen2/driver.py | 64 |
| **# If the current position is already compromised (looked up)** | src/blib2to3/pgen2/driver.py | 81 |
| **# return the eaten token, if not just go further on the given** | src/blib2to3/pgen2/driver.py | 82 |
| **# token producer.** | src/blib2to3/pgen2/driver.py | 83 |
| **# Try to eat, fail if it can't. The eat operation is cached** | src/blib2to3/pgen2/driver.py | 97 |
| **# so there won't be any additional cost of eating here** | src/blib2to3/pgen2/driver.py | 98 |
| **# XXX Move the prefix computation into a wrapper around tokenize.** | src/blib2to3/pgen2/driver.py | 116 |
| **# We never broke out -- EOF is too soon (how can this happen???)** | src/blib2to3/pgen2/driver.py | 174 |
| **# unexpected empty line** | src/blib2to3/pgen2/driver.py | 223 |
| **# indent is finished** | src/blib2to3/pgen2/driver.py | 228 |
| **# Ignore error, caching is not vital.** | src/blib2to3/pgen2/driver.py | 261 |

## Function Names and Associated Docstring
```python
def _generate_pickle_name(gt, cache_dir):
"""

"""
```
```python
def load_grammar(gt, gp, save, force, logger):
"""
Load the grammar (maybe from a pickle).
"""
```
```python
def _newer(a, b):
"""
Inquire whether file a was written since file b.
"""
```
```python
def load_packaged_grammar(package, grammar_source, cache_dir):
"""
Normally, loads a pickled grammar by doing
    pkgutil.get_data(package, pickled_grammar)
where *pickled_grammar* is computed from *grammar_source* by adding the
Python version and using a ``.pickle`` extension.

However, if *grammar_source* is an extant file, load_grammar(grammar_source)
is called instead. This facilitates using a packaged grammar file when needed
but preserves load_grammar's automatic regeneration behavior when possible.
"""
```
```python
def main():
"""
Main program, when run as a script: produce grammar pickle files.

Calls load_grammar for each argument, a path to a grammar text file.
"""
```
```python
def lock(self):
"""

"""
```
```python
def __init__(self, grammar, logger):
"""

"""
```
```python
def release(self):
"""

"""
```
```python
def eat(self, point):
"""

"""
```
```python
def __iter__(self):
"""

"""
```
```python
def __next__(self):
"""

"""
```
```python
def can_advance(self, to):
"""

"""
```
```python
def parse_tokens(self, tokens, debug):
"""
Parse a series of tokens and return the syntax tree.
"""
```
```python
def parse_stream_raw(self, stream, debug):
"""
Parse a stream and return the syntax tree.
"""
```
```python
def parse_stream(self, stream, debug):
"""
Parse a stream and return the syntax tree.
"""
```
```python
def parse_file(self, filename, encoding, debug):
"""
Parse a file and return the syntax tree.
"""
```
```python
def parse_string(self, text, debug):
"""
Parse a string and return the syntax tree.
"""
```
```python
def _partially_consume_prefix(self, prefix, column):
"""

"""
```
# src/blib2to3/pgen2/grammar.py



# Comments
| Comment | File | Line |
|---------|------|------|
| **# Copyright 2004-2005 Elemental Security, Inc. All Rights Reserved.** | src/blib2to3/pgen2/grammar.py | 1 |
| **# Licensed to PSF under a Contributor Agreement.** | src/blib2to3/pgen2/grammar.py | 2 |
| **# Python imports** | src/blib2to3/pgen2/grammar.py | 15 |
| **# Local imports** | src/blib2to3/pgen2/grammar.py | 21 |
| **# Python 3.7+ parses async as a keyword, not an identifier** | src/blib2to3/pgen2/grammar.py | 97 |
| **# mypyc generates objects that don't have a __dict__, but they** | src/blib2to3/pgen2/grammar.py | 103 |
| **# do have __getstate__ methods that will return an equivalent** | src/blib2to3/pgen2/grammar.py | 104 |
| **# dictionary** | src/blib2to3/pgen2/grammar.py | 105 |
| **# Map from operator to number (since tokenize doesn't do this)** | src/blib2to3/pgen2/grammar.py | 170 |

## Function Names and Associated Docstring
```python
def __init__(self):
"""

"""
```
```python
def dump(self, filename):
"""
Dump the grammar tables to a pickle file.
"""
```
```python
def _update(self, attrs):
"""

"""
```
```python
def load(self, filename):
"""
Load the grammar tables from a pickle file.
"""
```
```python
def loads(self, pkl):
"""
Load the grammar tables from a pickle bytes object.
"""
```
```python
def copy(self):
"""
Copy the grammar.
"""
```
```python
def report(self):
"""
Dump the grammar tables to standard output, for debugging.
"""
```
# src/blib2to3/pgen2/literals.py



# Comments
| Comment | File | Line |
|---------|------|------|
| **# Copyright 2004-2005 Elemental Security, Inc. All Rights Reserved.** | src/blib2to3/pgen2/literals.py | 1 |
| **# Licensed to PSF under a Contributor Agreement.** | src/blib2to3/pgen2/literals.py | 2 |

## Function Names and Associated Docstring
```python
def escape(m):
"""

"""
```
```python
def evalString(s):
"""

"""
```
```python
def test():
"""

"""
```
# src/blib2to3/pgen2/parse.py


# Comments
| Comment | File | Line |
|---------|------|------|
| **# Copyright 2004-2005 Elemental Security, Inc. All Rights Reserved.** | src/blib2to3/pgen2/parse.py | 1 |
| **# Licensed to PSF under a Contributor Agreement.** | src/blib2to3/pgen2/parse.py | 2 |
| **# Local imports** | src/blib2to3/pgen2/parse.py | 30 |
| **# A placeholder node, used when parser is backtracking.** | src/blib2to3/pgen2/parse.py | 48 |
| **# See note in docstring above. TL;DR this is ignored.** | src/blib2to3/pgen2/parse.py | 211 |
| **# Each stack entry is a tuple: (dfa, state, node).** | src/blib2to3/pgen2/parse.py | 231 |
| **# A node is a tuple: (type, value, context, children),** | src/blib2to3/pgen2/parse.py | 232 |
| **# where children is a list of nodes or None, and context may be None.** | src/blib2to3/pgen2/parse.py | 233 |
| **# Map from token to label** | src/blib2to3/pgen2/parse.py | 244 |
| **# If we have only one state to advance, we'll directly** | src/blib2to3/pgen2/parse.py | 248 |
| **# take it as is.** | src/blib2to3/pgen2/parse.py | 249 |
| **# If there are multiple states which we can advance (only** | src/blib2to3/pgen2/parse.py | 254 |
| **# happen under soft-keywords), then we will try all of them** | src/blib2to3/pgen2/parse.py | 255 |
| **# in parallel and as soon as one state can reach further than** | src/blib2to3/pgen2/parse.py | 256 |
| **# the rest, we'll choose that one. This is a pretty hacky** | src/blib2to3/pgen2/parse.py | 257 |
| **# and hopefully temporary algorithm.** | src/blib2to3/pgen2/parse.py | 258 |
| **#** | src/blib2to3/pgen2/parse.py | 259 |
| **# For a more detailed explanation, check out this post:** | src/blib2to3/pgen2/parse.py | 260 |
| **# https://tree.science/what-the-backtracking.html** | src/blib2to3/pgen2/parse.py | 261 |
| **# Loop until the token is shifted; may raise exceptions** | src/blib2to3/pgen2/parse.py | 291 |
| **# Look for a state with this label** | src/blib2to3/pgen2/parse.py | 296 |
| **# See if it's a symbol and if we're in its first set** | src/blib2to3/pgen2/parse.py | 300 |
| **# Push a symbol** | src/blib2to3/pgen2/parse.py | 304 |
| **# Look it up in the list of labels** | src/blib2to3/pgen2/parse.py | 309 |
| **# Shift a token; we're done with it** | src/blib2to3/pgen2/parse.py | 310 |
| **# Pop while we are in an accept-only state** | src/blib2to3/pgen2/parse.py | 312 |
| **# Done parsing!** | src/blib2to3/pgen2/parse.py | 317 |
| **# Done with this token** | src/blib2to3/pgen2/parse.py | 321 |
| **# An accepting state, pop it and try something else** | src/blib2to3/pgen2/parse.py | 327 |
| **# Done parsing, but another token is input** | src/blib2to3/pgen2/parse.py | 330 |
| **# No success finding a transition** | src/blib2to3/pgen2/parse.py | 333 |
| **# Keep a listing of all used names** | src/blib2to3/pgen2/parse.py | 342 |
| **# Check for reserved words** | src/blib2to3/pgen2/parse.py | 344 |
| **# Current soft keywords (match, case, type) can only appear at the** | src/blib2to3/pgen2/parse.py | 349 |
| **# beginning of a statement. So as a shortcut, don't try to treat them** | src/blib2to3/pgen2/parse.py | 350 |
| **# like keywords in any other context.** | src/blib2to3/pgen2/parse.py | 351 |
| **# ('_' is also a soft keyword in the real grammar, but for our grammar** | src/blib2to3/pgen2/parse.py | 352 |
| **# it's just an expression, so we don't need to treat it specially.)** | src/blib2to3/pgen2/parse.py | 353 |

## Function Names and Associated Docstring
```python
def lam_sub(grammar, node):
"""

"""
```
```python
def stack_copy(stack):
"""
Nodeless stack copy.
"""
```
```python
def __init__(self, grammar, convert):
"""
Constructor.

The grammar argument is a grammar.Grammar instance; see the
grammar module for more information.

The parser is not ready yet for parsing; you must call the
setup() method to get it started.

The optional convert argument is a function mapping concrete
syntax tree nodes to abstract syntax tree nodes.  If not
given, no conversion is done and the syntax tree produced is
the concrete syntax tree.  If given, it must be a function of
two arguments, the first being the grammar (a grammar.Grammar
instance), and the second being the concrete syntax tree node
to be converted.  The syntax tree is converted from the bottom
up.

**post-note: the convert argument is ignored since for Black's
usage, convert will always be blib2to3.pytree.convert. Allowing
this to be dynamic hurts mypyc's ability to use early binding.
These docs are left for historical and informational value.

A concrete syntax tree node is a (type, value, context, nodes)
tuple, where type is the node type (a token or symbol number),
value is None for symbols and a string for tokens, context is
None or an opaque value used for error reporting (typically a
(lineno, offset) pair), and nodes is a list of children for
symbols, and None for tokens.

An abstract syntax tree node may be anything; this is entirely
up to the converter function.
"""
```
```python
def ilabels(self):
"""

"""
```
```python
def switch_to(self, ilabel):
"""

"""
```
```python
def backtrack(self):
"""
Use the node-level invariant ones for basic parsing operations (push/pop/shift).
These still will operate on the stack; but they won't create any new nodes, or
modify the contents of any other existing nodes.

This saves us a ton of time when we are backtracking, since we
want to restore to the initial state as quick as possible, which
can only be done by having as little mutatations as possible.
"""
```
```python
def add_token(self, tok_type, tok_val, raw):
"""

"""
```
```python
def determine_route(self, value, force):
"""

"""
```
```python
def setup(self, proxy, start):
"""
Prepare for parsing.

This *must* be called before starting to parse.

The optional argument is an alternative start symbol; it
defaults to the grammar's start symbol.

You can use a Parser instance to parse any number of programs;
each time you call setup() the parser is reset to an initial
state determined by the (implicit or explicit) start symbol.
"""
```
```python
def addtoken(self, type, value, context):
"""
Add a token; return True iff this is the end of the program.
"""
```
```python
def _addtoken(self, ilabel, type, value, context):
"""

"""
```
```python
def classify(self, type, value, context):
"""
Turn a token into a label.  (Internal)

Depending on whether the value is a soft-keyword or not,
this function may return multiple labels to choose from.
"""
```
```python
def shift(self, type, value, newstate, context):
"""
Shift a token.  (Internal)
"""
```
```python
def push(self, type, newdfa, newstate, context):
"""
Push a nonterminal.  (Internal)
"""
```
```python
def pop(self):
"""
Pop a nonterminal.  (Internal)
"""
```
# src/blib2to3/pgen2/pgen.py



# Comments
| Comment | File | Line |
|---------|------|------|
| **# Copyright 2004-2005 Elemental Security, Inc. All Rights Reserved.** | src/blib2to3/pgen2/pgen.py | 1 |
| **# Licensed to PSF under a Contributor Agreement.** | src/blib2to3/pgen2/pgen.py | 2 |
| **##assert ilabel not in first # XXX failed on <> ... !=** | src/blib2to3/pgen2/pgen.py | 80 |
| **# XXX Maybe this should be a method on a subclass of converter?** | src/blib2to3/pgen2/pgen.py | 85 |
| **# Either a symbol name or a named token** | src/blib2to3/pgen2/pgen.py | 88 |
| **# A symbol name (a non-terminal)** | src/blib2to3/pgen2/pgen.py | 90 |
| **# A named token (NAME, NUMBER, STRING)** | src/blib2to3/pgen2/pgen.py | 98 |
| **# Either a keyword or an operator** | src/blib2to3/pgen2/pgen.py | 109 |
| **# A keyword** | src/blib2to3/pgen2/pgen.py | 118 |
| **# An operator (any non-numeric token)** | src/blib2to3/pgen2/pgen.py | 126 |
| **# print name, self.first[name].keys()** | src/blib2to3/pgen2/pgen.py | 141 |
| **# MSTART: (NEWLINE | RULE)* ENDMARKER** | src/blib2to3/pgen2/pgen.py | 178 |
| **# RULE: NAME ':' RHS NEWLINE** | src/blib2to3/pgen2/pgen.py | 182 |
| **# self.dump_nfa(name, a, z)** | src/blib2to3/pgen2/pgen.py | 187 |
| **# self.dump_dfa(name, dfa)** | src/blib2to3/pgen2/pgen.py | 189 |
| **# oldlen = len(dfa)** | src/blib2to3/pgen2/pgen.py | 190 |
| **# newlen = len(dfa)** | src/blib2to3/pgen2/pgen.py | 192 |
| **# print name, oldlen, newlen** | src/blib2to3/pgen2/pgen.py | 194 |
| **# To turn an NFA into a DFA, we define the states of the DFA** | src/blib2to3/pgen2/pgen.py | 201 |
| **# to correspond to *sets* of states of the NFA.  Then do some** | src/blib2to3/pgen2/pgen.py | 202 |
| **# state reduction.  Let's represent sets as dicts with 1 for** | src/blib2to3/pgen2/pgen.py | 203 |
| **# values.** | src/blib2to3/pgen2/pgen.py | 204 |
| **# This is not theoretically optimal, but works well enough.** | src/blib2to3/pgen2/pgen.py | 263 |
| **# Algorithm: repeatedly look for two states that have the same** | src/blib2to3/pgen2/pgen.py | 264 |
| **# set of arcs (same labels pointing to the same nodes) and** | src/blib2to3/pgen2/pgen.py | 265 |
| **# unify them, until things stop changing.** | src/blib2to3/pgen2/pgen.py | 266 |
| **# dfa is a list of DFAState instances** | src/blib2to3/pgen2/pgen.py | 268 |
| **# print "  unify", i, j** | src/blib2to3/pgen2/pgen.py | 276 |
| **# RHS: ALT ('|' ALT)*** | src/blib2to3/pgen2/pgen.py | 284 |
| **# ALT: ITEM+** | src/blib2to3/pgen2/pgen.py | 301 |
| **# ITEM: '[' RHS ']' | ATOM ['+' | '*']** | src/blib2to3/pgen2/pgen.py | 310 |
| **# ATOM: '(' RHS ')' | NAME | STRING** | src/blib2to3/pgen2/pgen.py | 330 |
| **# print token.tok_name[self.type], repr(self.value)** | src/blib2to3/pgen2/pgen.py | 362 |
| **# Equality test -- ignore the nfaset instance variable** | src/blib2to3/pgen2/pgen.py | 410 |
| **# Can't just return self.arcs == other.arcs, because that** | src/blib2to3/pgen2/pgen.py | 414 |
| **# would invoke this method recursively, with cycles...** | src/blib2to3/pgen2/pgen.py | 415 |

## Function Names and Associated Docstring
```python
def generate_grammar(filename):
"""

"""
```
```python
def __init__(self, nfaset, final):
"""

"""
```
```python
def make_grammar(self):
"""

"""
```
```python
def make_first(self, c, name):
"""

"""
```
```python
def make_label(self, c, label):
"""

"""
```
```python
def addfirstsets(self):
"""

"""
```
```python
def calcfirst(self, name):
"""

"""
```
```python
def parse(self):
"""

"""
```
```python
def make_dfa(self, start, finish):
"""

"""
```
```python
def dump_nfa(self, name, start, finish):
"""

"""
```
```python
def dump_dfa(self, name, dfa):
"""

"""
```
```python
def simplify_dfa(self, dfa):
"""

"""
```
```python
def parse_rhs(self):
"""

"""
```
```python
def parse_alt(self):
"""

"""
```
```python
def parse_item(self):
"""

"""
```
```python
def parse_atom(self):
"""

"""
```
```python
def expect(self, type, value):
"""

"""
```
```python
def gettoken(self):
"""

"""
```
```python
def raise_error(self, msg):
"""

"""
```
```python
def addarc(self, next, label):
"""

"""
```
```python
def unifystate(self, old, new):
"""

"""
```
```python
def __eq__(self, other):
"""

"""
```
```python
def closure(state):
"""

"""
```
```python
def addclosure(state, base):
"""

"""
```
# src/blib2to3/pgen2/token.py


# Comments
| Comment | File | Line |
|---------|------|------|
| **#  Taken from Python (r53757) and modified to include some tokens** | src/blib2to3/pgen2/token.py | 5 |
| **#   originally monkeypatched in by pgen2.tokenize** | src/blib2to3/pgen2/token.py | 6 |
| **# --start constants--** | src/blib2to3/pgen2/token.py | 8 |
| **# --end constants--** | src/blib2to3/pgen2/token.py | 71 |

## Function Names and Associated Docstring
```python
def ISTERMINAL(x):
"""

"""
```
```python
def ISNONTERMINAL(x):
"""

"""
```
```python
def ISEOF(x):
"""

"""
```
# src/blib2to3/pgen2/tokenize.py



# Comments
| Comment | File | Line |
|---------|------|------|
| **# Copyright (c) 2001, 2002, 2003, 2004, 2005, 2006 Python Software Foundation.** | src/blib2to3/pgen2/tokenize.py | 1 |
| **# All rights reserved.** | src/blib2to3/pgen2/tokenize.py | 2 |
| **# mypy: allow-untyped-defs, allow-untyped-calls** | src/blib2to3/pgen2/tokenize.py | 4 |
| **# Tail end of ' string.** | src/blib2to3/pgen2/tokenize.py | 115 |
| **# Tail end of " string.** | src/blib2to3/pgen2/tokenize.py | 117 |
| **# Tail end of ''' string.** | src/blib2to3/pgen2/tokenize.py | 119 |
| **# Tail end of """ string.** | src/blib2to3/pgen2/tokenize.py | 121 |
| **# Single-line ' or " string.** | src/blib2to3/pgen2/tokenize.py | 125 |
| **# Because of leftmost-then-longest match semantics, be sure to put the** | src/blib2to3/pgen2/tokenize.py | 131 |
| **# longest operators first (e.g., if = came before ==, == would get** | src/blib2to3/pgen2/tokenize.py | 132 |
| **# recognized as two instances of =).** | src/blib2to3/pgen2/tokenize.py | 133 |
| **# First (or only) line of ' or " string.** | src/blib2to3/pgen2/tokenize.py | 150 |
| **# backwards compatible interface** | src/blib2to3/pgen2/tokenize.py | 234 |
| **# Only care about the first 12 characters.** | src/blib2to3/pgen2/tokenize.py | 310 |
| **# This behaviour mimics the Python interpreter** | src/blib2to3/pgen2/tokenize.py | 361 |
| **# This behaviour mimics the Python interpreter** | src/blib2to3/pgen2/tokenize.py | 366 |
| **# Output text will tokenize the back to the input** | src/blib2to3/pgen2/tokenize.py | 407 |
| **# If we know we're parsing 3.7+, we can unconditionally parse `async` and** | src/blib2to3/pgen2/tokenize.py | 442 |
| **# `await` as keywords.** | src/blib2to3/pgen2/tokenize.py | 443 |
| **# 'stashed' and 'async_*' are used for async/await parsing** | src/blib2to3/pgen2/tokenize.py | 445 |
| **# This yield is new; needed for better idempotency:** | src/blib2to3/pgen2/tokenize.py | 666 |

## Function Names and Associated Docstring
```python
def group():
"""

"""
```
```python
def any():
"""

"""
```
```python
def maybe():
"""

"""
```
```python
def _combinations():
"""

"""
```
```python
def printtoken(type, token, srow_col, erow_col, line):
"""

"""
```
```python
def tokenize(readline, tokeneater):
"""
The tokenize() function accepts two parameters: one representing the
input stream, and one providing an output mechanism for tokenize().

The first parameter, readline, must be a callable object which provides
the same interface as the readline() method of built-in file objects.
Each call to the function should return one line of input as a string.

The second parameter, tokeneater, must also be a callable object. It is
called once for each token, with five arguments, corresponding to the
tuples generated by generate_tokens().
"""
```
```python
def tokenize_loop(readline, tokeneater):
"""

"""
```
```python
def _get_normal_name(orig_enc):
"""
Imitates get_normal_name in tokenizer.c.
"""
```
```python
def detect_encoding(readline):
"""
The detect_encoding() function is used to detect the encoding that should
be used to decode a Python source file. It requires one argument, readline,
in the same way as the tokenize() generator.

It will call readline a maximum of twice, and return the encoding used
(as a string) and a list of any lines (left as bytes) it has read
in.

It detects the encoding from the presence of a utf-8 bom or an encoding
cookie as specified in pep-0263. If both a bom and a cookie are present, but
disagree, a SyntaxError will be raised. If the encoding cookie is an invalid
charset, raise a SyntaxError.  Note that if a utf-8 bom is found,
'utf-8-sig' is returned.

If no encoding is specified, then the default of 'utf-8' will be returned.
"""
```
```python
def untokenize(self, iterable):
"""

"""
```
```python
def generate_tokens(readline, grammar):
"""
The generate_tokens() generator requires one argument, readline, which
must be a callable object which provides the same interface as the
readline() method of built-in file objects. Each call to the function
should return one line of input as a string.  Alternately, readline
can be a callable function terminating with StopIteration:
    readline = open(myfile).next    # Example of alternate readline

The generator produces 5-tuples with these members: the token type; the
token string; a 2-tuple (srow, scol) of ints specifying the row and
column where the token begins in the source; a 2-tuple (erow, ecol) of
ints specifying the row and column where the token ends in the source;
and the line on which the token was found. The line passed is the
logical line; continuation lines are included.
"""
```
```python
def __init__(self):
"""

"""
```
```python
def add_whitespace(self, start):
"""

"""
```
```python
def compat(self, token, iterable):
"""

"""
```
```python
def read_or_stop():
"""

"""
```
```python
def find_cookie(line):
"""

"""
```
# src/blib2to3/pygram.py



# Comments
| Comment | File | Line |
|---------|------|------|
| **# Copyright 2006 Google, Inc. All Rights Reserved.** | src/blib2to3/pygram.py | 1 |
| **# Licensed to PSF under a Contributor Agreement.** | src/blib2to3/pygram.py | 2 |
| **# Python imports** | src/blib2to3/pygram.py | 6 |
| **# Local imports** | src/blib2to3/pygram.py | 10 |
| **# Moved into initialize because mypyc can't handle __file__ (XXX bug)** | src/blib2to3/pygram.py | 14 |
| **# # The grammar file** | src/blib2to3/pygram.py | 15 |
| **# _GRAMMAR_FILE = os.path.join(os.path.dirname(__file__), "Grammar.txt")** | src/blib2to3/pygram.py | 16 |
| **# _PATTERN_GRAMMAR_FILE = os.path.join(os.path.dirname(__file__),** | src/blib2to3/pygram.py | 17 |
| **#                                      "PatternGrammar.txt")** | src/blib2to3/pygram.py | 18 |
| **# The grammar file** | src/blib2to3/pygram.py | 169 |
| **# Python 3.0-3.6** | src/blib2to3/pygram.py | 184 |
| **# Python 3.7+** | src/blib2to3/pygram.py | 187 |
| **# Python 3.10+** | src/blib2to3/pygram.py | 192 |

## Function Names and Associated Docstring
```python
def initialize(cache_dir):
"""

"""
```
```python
def __init__(self, grammar):
"""
Initializer.

Creates an attribute for each grammar symbol (nonterminal),
whose value is the symbol's type (an int >= 256).
"""
```
# src/blib2to3/pytree.py



# Comments
| Comment | File | Line |
|---------|------|------|
| **# Copyright 2006 Google, Inc. All Rights Reserved.** | src/blib2to3/pytree.py | 1 |
| **# Licensed to PSF under a Contributor Agreement.** | src/blib2to3/pytree.py | 2 |
| **# mypy: allow-untyped-defs, allow-incomplete-defs** | src/blib2to3/pytree.py | 13 |
| **# printing tokens is possible but not as useful** | src/blib2to3/pytree.py | 48 |
| **# from .pgen2 import token // token.__dict__.items():** | src/blib2to3/pytree.py | 49 |
| **# Default values for instance variables** | src/blib2to3/pytree.py | 74 |
| **# Default values for instance variables** | src/blib2to3/pytree.py | 385 |
| **# Changed later in brackets.py** | src/blib2to3/pytree.py | 389 |
| **# If not None, this Leaf is created by converting a block of fmt off/skip** | src/blib2to3/pytree.py | 395 |
| **# code, and `fmt_pass_converted_first_leaf` points to the first Leaf in the** | src/blib2to3/pytree.py | 396 |
| **# converted code.** | src/blib2to3/pytree.py | 397 |
| **# If there's exactly one child, return that child instead of** | src/blib2to3/pytree.py | 496 |
| **# creating a new node.** | src/blib2to3/pytree.py | 497 |
| **# Defaults for instance variables** | src/blib2to3/pytree.py | 524 |
| **# I don't even think this code is used anywhere, but it does cause** | src/blib2to3/pytree.py | 679 |
| **# unreachable errors from mypy. This function's signature does look** | src/blib2to3/pytree.py | 680 |
| **# odd though *shrug*.** | src/blib2to3/pytree.py | 681 |
| **# Check sanity of alternatives** | src/blib2to3/pytree.py | 765 |
| **# Shortcut for special case (see __init__.__doc__)** | src/blib2to3/pytree.py | 832 |
| **# The reason for this is that hitting the recursion limit usually** | src/blib2to3/pytree.py | 841 |
| **# results in some ugly messages about how RuntimeErrors are being** | src/blib2to3/pytree.py | 842 |
| **# ignored. We only have to do this on CPython, though, because other** | src/blib2to3/pytree.py | 843 |
| **# implementations don't have this nasty bug in the first place.** | src/blib2to3/pytree.py | 844 |
| **# We fall back to the iterative pattern matching scheme if the recursive** | src/blib2to3/pytree.py | 854 |
| **# scheme hits the recursion limit.** | src/blib2to3/pytree.py | 855 |
| **# generate matches that use just one alt from self.content** | src/blib2to3/pytree.py | 871 |
| **# for each match, iterate down the nodes** | src/blib2to3/pytree.py | 877 |
| **# stop if the entire set of nodes has been matched** | src/blib2to3/pytree.py | 881 |
| **# We never match a node in its entirety** | src/blib2to3/pytree.py | 940 |
| **# We only match an empty sequence of nodes in its entirety** | src/blib2to3/pytree.py | 944 |
| **# Return a match if there is an empty sequence** | src/blib2to3/pytree.py | 949 |
| **# Return a match if the argument pattern has no matches** | src/blib2to3/pytree.py | 953 |

## Function Names and Associated Docstring
```python
def type_repr(type_num):
"""

"""
```
```python
def convert(gr, raw_node):
"""
Convert raw node information to a Node or Leaf instance.

This is passed to the parser driver which calls it whenever a reduction of a
grammar rule produces a new complete node, so that the tree is build
strictly bottom-up.
"""
```
```python
def generate_matches(self, nodes):
"""

"""
```
```python
def __new__(cls):
"""
Constructor that prevents BasePattern from being instantiated.
"""
```
```python
def __eq__(self, other):
"""
Compare two nodes for equality.

This calls the method _eq().
"""
```
```python
def prefix(self, prefix):
"""

"""
```
```python
def _eq(self, other):
"""
Compare two nodes for equality.
"""
```
```python
def __deepcopy__(self, memo):
"""

"""
```
```python
def clone(self):
"""

"""
```
```python
def post_order(self):
"""
Return a post-order iterator for the tree.
"""
```
```python
def pre_order(self):
"""
Return a pre-order iterator for the tree.
"""
```
```python
def replace(self, new):
"""
Replace this node with a new one in the parent.
"""
```
```python
def get_lineno(self):
"""
Return the line number which generated the invocant node.
"""
```
```python
def changed(self):
"""

"""
```
```python
def remove(self):
"""
Remove the node from the tree. Returns the position of the node in its
parent's children before it was removed.
"""
```
```python
def next_sibling(self):
"""
The node immediately following the invocant in their parent's children
list. If the invocant does not have a next sibling, it is None
"""
```
```python
def prev_sibling(self):
"""
The node immediately preceding the invocant in their parent's children
list. If the invocant does not have a previous sibling, it is None.
"""
```
```python
def leaves(self):
"""

"""
```
```python
def depth(self):
"""

"""
```
```python
def get_suffix(self):
"""
Return the string immediately following the invocant node. This is
effectively equivalent to node.next_sibling.prefix
"""
```
```python
def __init__(self, content):
"""
Initializer.

The argument is either a pattern or None.  If it is None, this
only matches an empty sequence (effectively '$' in regex
lingo).  If it is not None, this matches whenever the argument
pattern doesn't have any matches.
"""
```
```python
def __repr__(self):
"""

"""
```
```python
def __str__(self):
"""
Return a pretty string representation.

This reproduces the input source exactly.
"""
```
```python
def set_child(self, i, child):
"""
Equivalent to 'node.children[i] = child'. This method also sets the
child's parent attribute appropriately.
"""
```
```python
def insert_child(self, i, child):
"""
Equivalent to 'node.children.insert(i, child)'. This method also sets
the child's parent attribute appropriately.
"""
```
```python
def append_child(self, child):
"""
Equivalent to 'node.children.append(child)'. This method also sets the
child's parent attribute appropriately.
"""
```
```python
def invalidate_sibling_maps(self):
"""

"""
```
```python
def update_sibling_maps(self):
"""

"""
```
```python
def _submatch(self, node, results):
"""
Match the pattern's content to the node's children.

This assumes the node type matches and self.content is not None.

Returns True if it matches, False if not.

If results is not None, it must be a dict which will be
updated with the nodes matching named subpatterns.

When returning False, the results dict may still be updated.
"""
```
```python
def optimize(self):
"""
Optimize certain stacked wildcard patterns.
"""
```
```python
def match(self, node, results):
"""

"""
```
```python
def match_seq(self, nodes, results):
"""

"""
```
```python
def _iterative_matches(self, nodes):
"""
Helper to iteratively yield the matches.
"""
```
```python
def _bare_name_matches(self, nodes):
"""
Special optimized matcher for bare_name.
"""
```
```python
def _recursive_matches(self, nodes, count):
"""
Helper to recursively yield the matches.
"""
```
# tests/conftest.py


## Function Names and Associated Docstring
```python
def pytest_addoption(parser):
"""

"""
```
```python
def pytest_configure(config):
"""

"""
```
# tests/data/cases/collections.py



# Comments
| Comment | File | Line |
|---------|------|------|
| **# keeps existing trailing comma** | tests/data/cases/collections.py | 5 |
| **# also keeps existing structure** | tests/data/cases/collections.py | 10 |
| **# `as` works as well** | tests/data/cases/collections.py | 16 |
| **# looping over a 1-tuple should also not get wrapped** | tests/data/cases/collections.py | 42 |
| **# output** | tests/data/cases/collections.py | 73 |
| **# keeps existing trailing comma** | tests/data/cases/collections.py | 80 |
| **# also keeps existing structure** | tests/data/cases/collections.py | 85 |
| **# `as` works as well** | tests/data/cases/collections.py | 91 |
| **# looping over a 1-tuple should also not get wrapped** | tests/data/cases/collections.py | 135 |

# tests/data/cases/comments.py



# Comments
| Comment | File | Line |
|---------|------|------|
| **#!/usr/bin/env python3** | tests/data/cases/comments.py | 1 |
| **# fmt: on** | tests/data/cases/comments.py | 2 |
| **# Some license here.** | tests/data/cases/comments.py | 3 |
| **#** | tests/data/cases/comments.py | 4 |
| **# Has many lines. Many, many lines.** | tests/data/cases/comments.py | 5 |
| **# Many, many, many lines.** | tests/data/cases/comments.py | 6 |
| **# Some comment before a function.** | tests/data/cases/comments.py | 24 |
| **# some strings** | tests/data/cases/comments.py | 27 |
| **# FIXME: Some comment about why this function is crap but still in production.** | tests/data/cases/comments.py | 37 |
| **# Explains why we have this if.** | tests/data/cases/comments.py | 41 |
| **# In great detail indeed.** | tests/data/cases/comments.py | 42 |
| **# This return is also commented for some reason.** | tests/data/cases/comments.py | 46 |
| **# Explains why we use global state.** | tests/data/cases/comments.py | 50 |
| **# Another comment!** | tests/data/cases/comments.py | 54 |
| **# This time two lines.** | tests/data/cases/comments.py | 55 |
| **#: Doc comment for class attribute Foo.bar.** | tests/data/cases/comments.py | 61 |
| **#: It can have multiple lines.** | tests/data/cases/comments.py | 62 |
| **#: Doc comment for instance attribute qux.** | tests/data/cases/comments.py | 71 |
| **#' <h1>This is pweave!</h1>** | tests/data/cases/comments.py | 78 |
| **# This comment, for some reason \** | tests/data/cases/comments.py | 83 |
| **# contains a trailing backslash.** | tests/data/cases/comments.py | 84 |
| **# Comment after ending a block.** | tests/data/cases/comments.py | 87 |
| **# Comment between things.** | tests/data/cases/comments.py | 90 |
| **# Some closing comments.** | tests/data/cases/comments.py | 94 |
| **# Maybe Vim or Emacs directives for formatting.** | tests/data/cases/comments.py | 95 |
| **# Who knows.** | tests/data/cases/comments.py | 96 |

## Function Names and Associated Docstring
```python
def function(default):
"""
Docstring comes first.

Possibly many lines.
"""
```
```python
def __init__(self):
"""

"""
```
# tests/data/cases/comments2.py


# Comments
| Comment | File | Line |
|---------|------|------|
| **# Please keep __all__ alphabetized within each category.** | tests/data/cases/comments2.py | 8 |
| **# Super-special typing primitives.** | tests/data/cases/comments2.py | 11 |
| **# ABCs (from collections.abc).** | tests/data/cases/comments2.py | 16 |
| **# Concrete collection types.** | tests/data/cases/comments2.py | 21 |
| **# singletons** | tests/data/cases/comments2.py | 34 |
| **# builtin types and objects** | tests/data/cases/comments2.py | 38 |
| **# user-defined types and objects** | tests/data/cases/comments2.py | 46 |
| **# for compiler in compilers.values():** | tests/data/cases/comments2.py | 55 |
| **# add_compiler(compiler)** | tests/data/cases/comments2.py | 56 |
| **# add_compiler(compilers[(7.1, 64)])** | tests/data/cases/comments2.py | 58 |
| **# Comment before function.** | tests/data/cases/comments2.py | 60 |
| **# has the child process finished?** | tests/data/cases/comments2.py | 81 |
| **# the child process has finished, but the** | tests/data/cases/comments2.py | 83 |
| **# transport hasn't been notified yet?** | tests/data/cases/comments2.py | 84 |
| **# no newline before or after** | tests/data/cases/comments2.py | 87 |
| **# one** | tests/data/cases/comments2.py | 89 |
| **# two** | tests/data/cases/comments2.py | 91 |
| **# no newline after** | tests/data/cases/comments2.py | 94 |
| **############################################################################** | tests/data/cases/comments2.py | 99 |
| **#short** | tests/data/cases/comments2.py | 102 |
| **#but** | tests/data/cases/comments2.py | 104 |
| **#multiline** | tests/data/cases/comments2.py | 106 |
| **# yup** | tests/data/cases/comments2.py | 110 |
| **# hello** | tests/data/cases/comments2.py | 118 |
| **# yup** | tests/data/cases/comments2.py | 120 |
| **# right** | tests/data/cases/comments2.py | 122 |
| **# This one is actually too long to fit in a single line.** | tests/data/cases/comments2.py | 126 |
| **# yup** | tests/data/cases/comments2.py | 128 |
| **# right** | tests/data/cases/comments2.py | 130 |
| **# and round and round we go** | tests/data/cases/comments2.py | 137 |
| **# and round and round we go** | tests/data/cases/comments2.py | 138 |
| **# let's return** | tests/data/cases/comments2.py | 140 |
| **#######################** | tests/data/cases/comments2.py | 158 |
| **### SECTION COMMENT ###** | tests/data/cases/comments2.py | 159 |
| **#######################** | tests/data/cases/comments2.py | 160 |
| **# END COMMENTS** | tests/data/cases/comments2.py | 165 |
| **# MORE END COMMENTS** | tests/data/cases/comments2.py | 166 |
| **# output** | tests/data/cases/comments2.py | 169 |
| **# Please keep __all__ alphabetized within each category.** | tests/data/cases/comments2.py | 179 |
| **# Super-special typing primitives.** | tests/data/cases/comments2.py | 182 |
| **# ABCs (from collections.abc).** | tests/data/cases/comments2.py | 186 |
| **# Concrete collection types.** | tests/data/cases/comments2.py | 190 |
| **# singletons** | tests/data/cases/comments2.py | 203 |
| **# builtin types and objects** | tests/data/cases/comments2.py | 208 |
| **# user-defined types and objects** | tests/data/cases/comments2.py | 216 |
| **# for compiler in compilers.values():** | tests/data/cases/comments2.py | 225 |
| **# add_compiler(compiler)** | tests/data/cases/comments2.py | 226 |
| **# add_compiler(compilers[(7.1, 64)])** | tests/data/cases/comments2.py | 228 |
| **# Comment before function.** | tests/data/cases/comments2.py | 231 |
| **# has the child process finished?** | tests/data/cases/comments2.py | 249 |
| **# the child process has finished, but the** | tests/data/cases/comments2.py | 251 |
| **# transport hasn't been notified yet?** | tests/data/cases/comments2.py | 252 |
| **# no newline before or after** | tests/data/cases/comments2.py | 256 |
| **# one** | tests/data/cases/comments2.py | 258 |
| **# two** | tests/data/cases/comments2.py | 260 |
| **# no newline after** | tests/data/cases/comments2.py | 264 |
| **############################################################################** | tests/data/cases/comments2.py | 274 |
| **# short** | tests/data/cases/comments2.py | 277 |
| **# but** | tests/data/cases/comments2.py | 279 |
| **# multiline** | tests/data/cases/comments2.py | 281 |
| **# yup** | tests/data/cases/comments2.py | 285 |
| **# hello** | tests/data/cases/comments2.py | 292 |
| **# yup** | tests/data/cases/comments2.py | 294 |
| **# right** | tests/data/cases/comments2.py | 296 |
| **# This one is actually too long to fit in a single line.** | tests/data/cases/comments2.py | 300 |
| **# yup** | tests/data/cases/comments2.py | 302 |
| **# right** | tests/data/cases/comments2.py | 304 |
| **# and round and round we go** | tests/data/cases/comments2.py | 311 |
| **# and round and round we go** | tests/data/cases/comments2.py | 312 |
| **# let's return** | tests/data/cases/comments2.py | 314 |
| **#######################** | tests/data/cases/comments2.py | 336 |
| **### SECTION COMMENT ###** | tests/data/cases/comments2.py | 337 |
| **#######################** | tests/data/cases/comments2.py | 338 |
| **# END COMMENTS** | tests/data/cases/comments2.py | 343 |
| **# MORE END COMMENTS** | tests/data/cases/comments2.py | 344 |

## Function Names and Associated Docstring
```python
def inline_comments_in_brackets_ruin_everything():
"""

"""
```
```python
def _init_host(self, parsed):
"""

"""
```
# tests/data/cases/comments4.py


# Comments
| Comment | File | Line |
|---------|------|------|
| **# metadata_version errors.** | tests/data/cases/comments4.py | 13 |
| **# name errors.** | tests/data/cases/comments4.py | 26 |
| **# version errors.** | tests/data/cases/comments4.py | 38 |
| **# Another comment about the filtering on is_quux goes here.** | tests/data/cases/comments4.py | 66 |
| **# Standalone comment reasonably placed.** | tests/data/cases/comments4.py | 76 |
| **# Standalone comment but weirdly placed.** | tests/data/cases/comments4.py | 88 |

## Function Names and Associated Docstring
```python
def foo(list_a, list_b):
"""

"""
```
```python
def foo2(list_a, list_b):
"""

"""
```
```python
def foo3(list_a, list_b):
"""

"""
```
```python
def test_fails_invalid_post_data(self, pyramid_config, db_request, post_data, message):
"""

"""
```
# tests/data/cases/comments5.py


# Comments
| Comment | File | Line |
|---------|------|------|
| **# Comment belongs to the `if` block.** | tests/data/cases/comments5.py | 4 |
| **# This one belongs to the `while` block.** | tests/data/cases/comments5.py | 5 |
| **# Should this one, too?  I guess so.** | tests/data/cases/comments5.py | 7 |
| **# This one is properly standalone now.** | tests/data/cases/comments5.py | 9 |
| **# first we do this** | tests/data/cases/comments5.py | 12 |
| **# then we do this** | tests/data/cases/comments5.py | 16 |
| **# and finally we loop around** | tests/data/cases/comments5.py | 18 |
| **# leading function comment** | tests/data/cases/comments5.py | 33 |
| **# trailing function comment** | tests/data/cases/comments5.py | 36 |
| **# SECTION COMMENT** | tests/data/cases/comments5.py | 39 |
| **# leading 1** | tests/data/cases/comments5.py | 42 |
| **# leading 2** | tests/data/cases/comments5.py | 44 |
| **# leading 3** | tests/data/cases/comments5.py | 46 |
| **# leading 1** | tests/data/cases/comments5.py | 51 |
| **# leading 2** | tests/data/cases/comments5.py | 53 |
| **# leading function comment** | tests/data/cases/comments5.py | 55 |
| **# Note: this is fixed in** | tests/data/cases/comments5.py | 59 |
| **# Preview.empty_lines_before_class_or_def_with_leading_comments.** | tests/data/cases/comments5.py | 60 |
| **# In the current style, the user will have to split those lines by hand.** | tests/data/cases/comments5.py | 61 |
| **# This comment should be split from `some_instruction` by two lines but isn't.** | tests/data/cases/comments5.py | 65 |

## Function Names and Associated Docstring
```python
def wat():
"""

"""
```
```python
def decorated1():
"""

"""
```
```python
def g():
"""

"""
```
# tests/data/cases/comments6.py


# Comments
| Comment | File | Line |
|---------|------|------|
| **# test type comments** | tests/data/cases/comments6.py | 10 |
| **# type: (int, int, int, int, int, int, int, int, int) -> None** | tests/data/cases/comments6.py | 12 |
| **# type: (...) -> None** | tests/data/cases/comments6.py | 27 |
| **# type: (...) -> None** | tests/data/cases/comments6.py | 37 |
| **# type: (...) -> None** | tests/data/cases/comments6.py | 47 |
| **# type: (...) -> None** | tests/data/cases/comments6.py | 76 |

## Function Names and Associated Docstring
```python
def f(x):
"""

"""
```
```python
def func(a):
"""

"""
```
# tests/data/cases/comments_in_blocks.py


# Comments
| Comment | File | Line |
|---------|------|------|
| **# Test cases from:** | tests/data/cases/comments_in_blocks.py | 1 |
| **# - https://github.com/psf/black/issues/1798** | tests/data/cases/comments_in_blocks.py | 2 |
| **# - https://github.com/psf/black/issues/1499** | tests/data/cases/comments_in_blocks.py | 3 |
| **# - https://github.com/psf/black/issues/1211** | tests/data/cases/comments_in_blocks.py | 4 |
| **# - https://github.com/psf/black/issues/563** | tests/data/cases/comments_in_blocks.py | 5 |
| **# a comment** | tests/data/cases/comments_in_blocks.py | 9 |
| **# b comment** | tests/data/cases/comments_in_blocks.py | 15 |
| **# a comment** | tests/data/cases/comments_in_blocks.py | 21 |
| **# b comment** | tests/data/cases/comments_in_blocks.py | 23 |
| **# Let's do this** | tests/data/cases/comments_in_blocks.py | 29 |
| **# OK?** | tests/data/cases/comments_in_blocks.py | 31 |
| **# Some comment** | tests/data/cases/comments_in_blocks.py | 33 |
| **# And another** | tests/data/cases/comments_in_blocks.py | 34 |
| **# One more** | tests/data/cases/comments_in_blocks.py | 36 |
| **# avoid returning any offers that don't match the grammar so** | tests/data/cases/comments_in_blocks.py | 43 |
| **# that the return values here are consistent with what would be** | tests/data/cases/comments_in_blocks.py | 44 |
| **# returned in AcceptValidHeader** | tests/data/cases/comments_in_blocks.py | 45 |
| **# qux** | tests/data/cases/comments_in_blocks.py | 51 |
| **# replace all variables by integers** | tests/data/cases/comments_in_blocks.py | 56 |
| **# 0 is reserved as line terminator** | tests/data/cases/comments_in_blocks.py | 60 |
| **# a comment** | tests/data/cases/comments_in_blocks.py | 68 |
| **# We take a candidate element from each group and shift it to** | tests/data/cases/comments_in_blocks.py | 77 |
| **# remove the bits that are not common to other group members, then** | tests/data/cases/comments_in_blocks.py | 78 |
| **# we convert it to a tree path that all elements from this group** | tests/data/cases/comments_in_blocks.py | 79 |
| **# have in common.** | tests/data/cases/comments_in_blocks.py | 80 |
| **# Each group will contain an even "power-of-two" number of# elements.** | tests/data/cases/comments_in_blocks.py | 83 |
| **# This tells us how many tailing bits each element has# which need to** | tests/data/cases/comments_in_blocks.py | 84 |
| **# be truncated to get the group's common prefix.** | tests/data/cases/comments_in_blocks.py | 85 |
| **# comment1** | tests/data/cases/comments_in_blocks.py | 92 |
| **# comment2** | tests/data/cases/comments_in_blocks.py | 94 |
| **# comment3** | tests/data/cases/comments_in_blocks.py | 96 |
| **# comment4** | tests/data/cases/comments_in_blocks.py | 98 |
| **# comment5** | tests/data/cases/comments_in_blocks.py | 101 |
| **# comment6** | tests/data/cases/comments_in_blocks.py | 103 |
| **# comment7** | tests/data/cases/comments_in_blocks.py | 106 |

## Function Names and Associated Docstring
```python
def convert(collection):
"""

"""
```
```python
def get_subtree_proof_nodes(chunk_index_groups):
"""

"""
```
# tests/data/cases/comments_non_breaking_space.py


# Comments
| Comment | File | Line |
|---------|------|------|
| **# DEFAULT_TYPE_ATTRIBUTES,** | tests/data/cases/comments_non_breaking_space.py | 2 |
| **#    There's a NBSP + 3 spaces before** | tests/data/cases/comments_non_breaking_space.py | 17 |
| **#    And 4 spaces on the next line** | tests/data/cases/comments_non_breaking_space.py | 18 |
| **# output** | tests/data/cases/comments_non_breaking_space.py | 21 |
| **# DEFAULT_TYPE_ATTRIBUTES,** | tests/data/cases/comments_non_breaking_space.py | 26 |
| **#    There's a NBSP + 3 spaces before** | tests/data/cases/comments_non_breaking_space.py | 42 |
| **#    And 4 spaces on the next line** | tests/data/cases/comments_non_breaking_space.py | 43 |

## Function Names and Associated Docstring
```python
def function(a):
"""
This docstring is already formatted
a
b
"""
```
# tests/data/cases/dummy_implementations.py


# Comments
| Comment | File | Line |
|---------|------|------|
| **# output** | tests/data/cases/dummy_implementations.py | 71 |

## Function Names and Associated Docstring
```python
def dummy(a):
"""

"""
```
```python
def a(arg):
"""

"""
```
```python
def dummy_two():
"""

"""
```
```python
def dummy_three():
"""

"""
```
```python
def dummy_four():
"""

"""
```
```python
def b(arg):
"""

"""
```
```python
def has_comment():
"""

"""
```
```python
def foo(self, a):
"""

"""
```
```python
def bar(self, b):
"""

"""
```
```python
def baz(self, c):
"""

"""
```
# tests/data/cases/fmtonoff.py



# Comments
| Comment | File | Line |
|---------|------|------|
| **#!/usr/bin/env python3** | tests/data/cases/fmtonoff.py | 1 |
| **# fmt: off** | tests/data/cases/fmtonoff.py | 9 |
| **# fmt: on** | tests/data/cases/fmtonoff.py | 12 |
| **# Comment 1** | tests/data/cases/fmtonoff.py | 14 |
| **# Comment 2** | tests/data/cases/fmtonoff.py | 16 |
| **# fmt: off** | tests/data/cases/fmtonoff.py | 18 |
| **# fmt: on** | tests/data/cases/fmtonoff.py | 40 |
| **# fmt: off** | tests/data/cases/fmtonoff.py | 48 |
| **# fmt: off** | tests/data/cases/fmtonoff.py | 54 |
| **# fmt: on** | tests/data/cases/fmtonoff.py | 57 |
| **# fmt: off** | tests/data/cases/fmtonoff.py | 62 |
| **# fmt: on** | tests/data/cases/fmtonoff.py | 65 |
| **# fmt: off** | tests/data/cases/fmtonoff.py | 68 |
| **# fmt: on** | tests/data/cases/fmtonoff.py | 71 |
| **# fmt: off** | tests/data/cases/fmtonoff.py | 74 |
| **# fmt: on** | tests/data/cases/fmtonoff.py | 77 |
| **# fmt: off** | tests/data/cases/fmtonoff.py | 79 |
| **# fmt: on** | tests/data/cases/fmtonoff.py | 82 |
| **# fmt: off** | tests/data/cases/fmtonoff.py | 85 |
| **# fmt: on** | tests/data/cases/fmtonoff.py | 92 |
| **# fmt: off** | tests/data/cases/fmtonoff.py | 98 |
| **#hey, that won't work** | tests/data/cases/fmtonoff.py | 101 |
| **# fmt: on** | tests/data/cases/fmtonoff.py | 104 |
| **# fmt: on** | tests/data/cases/fmtonoff.py | 108 |
| **# fmt: off** | tests/data/cases/fmtonoff.py | 109 |
| **# fmt: on** | tests/data/cases/fmtonoff.py | 114 |
| **# fmt: off** | tests/data/cases/fmtonoff.py | 115 |
| **# ...but comments still get reformatted even though they should not be** | tests/data/cases/fmtonoff.py | 116 |
| **# fmt: on** | tests/data/cases/fmtonoff.py | 117 |
| **# fmt: off** | tests/data/cases/fmtonoff.py | 123 |
| **# fmt: on** | tests/data/cases/fmtonoff.py | 127 |
| **# a trailing space which is why we need the silliness below** | tests/data/cases/fmtonoff.py | 137 |
| **# fmt: off** | tests/data/cases/fmtonoff.py | 148 |
| **# fmt: on** | tests/data/cases/fmtonoff.py | 150 |
| **# fmt: off** | tests/data/cases/fmtonoff.py | 165 |
| **# fmt: on** | tests/data/cases/fmtonoff.py | 178 |
| **# fmt: off** | tests/data/cases/fmtonoff.py | 181 |
| **# No formatting to the end of the file** | tests/data/cases/fmtonoff.py | 183 |
| **# output** | tests/data/cases/fmtonoff.py | 188 |
| **#!/usr/bin/env python3** | tests/data/cases/fmtonoff.py | 191 |
| **# fmt: off** | tests/data/cases/fmtonoff.py | 198 |
| **# fmt: on** | tests/data/cases/fmtonoff.py | 201 |
| **# Comment 1** | tests/data/cases/fmtonoff.py | 203 |
| **# Comment 2** | tests/data/cases/fmtonoff.py | 205 |
| **# fmt: off** | tests/data/cases/fmtonoff.py | 208 |
| **# fmt: on** | tests/data/cases/fmtonoff.py | 230 |
| **# fmt: off** | tests/data/cases/fmtonoff.py | 251 |
| **# fmt: off** | tests/data/cases/fmtonoff.py | 258 |
| **# fmt: on** | tests/data/cases/fmtonoff.py | 261 |
| **# fmt: off** | tests/data/cases/fmtonoff.py | 268 |
| **# fmt: on** | tests/data/cases/fmtonoff.py | 271 |
| **# fmt: off** | tests/data/cases/fmtonoff.py | 275 |
| **# fmt: on** | tests/data/cases/fmtonoff.py | 278 |
| **# fmt: off** | tests/data/cases/fmtonoff.py | 282 |
| **# fmt: on** | tests/data/cases/fmtonoff.py | 285 |
| **# fmt: off** | tests/data/cases/fmtonoff.py | 287 |
| **# fmt: on** | tests/data/cases/fmtonoff.py | 290 |
| **# fmt: off** | tests/data/cases/fmtonoff.py | 294 |
| **# fmt: on** | tests/data/cases/fmtonoff.py | 301 |
| **# fmt: off** | tests/data/cases/fmtonoff.py | 309 |
| **# hey, that won't work** | tests/data/cases/fmtonoff.py | 311 |
| **# fmt: on** | tests/data/cases/fmtonoff.py | 313 |
| **# fmt: on** | tests/data/cases/fmtonoff.py | 319 |
| **# fmt: off** | tests/data/cases/fmtonoff.py | 320 |
| **# fmt: on** | tests/data/cases/fmtonoff.py | 325 |
| **# fmt: off** | tests/data/cases/fmtonoff.py | 326 |
| **# ...but comments still get reformatted even though they should not be** | tests/data/cases/fmtonoff.py | 327 |
| **# fmt: on** | tests/data/cases/fmtonoff.py | 328 |
| **# fmt: off** | tests/data/cases/fmtonoff.py | 341 |
| **# fmt: on** | tests/data/cases/fmtonoff.py | 345 |
| **# a trailing space which is why we need the silliness below** | tests/data/cases/fmtonoff.py | 355 |
| **# fmt: off** | tests/data/cases/fmtonoff.py | 366 |
| **# fmt: on** | tests/data/cases/fmtonoff.py | 368 |
| **# fmt: off** | tests/data/cases/fmtonoff.py | 388 |
| **# fmt: on** | tests/data/cases/fmtonoff.py | 401 |
| **# fmt: off** | tests/data/cases/fmtonoff.py | 404 |
| **# No formatting to the end of the file** | tests/data/cases/fmtonoff.py | 406 |

## Function Names and Associated Docstring
```python
def func_no_args():
"""

"""
```
```python
def function_signature_stress_test(number, no_annotation, text):
"""

"""
```
```python
def spaces(a, b, c, d, e, f, g, h, i):
"""

"""
```
```python
def spaces_types(a, b, c, d, e, f, g, h, i):
"""

"""
```
```python
def spaces2(result):
"""

"""
```
```python
def subscriptlist():
"""

"""
```
```python
def import_as_names():
"""

"""
```
```python
def testlist_star_expr():
"""

"""
```
```python
def yield_expr():
"""

"""
```
```python
def example(session):
"""

"""
```
```python
def off_and_on_without_data():
"""
All comments here are technically on the same prefix.

The comments between will be formatted. This is a known limitation.
"""
```
```python
def on_and_off_broken():
"""
Another known limitation.
"""
```
```python
def long_lines():
"""

"""
```
```python
def single_literal_yapf_disable():
"""
Black does not support this.
"""
```
# tests/data/cases/fmtonoff2.py


# Comments
| Comment | File | Line |
|---------|------|------|
| **# fmt: off** | tests/data/cases/fmtonoff2.py | 6 |
| **# Test data:** | tests/data/cases/fmtonoff2.py | 8 |
| **#   Position, Volume, State, TmSt/TmEx/None, [call, [arg1...]]** | tests/data/cases/fmtonoff2.py | 9 |
| **# Test don't manage the volume** | tests/data/cases/fmtonoff2.py | 13 |
| **# misaligned comment** | tests/data/cases/fmtonoff2.py | 26 |
| **# one is zero/none** | tests/data/cases/fmtonoff2.py | 35 |
| **# fmt: on** | tests/data/cases/fmtonoff2.py | 40 |

## Function Names and Associated Docstring
```python
def test_fader(test):
"""

"""
```
```python
def check_fader(test):
"""

"""
```
```python
def verify_fader(test):
"""
Hey, ho.
"""
```
```python
def test_calculate_fades():
"""

"""
```
# tests/data/cases/fmtpass_imports.py


# Comments
| Comment | File | Line |
|---------|------|------|
| **# Regression test for https://github.com/psf/black/issues/3438** | tests/data/cases/fmtpass_imports.py | 1 |
| **# fmt: off** | tests/data/cases/fmtpass_imports.py | 6 |
| **# fmt: on** | tests/data/cases/fmtpass_imports.py | 8 |
| **# fmt: off** | tests/data/cases/fmtpass_imports.py | 14 |
| **# fmt: on** | tests/data/cases/fmtpass_imports.py | 16 |

# tests/data/cases/function.py



# Comments
| Comment | File | Line |
|---------|------|------|
| **#!/usr/bin/env python3** | tests/data/cases/function.py | 1 |
| **# EMPTY LINE WITH WHITESPACE (this comment will be removed)** | tests/data/cases/function.py | 37 |
| **# trailing standalone comment** | tests/data/cases/function.py | 53 |
| **# a trailing space which is why we need the silliness below** | tests/data/cases/function.py | 65 |
| **# output** | tests/data/cases/function.py | 97 |
| **#!/usr/bin/env python3** | tests/data/cases/function.py | 100 |
| **# trailing standalone comment** | tests/data/cases/function.py | 194 |
| **# a trailing space which is why we need the silliness below** | tests/data/cases/function.py | 206 |

## Function Names and Associated Docstring
```python
def func_no_args():
"""

"""
```
```python
def function_signature_stress_test(number, no_annotation, text):
"""

"""
```
```python
def spaces(a, b, c, d, e, f, g, h, i):
"""

"""
```
```python
def spaces_types(a, b, c, d, e, f, g, h, i):
"""

"""
```
```python
def spaces2(result):
"""

"""
```
```python
def example(session):
"""

"""
```
```python
def long_lines():
"""

"""
```
```python
def trailing_comma():
"""

"""
```
```python
def f(a):
"""

"""
```
```python
def __await__():
"""

"""
```
# tests/data/cases/import_spacing.py



# Comments
| Comment | File | Line |
|---------|------|------|
| **# flake8: noqa** | tests/data/cases/import_spacing.py | 3 |
| **# This relies on each of the submodules having an __all__ variable.** | tests/data/cases/import_spacing.py | 13 |
| **# output** | tests/data/cases/import_spacing.py | 52 |
| **# flake8: noqa** | tests/data/cases/import_spacing.py | 57 |
| **# This relies on each of the submodules having an __all__ variable.** | tests/data/cases/import_spacing.py | 65 |

# tests/data/cases/line_ranges_basic.py



# Comments
| Comment | File | Line |
|---------|------|------|
| **# flags: --line-ranges=5-6** | tests/data/cases/line_ranges_basic.py | 1 |
| **# NOTE: If you need to modify this file, pay special attention to the --line-ranges=** | tests/data/cases/line_ranges_basic.py | 2 |
| **# flag above as it's formatting specifically these lines.** | tests/data/cases/line_ranges_basic.py | 3 |
| **# Adding some unformated code covering a wide range of syntaxes.** | tests/data/cases/line_ranges_basic.py | 9 |
| **# Incorrectly indented prefix comments.** | tests/data/cases/line_ranges_basic.py | 12 |
| **#NOTE: The following indentation is incorrect:** | tests/data/cases/line_ranges_basic.py | 20 |
| **# output** | tests/data/cases/line_ranges_basic.py | 44 |
| **# flags: --line-ranges=5-6** | tests/data/cases/line_ranges_basic.py | 45 |
| **# NOTE: If you need to modify this file, pay special attention to the --line-ranges=** | tests/data/cases/line_ranges_basic.py | 46 |
| **# flag above as it's formatting specifically these lines.** | tests/data/cases/line_ranges_basic.py | 47 |
| **# Adding some unformated code covering a wide range of syntaxes.** | tests/data/cases/line_ranges_basic.py | 75 |
| **# Incorrectly indented prefix comments.** | tests/data/cases/line_ranges_basic.py | 78 |
| **#NOTE: The following indentation is incorrect:** | tests/data/cases/line_ranges_basic.py | 86 |

## Function Names and Associated Docstring
```python
def foo1(parameter_1, parameter_2, parameter_3, parameter_4, parameter_5, parameter_6, parameter_7):
"""

"""
```
```python
def foo2(parameter_1, parameter_2, parameter_3, parameter_4, parameter_5, parameter_6, parameter_7):
"""

"""
```
```python
def foo3(parameter_1, parameter_2, parameter_3, parameter_4, parameter_5, parameter_6, parameter_7):
"""

"""
```
```python
def foo4(parameter_1, parameter_2, parameter_3, parameter_4, parameter_5, parameter_6, parameter_7):
"""

"""
```
```python
def my_func(arg):
"""

"""
```
# tests/data/cases/line_ranges_fmt_off.py


# Comments
| Comment | File | Line |
|---------|------|------|
| **# flags: --line-ranges=7-7 --line-ranges=17-23** | tests/data/cases/line_ranges_fmt_off.py | 1 |
| **# NOTE: If you need to modify this file, pay special attention to the --line-ranges=** | tests/data/cases/line_ranges_fmt_off.py | 2 |
| **# flag above as it's formatting specifically these lines.** | tests/data/cases/line_ranges_fmt_off.py | 3 |
| **# fmt: off** | tests/data/cases/line_ranges_fmt_off.py | 5 |
| **# fmt: on** | tests/data/cases/line_ranges_fmt_off.py | 9 |
| **# fmt: off** | tests/data/cases/line_ranges_fmt_off.py | 14 |
| **# fmt: on** | tests/data/cases/line_ranges_fmt_off.py | 19 |
| **# output** | tests/data/cases/line_ranges_fmt_off.py | 25 |
| **# flags: --line-ranges=7-7 --line-ranges=17-23** | tests/data/cases/line_ranges_fmt_off.py | 27 |
| **# NOTE: If you need to modify this file, pay special attention to the --line-ranges=** | tests/data/cases/line_ranges_fmt_off.py | 28 |
| **# flag above as it's formatting specifically these lines.** | tests/data/cases/line_ranges_fmt_off.py | 29 |
| **# fmt: off** | tests/data/cases/line_ranges_fmt_off.py | 31 |
| **# fmt: on** | tests/data/cases/line_ranges_fmt_off.py | 35 |
| **# fmt: off** | tests/data/cases/line_ranges_fmt_off.py | 40 |
| **# fmt: on** | tests/data/cases/line_ranges_fmt_off.py | 45 |

## Function Names and Associated Docstring
```python
def myfunc():
"""

"""
```
# tests/data/cases/line_ranges_imports.py


# Comments
| Comment | File | Line |
|---------|------|------|
| **# flags: --line-ranges=8-8** | tests/data/cases/line_ranges_imports.py | 1 |
| **# NOTE: If you need to modify this file, pay special attention to the --line-ranges=** | tests/data/cases/line_ranges_imports.py | 2 |
| **# flag above as it's formatting specifically these lines.** | tests/data/cases/line_ranges_imports.py | 3 |
| **# This test ensures no empty lines are added around import lines.** | tests/data/cases/line_ranges_imports.py | 5 |
| **# It caused an issue before https://github.com/psf/black/pull/3610 is merged.** | tests/data/cases/line_ranges_imports.py | 6 |

# tests/data/cases/nested_stub.py


# Comments
| Comment | File | Line |
|---------|------|------|
| **# flags: --pyi** | tests/data/cases/nested_stub.py | 1 |
| **# output** | tests/data/cases/nested_stub.py | 33 |

## Function Names and Associated Docstring
```python
def f1(self):
"""

"""
```
```python
def f2(self):
"""

"""
```
```python
def function_definition(self):
"""

"""
```
```python
def bar(self):
"""

"""
```
# tests/data/cases/pattern_matching_extras.py


# Comments
| Comment | File | Line |
|---------|------|------|
| **# flags: --minimum-version=3.10** | tests/data/cases/pattern_matching_extras.py | 1 |

## Function Names and Associated Docstring
```python
def func(match, case):
"""

"""
```
# tests/data/cases/power_op_newline.py


# Comments
| Comment | File | Line |
|---------|------|------|
| **# flags: --line-length=0** | tests/data/cases/power_op_newline.py | 1 |
| **# output** | tests/data/cases/power_op_newline.py | 4 |

# tests/data/cases/preview_comments7.py


# Comments
| Comment | File | Line |
|---------|------|------|
| **# flags: --unstable** | tests/data/cases/preview_comments7.py | 1 |
| **#  String,** | tests/data/cases/preview_comments7.py | 9 |
| **#  resolve_to_config_type,** | tests/data/cases/preview_comments7.py | 10 |
| **#  DEFAULT_TYPE_ATTRIBUTES,** | tests/data/cases/preview_comments7.py | 11 |
| **#  and some comments,** | tests/data/cases/preview_comments7.py | 22 |
| **#  resolve_to_config_type,** | tests/data/cases/preview_comments7.py | 23 |
| **#  DEFAULT_TYPE_ATTRIBUTES,** | tests/data/cases/preview_comments7.py | 24 |
| **# The type: ignore exception only applies to line length, not** | tests/data/cases/preview_comments7.py | 77 |
| **# other types of formatting.** | tests/data/cases/preview_comments7.py | 78 |
| **# metadata_version errors.** | tests/data/cases/preview_comments7.py | 89 |
| **# name errors.** | tests/data/cases/preview_comments7.py | 102 |
| **# version errors.** | tests/data/cases/preview_comments7.py | 114 |
| **# Regression test for https://github.com/psf/black/issues/3756.** | tests/data/cases/preview_comments7.py | 135 |
| **# output** | tests/data/cases/preview_comments7.py | 147 |
| **#  String,** | tests/data/cases/preview_comments7.py | 156 |
| **#  resolve_to_config_type,** | tests/data/cases/preview_comments7.py | 157 |
| **#  DEFAULT_TYPE_ATTRIBUTES,** | tests/data/cases/preview_comments7.py | 158 |
| **#  and some comments,** | tests/data/cases/preview_comments7.py | 169 |
| **#  resolve_to_config_type,** | tests/data/cases/preview_comments7.py | 170 |
| **#  DEFAULT_TYPE_ATTRIBUTES,** | tests/data/cases/preview_comments7.py | 171 |
| **# The type: ignore exception only applies to line length, not** | tests/data/cases/preview_comments7.py | 217 |
| **# other types of formatting.** | tests/data/cases/preview_comments7.py | 218 |
| **# metadata_version errors.** | tests/data/cases/preview_comments7.py | 239 |
| **# name errors.** | tests/data/cases/preview_comments7.py | 256 |
| **# version errors.** | tests/data/cases/preview_comments7.py | 273 |
| **# Regression test for https://github.com/psf/black/issues/3756.** | tests/data/cases/preview_comments7.py | 299 |

## Function Names and Associated Docstring
```python
def func():
"""

"""
```
```python
def test_fails_invalid_post_data(self, pyramid_config, db_request, post_data, message):
"""

"""
```
# tests/data/cases/remove_await_parens.py


# Comments
| Comment | File | Line |
|---------|------|------|
| **# Control example** | tests/data/cases/remove_await_parens.py | 3 |
| **# Remove brackets for short coroutine/task** | tests/data/cases/remove_await_parens.py | 7 |
| **# Check comments** | tests/data/cases/remove_await_parens.py | 20 |
| **# Long lines** | tests/data/cases/remove_await_parens.py | 36 |
| **# Same as above but with magic trailing comma in function** | tests/data/cases/remove_await_parens.py | 40 |
| **# Cr@zY Br@ck3Tz** | tests/data/cases/remove_await_parens.py | 44 |
| **# Keep brackets around non power operations and nested awaits** | tests/data/cases/remove_await_parens.py | 60 |
| **# It's awaits all the way down...** | tests/data/cases/remove_await_parens.py | 67 |
| **# output** | tests/data/cases/remove_await_parens.py | 92 |
| **# Control example** | tests/data/cases/remove_await_parens.py | 96 |
| **# Remove brackets for short coroutine/task** | tests/data/cases/remove_await_parens.py | 101 |
| **# Check comments** | tests/data/cases/remove_await_parens.py | 114 |
| **# Long lines** | tests/data/cases/remove_await_parens.py | 127 |
| **# Same as above but with magic trailing comma in function** | tests/data/cases/remove_await_parens.py | 140 |
| **# Cr@zY Br@ck3Tz** | tests/data/cases/remove_await_parens.py | 153 |
| **# Keep brackets around non power operations and nested awaits** | tests/data/cases/remove_await_parens.py | 158 |
| **# It's awaits all the way down...** | tests/data/cases/remove_await_parens.py | 167 |

# tests/data/cases/remove_newline_after_code_block_open.py


# Comments
| Comment | File | Line |
|---------|------|------|
| **# There is a comment here** | tests/data/cases/remove_newline_after_code_block_open.py | 25 |
| **# output** | tests/data/cases/remove_newline_after_code_block_open.py | 112 |
| **# There is a comment here** | tests/data/cases/remove_newline_after_code_block_open.py | 136 |

## Function Names and Associated Docstring
```python
def foo1():
"""

"""
```
```python
def foo2():
"""

"""
```
```python
def foo3():
"""

"""
```
```python
def foo4():
"""

"""
```
```python
def bar(self):
"""

"""
```
# tests/data/cases/torture.py


# Comments
| Comment | File | Line |
|---------|------|------|
| **# output** | tests/data/cases/torture.py | 31 |

## Function Names and Associated Docstring
```python
def test(self, othr):
"""

"""
```
```python
def foo(self):
"""

"""
```
# tests/data/line_ranges_formatted/basic.py


# Comments
| Comment | File | Line |
|---------|------|------|
| **# fmt: off** | tests/data/line_ranges_formatted/basic.py | 9 |
| **# fmt: on** | tests/data/line_ranges_formatted/basic.py | 13 |
| **# This should cover as many syntaxes as possible.** | tests/data/line_ranges_formatted/basic.py | 19 |

## Function Names and Associated Docstring
```python
def should_also_work(self):
"""

"""
```
```python
def __init__(self):
"""

"""
```
```python
def plus_one(self, number):
"""

"""
```
# tests/data/miscellaneous/force_pyi.py


# Comments
| Comment | File | Line |
|---------|------|------|
| **# flags: --pyi** | tests/data/miscellaneous/force_pyi.py | 1 |
| **# output** | tests/data/miscellaneous/force_pyi.py | 33 |

## Function Names and Associated Docstring
```python
def zoo():
"""

"""
```
```python
def foo():
"""

"""
```
```python
def spam(arg):
"""

"""
```
```python
def eggs():
"""

"""
```
```python
def BMethod(self, arg):
"""

"""
```
# tests/optional.py



# Comments
| Comment | File | Line |
|---------|------|------|
| **# pytest < 7** | tests/optional.py | 28 |
| **#** | tests/optional.py | 29 |
| **# "isort: skip" is needed or it moves the "type: ignore" to the following line** | tests/optional.py | 30 |
| **# because of the line length, and then mypy complains.** | tests/optional.py | 31 |
| **# Of course, adding the "isort: skip" means that** | tests/optional.py | 32 |
| **# flake8-bugbear then also complains about the line length,** | tests/optional.py | 33 |
| **# so we *also* need a "noqa" comment for good measure :)** | tests/optional.py | 34 |
| **# collect requested optional tests** | tests/optional.py | 89 |

## Function Names and Associated Docstring
```python
def pytest_addoption(parser):
"""

"""
```
```python
def pytest_configure(config):
"""
Optional tests are markers.

Use the syntax in https://docs.pytest.org/en/stable/mark.html#registering-marks.
"""
```
```python
def pytest_collection_modifyitems(config, items):
"""

"""
```
```python
def skip_mark(tests):
"""

"""
```
```python
def no(name):
"""

"""
```
# tests/test_black.py



# Comments
| Comment | File | Line |
|---------|------|------|
| **#!/usr/bin/env python3** | tests/test_black.py | 1 |
| **# Import other test classes** | tests/test_black.py | 53 |
| **# Match the time output in a diff, but nothing else** | tests/test_black.py | 80 |
| **# Dummy root, since most of the tests don't care about it** | tests/test_black.py | 113 |
| **# Writing files in text mode automatically uses the system newline,** | tests/test_black.py | 173 |
| **# but in this case we don't want this for testing reasons. See:** | tests/test_black.py | 174 |
| **# https://github.com/psf/black/pull/3348** | tests/test_black.py | 175 |
| **# Again, the contents are checked in a different test, so only look for colors.** | tests/test_black.py | 242 |
| **# We check the contents of the diff in `test_expression_diff`. All** | tests/test_black.py | 317 |
| **# we need to check here is that color codes exist in the result.** | tests/test_black.py | 318 |
| **# We don't yet support feature version detection in nested f-strings** | tests/test_black.py | 346 |
| **# Full source should fail (invalid syntax at header)** | tests/test_black.py | 367 |
| **# So, skipping the first line should work** | tests/test_black.py | 369 |
| **# ensure black can parse this when the target is 3.6** | tests/test_black.py | 427 |
| **# but not on 3.7, because async/await is no longer an identifier** | tests/test_black.py | 429 |
| **# ensure black can parse this when the target is 3.7** | tests/test_black.py | 442 |
| **# but not on 3.6, because we use async as a reserved keyword** | tests/test_black.py | 444 |
| **# mixed tabs and spaces (valid Python 2 code)** | tests/test_black.py | 458 |
| **# Emulate the behavior when using the CLI (`black ./child  --verbose`), which** | tests/test_black.py | 470 |
| **# involves patching some `pathlib.Path` methods. In particular, `is_dir` is** | tests/test_black.py | 471 |
| **# patched only on its first call: when checking if "./child" is a directory it** | tests/test_black.py | 472 |
| **# should return True. The "./child" folder exists relative to the cwd when** | tests/test_black.py | 473 |
| **# running from CLI, but fails when running the tests because cwd is different** | tests/test_black.py | 474 |
| **# Note that the root folder (project_root) isn't the folder** | tests/test_black.py | 479 |
| **# named "root" (aka working_directory)** | tests/test_black.py | 480 |
| **# Test the feature detection of new decorator syntax** | tests/test_black.py | 813 |
| **# since this makes some test cases of test_get_features_used()** | tests/test_black.py | 814 |
| **# fails if it fails, this is tested first so that a useful case** | tests/test_black.py | 815 |
| **# is identified** | tests/test_black.py | 816 |
| **# skip explanation comments at the top of the file** | tests/test_black.py | 818 |
| **# f"The full node is\n{node!r}"** | tests/test_black.py | 828 |
| **# skip the '# output' comment at the top of the output part** | tests/test_black.py | 831 |
| **# f"The full node is\n{node!r}"** | tests/test_black.py | 841 |
| **# Files which will be reformatted.** | tests/test_black.py | 1097 |
| **# Files which will not be reformatted.** | tests/test_black.py | 1100 |
| **# Multi file command.** | tests/test_black.py | 1103 |
| **# verify cache with --pyi is separate** | tests/test_black.py | 1131 |
| **# verify cache with --pyi is separate** | tests/test_black.py | 1156 |
| **# verify cache with --target-version is separate** | tests/test_black.py | 1181 |
| **# verify cache with --target-version is separate** | tests/test_black.py | 1204 |
| **# __BLACK_STDIN_FILENAME__ should have been stripped** | tests/test_black.py | 1260 |
| **# __BLACK_STDIN_FILENAME__ should have been stripped** | tests/test_black.py | 1286 |
| **# __BLACK_STDIN_FILENAME__ should have been stripped** | tests/test_black.py | 1312 |
| **# Even with an existing file, since we are forcing stdin, black** | tests/test_black.py | 1322 |
| **# should output to stdout and not modify the file inplace** | tests/test_black.py | 1323 |
| **# Make sure is_file actually returns True** | tests/test_black.py | 1325 |
| **# __BLACK_STDIN_FILENAME__ should have been stripped** | tests/test_black.py | 1337 |
| **# It's `format_stdin_to_stdout()` calling `io.TextIOWrapper()`,** | tests/test_black.py | 1355 |
| **# return our mock object.** | tests/test_black.py | 1356 |
| **# It's something else (i.e. `decode_bytes()`) calling** | tests/test_black.py | 1358 |
| **# `io.TextIOWrapper()`, pass through to the original implementation.** | tests/test_black.py | 1359 |
| **# See discussion in https://github.com/psf/black/pull/2489** | tests/test_black.py | 1360 |
| **# Must also pass --preview** | tests/test_black.py | 1384 |
| **# we skip src_sub_pyproject since it is missing the [tool.black] section** | tests/test_black.py | 1690 |
| **# Test if XDG_CONFIG_HOME is checked** | tests/test_black.py | 1719 |
| **# Test fallback for XDG_CONFIG_HOME** | tests/test_black.py | 1727 |
| **# https://bugs.python.org/issue33660** | tests/test_black.py | 1748 |
| **# Can be removed when we drop support for Python 3.8.5** | tests/test_black.py | 1749 |
| **# Manually delete for Python < 3.8** | tests/test_black.py | 1773 |
| **# https://bugs.python.org/issue2142** | tests/test_black.py | 1784 |
| **# read_data adds a trailing newline** | tests/test_black.py | 1787 |
| **# Remove time from diff** | tests/test_black.py | 1853 |
| **# Remove time from diff** | tests/test_black.py | 1870 |
| **# Patch black.assert_equivalent to ensure the sanity checks fail** | tests/test_black.py | 1879 |
| **# Patch black.assert_equivalent to ensure the sanity checks fail** | tests/test_black.py | 1891 |
| **# This is the only directory known to contain a pyproject.toml** | tests/test_black.py | 1908 |
| **# See CVE-2024-21503. Mostly test that this completes in a reasonable** | tests/test_black.py | 2034 |
| **# time.** | tests/test_black.py | 2035 |
| **# Create multiple cache directories** | tests/test_black.py | 2051 |
| **# Force user_cache_dir to use the temporary directory for easier assertions** | tests/test_black.py | 2057 |
| **# If BLACK_CACHE_DIR is not set, use user_cache_dir** | tests/test_black.py | 2064 |
| **# If it is set, use the path provided in the env var.** | tests/test_black.py | 2069 |
| **# all of the target versions** | tests/test_black.py | 2076 |
| **# all of the features** | tests/test_black.py | 2078 |
| **# all of the magics** | tests/test_black.py | 2080 |
| **# all of the things** | tests/test_black.py | 2082 |
| **# Some common file systems enforce a maximum path length** | tests/test_black.py | 2091 |
| **# of 143 (issue #4174). We can't do anything if the directory** | tests/test_black.py | 2092 |
| **# path is too long, but ensure the name of the cache file itself** | tests/test_black.py | 2093 |
| **# doesn't get too crazy.** | tests/test_black.py | 2094 |
| **# this isn't quite doing what we want, but if it _isn't_** | tests/test_black.py | 2171 |
| **# called then we cannot be using the lock it provides** | tests/test_black.py | 2172 |
| **# Modify st_mtime** | tests/test_black.py | 2242 |
| **# Modify contents** | tests/test_black.py | 2255 |
| **# Exclude shouldn't touch files that were explicitly given to Black through the** | tests/test_black.py | 2379 |
| **# CLI. Exclude is supposed to only apply to the recursive discovery of files.** | tests/test_black.py | 2380 |
| **# https://github.com/psf/black/issues/1572** | tests/test_black.py | 2381 |
| **# https://github.com/psf/black/issues/2598** | tests/test_black.py | 2447 |
| **# If gitignore with */* is in root** | tests/test_black.py | 2486 |
| **# If .gitignore with */* is nested** | tests/test_black.py | 2491 |
| **# If command is executed from outer dir** | tests/test_black.py | 2499 |
| **# Setting exclude explicitly to an empty string to block .gitignore usage.** | tests/test_black.py | 2521 |
| **# A symlink that has an excluded name, but points to an included name** | tests/test_black.py | 2581 |
| **# A symlink that has an included name, but points to an excluded name** | tests/test_black.py | 2588 |
| **# a few tricky tests for force_exclude** | tests/test_black.py | 2652 |
| **# Exclude shouldn't exclude stdin_filename since it is mimicking the** | tests/test_black.py | 2727 |
| **# file being passed directly. This is the same as** | tests/test_black.py | 2728 |
| **# test_exclude_for_issue_1572** | tests/test_black.py | 2729 |
| **# Extend exclude shouldn't exclude stdin_filename since it is mimicking the** | tests/test_black.py | 2743 |
| **# file being passed directly. This is the same as** | tests/test_black.py | 2744 |
| **# test_exclude_for_issue_1572** | tests/test_black.py | 2745 |
| **# Force exclude should exclude the file when passing it through** | tests/test_black.py | 2759 |
| **# stdin_filename** | tests/test_black.py | 2760 |
| **# Force exclude should exclude a symlink based on the symlink, not its target** | tests/test_black.py | 2774 |
| **# format_str and Mode should keep working** | tests/test_black.py | 2802 |
| **# you can pass line length** | tests/test_black.py | 2807 |
| **# invalid input raises InvalidInput** | tests/test_black.py | 2813 |
| **# You probably should be using format_str() instead, but let's keep** | tests/test_black.py | 2818 |
| **# this one around since people do use it** | tests/test_black.py | 2819 |
| **# If we get a failure, make sure it's not because the code itself** | tests/test_black.py | 2832 |
| **# is invalid, since that will also cause assert_equivalent() to throw** | tests/test_black.py | 2833 |
| **# ASTSafetyError.** | tests/test_black.py | 2834 |
| **# https://github.com/psf/black/issues/4268** | tests/test_black.py | 2928 |
| **# Unfortunately the SyntaxError message has changed in newer versions so we** | tests/test_black.py | 2945 |
| **# can't match it directly.** | tests/test_black.py | 2946 |

## Function Names and Associated Docstring
```python
def cache_dir(exists):
"""

"""
```
```python
def event_loop():
"""

"""
```
```python
def invokeBlack(args, exit_code, ignore_config):
"""

"""
```
```python
def assert_collected_sources(src, expected):
"""

"""
```
```python
def tracefunc(frame, event, arg):
"""
Show function calls `from black/__init__.py` as they happen.

Register this with `sys.settrace()` in a test you're debugging.
"""
```
```python
def __init__(self):
"""

"""
```
```python
def test_empty_ff(self):
"""

"""
```
```python
def test_one_empty_line(self):
"""

"""
```
```python
def test_one_empty_line_ff(self):
"""

"""
```
```python
def test_piping(self):
"""

"""
```
```python
def test_piping_diff(self):
"""

"""
```
```python
def test_piping_diff_with_color(self):
"""

"""
```
```python
def test_pep_572_version_detection(self):
"""

"""
```
```python
def test_pep_695_version_detection(self):
"""

"""
```
```python
def test_expression_ff(self):
"""

"""
```
```python
def test_expression_diff(self):
"""

"""
```
```python
def test_expression_diff_with_color(self):
"""

"""
```
```python
def test_detect_pos_only_arguments(self):
"""

"""
```
```python
def test_detect_debug_f_strings(self):
"""

"""
```
```python
def test_string_quotes(self):
"""

"""
```
```python
def test_skip_source_first_line(self):
"""

"""
```
```python
def test_skip_source_first_line_when_mixing_newlines(self):
"""

"""
```
```python
def test_skip_magic_trailing_comma(self):
"""

"""
```
```python
def test_async_as_identifier(self):
"""

"""
```
```python
def test_python37(self):
"""

"""
```
```python
def test_tab_comment_indentation(self):
"""

"""
```
```python
def test_false_positive_symlink_output_issue_3384(self):
"""

"""
```
```python
def test_report_verbose(self):
"""

"""
```
```python
def test_report_quiet(self):
"""

"""
```
```python
def test_report_normal(self):
"""

"""
```
```python
def test_lib2to3_parse(self):
"""

"""
```
```python
def test_get_features_used_decorator(self):
"""

"""
```
```python
def test_get_features_used(self):
"""

"""
```
```python
def check_features_used(self, source, expected):
"""

"""
```
```python
def test_get_features_used_for_future_flags(self):
"""

"""
```
```python
def test_get_future_imports(self):
"""

"""
```
```python
def test_debug_visitor(self):
"""

"""
```
```python
def test_format_file_contents(self):
"""

"""
```
```python
def test_endmarker(self):
"""

"""
```
```python
def test_assertFormatEqual_print_full_tree(self):
"""

"""
```
```python
def test_assertFormatEqual_print_tree_diff(self):
"""

"""
```
```python
def test_works_in_mono_process_only_environment(self):
"""

"""
```
```python
def test_check_diff_use_together(self):
"""

"""
```
```python
def test_no_src_fails(self):
"""

"""
```
```python
def test_src_and_code_fails(self):
"""

"""
```
```python
def test_broken_symlink(self):
"""

"""
```
```python
def test_single_file_force_pyi(self):
"""

"""
```
```python
def test_multi_file_force_pyi(self):
"""

"""
```
```python
def test_pipe_force_pyi(self):
"""

"""
```
```python
def test_single_file_force_py36(self):
"""

"""
```
```python
def test_multi_file_force_py36(self):
"""

"""
```
```python
def test_pipe_force_py36(self):
"""

"""
```
```python
def test_reformat_one_with_stdin(self):
"""

"""
```
```python
def test_reformat_one_with_stdin_filename(self):
"""

"""
```
```python
def test_reformat_one_with_stdin_filename_pyi(self):
"""

"""
```
```python
def test_reformat_one_with_stdin_filename_ipynb(self):
"""

"""
```
```python
def test_reformat_one_with_stdin_and_existing_path(self):
"""

"""
```
```python
def test_reformat_one_with_stdin_empty(self):
"""

"""
```
```python
def test_cli_unstable(self):
"""

"""
```
```python
def test_invalid_cli_regex(self):
"""

"""
```
```python
def test_required_version_matches_version(self):
"""

"""
```
```python
def test_required_version_matches_partial_version(self):
"""

"""
```
```python
def test_required_version_does_not_match_on_minor_version(self):
"""

"""
```
```python
def test_required_version_does_not_match_version(self):
"""

"""
```
```python
def test_preserves_line_endings(self):
"""

"""
```
```python
def test_preserves_line_endings_via_stdin(self):
"""

"""
```
```python
def test_normalize_line_endings(self):
"""

"""
```
```python
def test_root_logger_not_used_directly(self):
"""

"""
```
```python
def test_invalid_config_return_code(self):
"""

"""
```
```python
def test_parse_pyproject_toml(self):
"""

"""
```
```python
def test_spellcheck_pyproject_toml(self):
"""

"""
```
```python
def test_parse_pyproject_toml_project_metadata(self):
"""

"""
```
```python
def test_infer_target_version(self):
"""

"""
```
```python
def test_read_pyproject_toml(self):
"""

"""
```
```python
def test_read_pyproject_toml_from_stdin(self):
"""

"""
```
```python
def test_find_project_root(self):
"""

"""
```
```python
def test_find_pyproject_toml(self, find_user_pyproject_toml):
"""

"""
```
```python
def test_find_user_pyproject_toml_linux(self):
"""

"""
```
```python
def test_find_user_pyproject_toml_windows(self):
"""

"""
```
```python
def test_bpo_33660_workaround(self):
"""

"""
```
```python
def test_normalize_path_ignore_windows_junctions_outside_of_root(self):
"""

"""
```
```python
def test_newline_comment_interaction(self):
"""

"""
```
```python
def test_bpo_2142_workaround(self):
"""

"""
```
```python
def compare_results(result, expected_value, expected_exit_code):
"""
Helper method to test the value and exit code of a click Result.
"""
```
```python
def test_code_option(self):
"""
Test the code option with no changes.
"""
```
```python
def test_code_option_changed(self):
"""
Test the code option when changes are required.
"""
```
```python
def test_code_option_check(self):
"""
Test the code option when check is passed.
"""
```
```python
def test_code_option_check_changed(self):
"""
Test the code option when changes are required, and check is passed.
"""
```
```python
def test_code_option_diff(self):
"""
Test the code option when diff is passed.
"""
```
```python
def test_code_option_color_diff(self):
"""
Test the code option when color and diff are passed.
"""
```
```python
def test_code_option_safe(self):
"""
Test that the code option throws an error when the sanity checks fail.
"""
```
```python
def test_code_option_fast(self):
"""
Test that the code option ignores errors when the sanity checks fail.
"""
```
```python
def test_code_option_config(self):
"""
Test that the code option finds the pyproject.toml in the current directory.
"""
```
```python
def test_code_option_parent_config(self):
"""
Test that the code option finds the pyproject.toml in the parent directory.
"""
```
```python
def test_for_handled_unexpected_eof_error(self):
"""
Test that an unexpected EOF SyntaxError is nicely presented.
"""
```
```python
def test_line_ranges_with_code_option(self):
"""

"""
```
```python
def test_line_ranges_with_stdin(self):
"""

"""
```
```python
def test_line_ranges_with_source(self):
"""

"""
```
```python
def test_line_ranges_with_multiple_sources(self):
"""

"""
```
```python
def test_line_ranges_with_ipynb(self):
"""

"""
```
```python
def test_line_ranges_in_pyproject_toml(self):
"""

"""
```
```python
def test_lines_with_leading_tabs_expanded(self):
"""

"""
```
```python
def test_get_cache_dir(self, tmp_path, monkeypatch):
"""

"""
```
```python
def test_cache_file_length(self):
"""

"""
```
```python
def test_cache_broken_file(self):
"""

"""
```
```python
def test_cache_single_file_already_cached(self):
"""

"""
```
```python
def test_cache_multiple_files(self):
"""

"""
```
```python
def test_no_cache_when_writeback_diff(self, color):
"""

"""
```
```python
def test_output_locking_when_writeback_diff(self, color):
"""

"""
```
```python
def test_no_cache_when_stdin(self):
"""

"""
```
```python
def test_read_cache_no_cachefile(self):
"""

"""
```
```python
def test_write_cache_read_cache(self):
"""

"""
```
```python
def test_filter_cached(self):
"""

"""
```
```python
def test_filter_cached_hash(self):
"""

"""
```
```python
def test_write_cache_creates_directory_if_needed(self):
"""

"""
```
```python
def test_failed_formatting_does_not_get_cached(self):
"""

"""
```
```python
def test_write_cache_write_fail(self):
"""

"""
```
```python
def test_read_cache_line_lengths(self):
"""

"""
```
```python
def test_include_exclude(self):
"""

"""
```
```python
def test_gitignore_used_as_default(self):
"""

"""
```
```python
def test_gitignore_used_on_multiple_sources(self):
"""

"""
```
```python
def test_exclude_for_issue_1572(self):
"""

"""
```
```python
def test_gitignore_exclude(self):
"""

"""
```
```python
def test_nested_gitignore(self):
"""

"""
```
```python
def test_nested_gitignore_directly_in_source_directory(self):
"""

"""
```
```python
def test_invalid_gitignore(self):
"""

"""
```
```python
def test_invalid_nested_gitignore(self):
"""

"""
```
```python
def test_gitignore_that_ignores_subfolders(self):
"""

"""
```
```python
def test_empty_include(self):
"""

"""
```
```python
def test_include_absolute_path(self):
"""

"""
```
```python
def test_exclude_absolute_path(self):
"""

"""
```
```python
def test_extend_exclude(self):
"""

"""
```
```python
def test_symlinks(self):
"""

"""
```
```python
def test_get_sources_symlink_and_force_exclude(self):
"""

"""
```
```python
def test_get_sources_with_stdin_symlink_outside_root(self):
"""

"""
```
```python
def test_get_sources_with_stdin(self):
"""

"""
```
```python
def test_get_sources_with_stdin_filename(self):
"""

"""
```
```python
def test_get_sources_with_stdin_filename_and_exclude(self):
"""

"""
```
```python
def test_get_sources_with_stdin_filename_and_extend_exclude(self):
"""

"""
```
```python
def test_get_sources_with_stdin_filename_and_force_exclude(self):
"""

"""
```
```python
def test_get_sources_with_stdin_filename_and_force_exclude_and_symlink(self):
"""

"""
```
```python
def test_format_str(self):
"""

"""
```
```python
def check_ast_equivalence(self, source, dest):
"""

"""
```
```python
def test_assert_equivalent_basic(self):
"""

"""
```
```python
def test_assert_equivalent_del(self):
"""

"""
```
```python
def test_assert_equivalent_strings(self):
"""

"""
```
```python
def test_assert_equivalent_fstring(self):
"""

"""
```
```python
def test_equivalency_ast_parse_failure_includes_error(self):
"""

"""
```
```python
def out(msg):
"""

"""
```
```python
def err(msg):
"""

"""
```
```python
def _new_wrapper(output, io_TextIOWrapper):
"""

"""
```
```python
def fail():
"""

"""
```
```python
def get_output():
"""

"""
```
```python
def wrapped_func(path):
"""

"""
```
# tests/test_blackd.py



# Comments
| Comment | File | Line |
|---------|------|------|
| **# unittest_run_loop is unnecessary and a no-op since aiohttp 3.8, and** | tests/test_blackd.py | 26 |
| **# aiohttp 4 removed it. To maintain compatibility we can make our own** | tests/test_blackd.py | 27 |
| **# no-op decorator.** | tests/test_blackd.py | 28 |
| **# test preserved newlines when reformatted** | tests/test_blackd.py | 230 |
| **# test 204 when no change** | tests/test_blackd.py | 233 |

## Function Names and Associated Docstring
```python
def test_blackd_main(self):
"""

"""
```
```python
def unittest_run_loop(func):
"""

"""
```
# tests/test_docs.py



## Function Names and Associated Docstring
```python
def check_feature_list(lines, expected_feature_names, label):
"""

"""
```
```python
def test_feature_lists_are_up_to_date():
"""

"""
```
# tests/test_format.py



# Comments
| Comment | File | Line |
|---------|------|------|
| **# =============== #** | tests/test_format.py | 74 |
| **# Unusual cases** | tests/test_format.py | 75 |
| **# =============== #** | tests/test_format.py | 76 |

## Function Names and Associated Docstring
```python
def patch_dump_to_file(request):
"""

"""
```
```python
def check_file(subdir, filename):
"""

"""
```
```python
def test_simple_format(filename):
"""

"""
```
```python
def test_line_ranges_line_by_line(filename):
"""

"""
```
```python
def test_empty():
"""

"""
```
```python
def test_patma_invalid():
"""

"""
```
# tests/test_ipynb.py



# Comments
| Comment | File | Line |
|---------|------|------|
| **# Check that the cache isn't written to if Jupyter dependencies aren't installed.** | tests/test_ipynb.py | 438 |
| **# Check that the cache isn't written to if Jupyter dependencies aren't installed.** | tests/test_ipynb.py | 459 |

## Function Names and Associated Docstring
```python
def test_noop():
"""

"""
```
```python
def test_trailing_semicolon(fast):
"""

"""
```
```python
def test_trailing_semicolon_with_comment():
"""

"""
```
```python
def test_trailing_semicolon_with_comment_on_next_line():
"""

"""
```
```python
def test_trailing_semicolon_indented():
"""

"""
```
```python
def test_trailing_semicolon_noop():
"""

"""
```
```python
def test_cell_magic(mode):
"""

"""
```
```python
def test_cell_magic_noop():
"""

"""
```
```python
def test_magic(src, expected, mode):
"""

"""
```
```python
def test_non_python_magics(src):
"""

"""
```
```python
def test_set_input():
"""

"""
```
```python
def test_input_already_contains_transformed_magic():
"""

"""
```
```python
def test_magic_noop():
"""

"""
```
```python
def test_cell_magic_with_magic():
"""

"""
```
```python
def test_cell_magic_with_custom_python_magic(mode, expected_output, expectation):
"""

"""
```
```python
def test_cell_magic_nested():
"""

"""
```
```python
def test_cell_magic_with_magic_noop():
"""

"""
```
```python
def test_automagic():
"""

"""
```
```python
def test_multiline_magic():
"""

"""
```
```python
def test_multiline_no_magic():
"""

"""
```
```python
def test_cell_magic_with_invalid_body():
"""

"""
```
```python
def test_empty_cell():
"""

"""
```
```python
def test_entire_notebook_empty_metadata():
"""

"""
```
```python
def test_entire_notebook_trailing_newline():
"""

"""
```
```python
def test_entire_notebook_no_trailing_newline():
"""

"""
```
```python
def test_entire_notebook_without_changes():
"""

"""
```
```python
def test_non_python_notebook():
"""

"""
```
```python
def test_empty_string():
"""

"""
```
```python
def test_unparseable_notebook():
"""

"""
```
```python
def test_ipynb_diff_with_change():
"""

"""
```
```python
def test_ipynb_diff_with_no_change():
"""

"""
```
```python
def test_cache_isnt_written_if_no_jupyter_deps_single(monkeypatch, tmp_path):
"""

"""
```
```python
def test_cache_isnt_written_if_no_jupyter_deps_dir(monkeypatch, tmp_path):
"""

"""
```
```python
def test_ipynb_flag(tmp_path):
"""

"""
```
```python
def test_ipynb_and_pyi_flags():
"""

"""
```
```python
def test_unable_to_replace_magics(monkeypatch):
"""

"""
```
# tests/test_no_ipynb.py



## Function Names and Associated Docstring
```python
def test_ipynb_diff_with_no_change_single():
"""

"""
```
```python
def test_ipynb_diff_with_no_change_dir(tmp_path):
"""

"""
```
# tests/test_ranges.py



## Function Names and Associated Docstring
```python
def test_no_diff(lines):
"""

"""
```
```python
def test_invalid_lines(lines):
"""

"""
```
```python
def test_removals(lines, adjusted):
"""

"""
```
```python
def test_additions(lines, adjusted):
"""

"""
```
```python
def test_diffs(lines, adjusted):
"""

"""
```
```python
def test_sanitize(lines, sanitized):
"""

"""
```
# tests/test_schema.py


## Function Names and Associated Docstring
```python
def test_schema_entrypoint():
"""

"""
```
# tests/test_trans.py


# Comments
| Comment | File | Line |
|---------|------|------|
| **# Checking slices isn't strictly necessary, but it's easier to verify at** | tests/test_trans.py | 12 |
| **# a glance than only spans** | tests/test_trans.py | 13 |
| **# Most of these test cases omit the leading 'f' and leading / closing quotes** | tests/test_trans.py | 21 |
| **# for convenience** | tests/test_trans.py | 22 |
| **# Some additional property-based tests can be found in** | tests/test_trans.py | 23 |
| **# https://github.com/psf/black/pull/2654#issuecomment-981411748** | tests/test_trans.py | 24 |

## Function Names and Associated Docstring
```python
def test_fexpr_spans():
"""

"""
```
```python
def check(string, expected_spans, expected_slices):
"""

"""
```
# tests/util.py



# Comments
| Comment | File | Line |
|---------|------|------|
| **# For both preview and non-preview tests, ensure that Black doesn't crash on** | tests/util.py | 112 |
| **# this code, but don't pass "expected" because the precise output may differ.** | tests/util.py | 113 |
| **# Similarly, setting line length to 1 is a good way to catch** | tests/util.py | 136 |
| **# stability bugs. Some tests are known to be broken in preview mode with line length** | tests/util.py | 137 |
| **# of 1 though, and have marked that with a flag --no-preview-line-length-1** | tests/util.py | 138 |
| **# It's not useful to run safety checks if we're expecting no changes anyway. The** | tests/util.py | 173 |
| **# assertion right above will raise if reality does actually make changes. This just** | tests/util.py | 174 |
| **# avoids wasted CPU cycles.** | tests/util.py | 175 |
| **# Unfortunately the AST equivalence check relies on the built-in ast module** | tests/util.py | 177 |
| **# being able to parse the code being formatted. This doesn't always work out** | tests/util.py | 178 |
| **# when checking modern code on older versions.** | tests/util.py | 179 |
| **# Retain the `# flags: ` line when using --line-ranges=. This requires** | tests/util.py | 316 |
| **# the `# output` section to also include this line, but retaining the** | tests/util.py | 317 |
| **# line is important to make the line ranges match what you see in the** | tests/util.py | 318 |
| **# test file.** | tests/util.py | 319 |
| **# If there's no output marker, treat the entire file as already pre-formatted.** | tests/util.py | 329 |

## Function Names and Associated Docstring
```python
def _assert_format_equal(expected, actual):
"""

"""
```
```python
def assert_format(source, expected, mode):
"""
Convenience function to check that Black formats as expected.

You can pass @minimum_version if you're passing code with newer syntax to guard
safety guards so they don't just crash with a SyntaxError. Please note this is
separate from TargetVerson Mode configuration.
"""
```
```python
def _assert_format_inner(source, expected, mode):
"""

"""
```
```python
def dump_to_stderr():
"""

"""
```
```python
def get_base_dir(data):
"""

"""
```
```python
def all_data_cases(subdir_name, data):
"""

"""
```
```python
def get_case_path(subdir_name, name, data, suffix):
"""
Get case path from name
"""
```
```python
def read_data_with_mode(subdir_name, name, data):
"""
read_data_with_mode('test_name') -> Mode(), 'input', 'output'
"""
```
```python
def read_data(subdir_name, name, data):
"""
read_data('test_name') -> 'input', 'output'
"""
```
```python
def _parse_minimum_version(version):
"""

"""
```
```python
def get_flags_parser():
"""

"""
```
```python
def parse_mode(flags_line):
"""

"""
```
```python
def read_data_from_file(file_name):
"""

"""
```
```python
def read_jupyter_notebook(subdir_name, name, data):
"""

"""
```
```python
def read_jupyter_notebook_from_file(file_name):
"""

"""
```
```python
def change_directory(path):
"""
Context manager to temporarily chdir to a different directory.
"""
```
```python
def assertFormatEqual(self, expected, actual):
"""

"""
```
